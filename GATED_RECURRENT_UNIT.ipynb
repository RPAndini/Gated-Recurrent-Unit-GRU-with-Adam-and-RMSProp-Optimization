{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCd4_y83SOuH"
      },
      "source": [
        "# **GATED RECURRENT UNIT**\n",
        "\n",
        "Gated Recurrent Unit yang kemudian disingkat sebagai GRU merupakan salah satu algoritma pengembangan dari Recurrent Neural Network (RNN). GRU pertama kali diperkenalkan pada tahun 2014 oleh Kyunghyun Cho dkk dengan tujuan untuk mengatasi masalah vanishing gradient dan exploding gradient yang biasa terjadi pada RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCMsYO0GDcv"
      },
      "source": [
        "## **INSTALL TENSORFLOW VERSION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yxmGzj-VzxT"
      },
      "source": [
        "Dalam proses analisis data, digunakan framework open source tensorflow. TensorFlow adalah pilihan yang sangat baik untuk analisis menggunakan GRU karena menawarkan kombinasi yang kuat antara fitur, ekosistem, skalabilitas, dan fleksibilitas.\n",
        "\n",
        "Versi tensorflow yang digunakan pada penelitian ini yaitu tensorflow versi 2.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Mu6ZaKMdz4",
        "outputId": "4a91a919-5741-4821-ed8d-9cdf47429afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Requirement already satisfied: keras==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.15.0\n",
        "!pip install keras==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQebe4ZR4Hv7"
      },
      "source": [
        "## **INSTALL PACKAGE** ðŸ“¦"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11T5ObED5hxc"
      },
      "outputs": [],
      "source": [
        "# BASIC\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import math\n",
        "import statistics\n",
        "import random\n",
        "\n",
        "# TENSORFLOW\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Input\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# SKLEARN\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyHxBKuc3lV7"
      },
      "source": [
        "**KETERANGAN**\n",
        "\n",
        "`import numpy as np`\n",
        "\n",
        "Untuk komputasi numerik di python. Untuk array multidimensi dan fungsi matematika untuk operasi array tersebut.\n",
        "\n",
        ".\n",
        "\n",
        "`import pandas as pd`\n",
        "\n",
        "Untuk manipulasi dan analisis data yang mendukung struktur data seperti DataFrame/ pengolahan tabel\n",
        "\n",
        ".\n",
        "\n",
        "`import matplotlib.pyplot as plt`\n",
        "\n",
        "Membuat visualisasi data dalam bentuk grafik dan plot\n",
        "\n",
        ".\n",
        "\n",
        "`from datetime import datetime, timedelta`\n",
        "\n",
        "Memanipulasi tanggal dan waktu\n",
        "\n",
        ".\n",
        "\n",
        "`import math`\n",
        "\n",
        "Menyediakan fungsi-fungsi matematika dasar\n",
        "\n",
        "============================================================================\n",
        "\n",
        "`import tensorflow as tf`\n",
        "`from tensorflow import keras`\n",
        "\n",
        "pustaka open-source untuk pembelajaran mesin yang digunakan untuk berbagai tugas seperti jaringan saraf tiruan. Keras adalah antarmuka tingkat tinggi untuk TensorFlow yang menyediakan API yang lebih sederhana dan modular untuk membuat dan melatih model pembelajaran mesin.\n",
        "\n",
        ".\n",
        "\n",
        "`from keras import Input`\n",
        "\n",
        "Digunakan untuk mendefinisikan input layer dalam model.\n",
        "\n",
        ".\n",
        "\n",
        "`from keras.callbacks import EarlyStopping, ModelCheckpoint`\n",
        "\n",
        "`EarlyStopping` Callback untuk menghentikan pelatihan lebih awal jika metrik tertentu tidak meningkat.\n",
        "\n",
        "`ModelCheckpoint` Callback untuk menyimpan model atau bobot pada interval tertentu.\n",
        "\n",
        ".\n",
        "\n",
        "`from keras.optimizers import Adam`\n",
        "`from keras.optimizers import RMSprop`\n",
        "\n",
        "Optimizer yang digunakan untuk memperbarui bobot model berdasarkan gradien.\n",
        "\n",
        ".\n",
        "\n",
        "`from keras.models import Sequential`\n",
        "\n",
        "Jenis model yang lapisannya ditumpuk secara berurutan.\n",
        "\n",
        ".\n",
        "\n",
        "`from keras.layers import GRU, Dense, Dropout`\n",
        "\n",
        "Jenis lapisan dalam jaringan saraf. GRU adalah jenis RNN, Dense adalah lapisan yang sepenuhnya terhubung, dan Dropout adalah teknik regularisasi untuk mencegah overfitting.\n",
        "\n",
        "==========================================================================================================\n",
        "\n",
        "`import sklearn`\n",
        "\n",
        "Scikit-Learn adalah pustaka untuk pembelajaran mesin di Python.\n",
        "\n",
        ".\n",
        "\n",
        "`from sklearn.preprocessing import MinMaxScaler`\n",
        "\n",
        "Digunakan untuk normalisasi fitur dengan mengubah skala setiap fitur sehingga berada dalam rentang yang ditentukan.\n",
        "\n",
        ".\n",
        "\n",
        "`from sklearn.model_selection import\n",
        "train_test_split, ParameterGrid`\n",
        "\n",
        "Digunakan untuk melakukan pencarian grid pada parameter.\n",
        "\n",
        ".\n",
        "\n",
        "`from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error`\n",
        "\n",
        "Metode evaluasi untuk mengukur kesalahan prediksi model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjoJ8njZzF4Q"
      },
      "source": [
        "## **UPLOAD DATA** ðŸ“‘"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk upload file\n",
        "\n",
        "1. Pastikan Google Colab sudah `Connect` pada bagian atas (ditandai dengan adanya tanda centang hijau)\n",
        "2. Klik menu `Files` pada bagian samping jendela console\n",
        "3. Klik kanan pada jendela `Files`, lalu pilih `Upload`\n",
        "4. Pilih dataset yang akan digunakan (dalam format `csv.`)"
      ],
      "metadata": {
        "id": "BMqkWRg19m01"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GChfbOIs7mh8"
      },
      "source": [
        "Data yang telah diupload dalam bentuk `csv.`, kemudian dibaca menggunakan `pandas` dan didefinisikan sebagai `df`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBm0xpvBiwhP"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/Dataset Timah.csv', sep=';', index_col=['Date'], parse_dates=['Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHyUzY6GP_-"
      },
      "source": [
        "**Keterangan**\n",
        "\n",
        "* `sep` = separator, pemisah antar data dalam csv\n",
        "* `index_col` = kolom yang dijadikan index, dalam hal ini yaitu `Date` yang menunjukkan tanggal haraga timah dicatat.\n",
        "* `parse_date` = membuat kolom Date menjadi format date/tanggal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WML0wJO8Bb2"
      },
      "source": [
        "Menampilakn 5 data pertama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ythtDwooEH0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e6a4db-6dcd-42bd-9f69-6beb0ab7d786"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Close\n",
              "Date               \n",
              "02/01/2019  19482.5\n",
              "03/01/2019  19535.0\n",
              "04/01/2019  19585.0\n",
              "07/01/2019  19745.0\n",
              "08/01/2019  19942.5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b6db122-eac6-423f-bc2b-c7867c641967\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>02/01/2019</th>\n",
              "      <td>19482.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03/01/2019</th>\n",
              "      <td>19535.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>04/01/2019</th>\n",
              "      <td>19585.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>07/01/2019</th>\n",
              "      <td>19745.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08/01/2019</th>\n",
              "      <td>19942.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b6db122-eac6-423f-bc2b-c7867c641967')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b6db122-eac6-423f-bc2b-c7867c641967 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b6db122-eac6-423f-bc2b-c7867c641967');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-abfb3c77-bf73-4389-bcc0-d6d07b0edcc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-abfb3c77-bf73-4389-bcc0-d6d07b0edcc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-abfb3c77-bf73-4389-bcc0-d6d07b0edcc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1387,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1387,\n        \"samples\": [\n          \"27/07/2021\",\n          \"28/10/2019\",\n          \"30/09/2022\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7640.3333343472805,\n        \"min\": 13250.0,\n        \"max\": 48650.0,\n        \"num_unique_values\": 1279,\n        \"samples\": [\n          30603.0,\n          27293.0,\n          33600.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quUiueKbzgWK"
      },
      "source": [
        "## **PLOT DATA** ðŸ“ˆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q9FNVCL9bT4"
      },
      "source": [
        "- Membuat plot data dengan nama `df_plot`. Data yang digunakan yaitu variabel/ kolom `Close` saja. Agar mencegah error karena penggunaan yang tumpang tindih, dibuat dataframe baru khusus plot data yang berisi kolom `Close` saja\n",
        "\n",
        "- `figsize` merupakan ukuran dari gambar yang akan dibuat, `color` merupakan warna dari grafik yang dibuat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyOd1ZKCzjw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d644a4f7-fdfb-4d1c-c2dc-2efcb9b051ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Jumlah Total Data :  1387\n"
          ]
        }
      ],
      "source": [
        "# PLOT CLOSE PRICE\n",
        "\n",
        "# Membuat dataframe khusus plot yang hanya berisi kolom Close\n",
        "df_plot = df.copy()\n",
        "\n",
        "# Membuat plot data\n",
        "ax=df_plot.plot(figsize=(20,6), color='blue')\n",
        "\n",
        "# Menambahkan judul serta label pada sumbu-x dan sumbu-y\n",
        "plt.title('Harga Penutupan Harian Timah LME 2019 - 2023', fontsize=20, fontweight='bold') # Judul Grafik\n",
        "plt.xlabel('Date') # Label sumbu-x\n",
        "plt.ylabel('Harga Timah') # Label sumbu-y\n",
        "\n",
        "# Menampilkan plot\n",
        "plt.show()\n",
        "\n",
        "# Menampilkan jumlah total data\n",
        "print ('\\n' 'Jumlah Total Data : ', len(df_plot))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nikTJQchzjYj"
      },
      "source": [
        "## **STATISTIK DESKRIPTIF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeuptcPOz8F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f069aa-1f05-4656-8c47-2e1919ae120c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Close\n",
              "count   1387.000\n",
              "mean   25145.033\n",
              "std     7640.333\n",
              "min    13250.000\n",
              "25%    18380.000\n",
              "50%    24590.000\n",
              "75%    29496.500\n",
              "max    48650.000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9141dde9-274f-4848-896e-169f4229f38c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1387.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>25145.033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7640.333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13250.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>18380.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>24590.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29496.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>48650.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9141dde9-274f-4848-896e-169f4229f38c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9141dde9-274f-4848-896e-169f4229f38c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9141dde9-274f-4848-896e-169f4229f38c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-849f50be-3e76-435e-bca9-91f8be0d42a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-849f50be-3e76-435e-bca9-91f8be0d42a8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-849f50be-3e76-435e-bca9-91f8be0d42a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_91645282-0ea9-448e-9f6a-fb0eb9a7bfd9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('stat_descriptive')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_91645282-0ea9-448e-9f6a-fb0eb9a7bfd9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('stat_descriptive');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stat_descriptive",
              "summary": "{\n  \"name\": \"stat_descriptive\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14622.993074026717,\n        \"min\": 1387.0,\n        \"max\": 48650.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          25145.033,\n          24590.0,\n          1387.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "stat_descriptive = df.describe().round(3)\n",
        "stat_descriptive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQwWi3h71J9S"
      },
      "outputs": [],
      "source": [
        "# Menyimpan statistik deskriptif dalam bentuk excel\n",
        "stat_descriptive.to_excel('stat_descriptive.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9oEyHzGz84A"
      },
      "source": [
        "## **NORMALISASI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QizVmkOA_LuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d81710-76f6-4df4-f595-1ef7904a8140"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Close  Close_normalized\n",
              "Date                                 \n",
              "02/01/2019  19482.5          0.176059\n",
              "03/01/2019  19535.0          0.177542\n",
              "04/01/2019  19585.0          0.178955\n",
              "07/01/2019  19745.0          0.183475\n",
              "08/01/2019  19942.5          0.189054\n",
              "...             ...               ...\n",
              "24/06/2024  32746.0          0.550734\n",
              "25/06/2024  32251.0          0.536751\n",
              "26/06/2024  32012.0          0.530000\n",
              "27/06/2024  32208.0          0.535537\n",
              "28/06/2024  32739.0          0.550537\n",
              "\n",
              "[1387 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb64883e-a41d-4976-99f2-83ab24d5da9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Close_normalized</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>02/01/2019</th>\n",
              "      <td>19482.5</td>\n",
              "      <td>0.176059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>03/01/2019</th>\n",
              "      <td>19535.0</td>\n",
              "      <td>0.177542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>04/01/2019</th>\n",
              "      <td>19585.0</td>\n",
              "      <td>0.178955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>07/01/2019</th>\n",
              "      <td>19745.0</td>\n",
              "      <td>0.183475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>08/01/2019</th>\n",
              "      <td>19942.5</td>\n",
              "      <td>0.189054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24/06/2024</th>\n",
              "      <td>32746.0</td>\n",
              "      <td>0.550734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25/06/2024</th>\n",
              "      <td>32251.0</td>\n",
              "      <td>0.536751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26/06/2024</th>\n",
              "      <td>32012.0</td>\n",
              "      <td>0.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27/06/2024</th>\n",
              "      <td>32208.0</td>\n",
              "      <td>0.535537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28/06/2024</th>\n",
              "      <td>32739.0</td>\n",
              "      <td>0.550537</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1387 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb64883e-a41d-4976-99f2-83ab24d5da9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb64883e-a41d-4976-99f2-83ab24d5da9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb64883e-a41d-4976-99f2-83ab24d5da9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2b9d6f8-e5da-4aa5-aeee-a8ef4f5169ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2b9d6f8-e5da-4aa5-aeee-a8ef4f5169ca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2b9d6f8-e5da-4aa5-aeee-a8ef4f5169ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8c69f6d8-14be-4df9-8bc8-565349516f04\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_norm')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8c69f6d8-14be-4df9-8bc8-565349516f04 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_norm');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_norm",
              "summary": "{\n  \"name\": \"df_norm\",\n  \"rows\": 1387,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1387,\n        \"samples\": [\n          \"27/07/2021\",\n          \"28/10/2019\",\n          \"30/09/2022\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7640.3333343472805,\n        \"min\": 13250.0,\n        \"max\": 48650.0,\n        \"num_unique_values\": 1279,\n        \"samples\": [\n          30603.0,\n          27293.0,\n          33600.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close_normalized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2158286252640475,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1279,\n        \"samples\": [\n          0.4901977401129943,\n          0.3966949152542372,\n          0.5748587570621468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Min-Max Normalization\n",
        "df_norm = df.copy() # Membuat salinan dataframe\n",
        "scaler = MinMaxScaler() #scaler menggunakan min max scaler\n",
        "df_norm['Close_normalized'] = scaler.fit_transform(df[['Close']]) # Hasil normalisasi dari data close disimpan pada kolom Close Normalized\n",
        "# Menampilkan df_norm\n",
        "df_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Otu_8Hi9uZo"
      },
      "source": [
        "## **DATA SPLITING**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Proporsi data test dan validation\n",
        "test_size = 0.1  # 10% untuk test set\n",
        "validation_size = 0.1  # 10% dari data training untuk validation set\n",
        "\n",
        "# Membagi data menjadi data training dan data testing\n",
        "train_data, test_data = train_test_split(df_norm['Close_normalized'].values, test_size=test_size, shuffle=False)\n",
        "\n",
        "# Sekarang, bagi train_data lebih lanjut menjadi training set dan validation set\n",
        "train_data, val_data = train_test_split(train_data, test_size=validation_size, shuffle=False)\n",
        "\n",
        "# Menampilkan jumlah data training, validation, dan testing\n",
        "print('JUMLAH PEMBAGIAN DATA\\n')\n",
        "print(\"Jumlah data training:\", len(train_data), \"dari\", df_norm.index[0], \"hingga\", df_norm.index[len(train_data)-1])\n",
        "print(\"Jumlah data validation:\", len(val_data), \"dari\", df_norm.index[len(train_data)], \"hingga\", df_norm.index[len(train_data) + len(val_data)-1])\n",
        "print(\"Jumlah data testing:\", len(test_data), \"dari\", df_norm.index[len(train_data) + len(val_data)], \"hingga\", df_norm.index[len(df_norm)-1])\n",
        "\n",
        "# Jumlah timesteps\n",
        "time_step = 20\n",
        "\n",
        "# Membagi data training menjadi data input dan data target\n",
        "X_train, y_train = [], []\n",
        "for i in range(time_step, len(train_data)):\n",
        "    X_train.append(train_data[i-time_step:i])\n",
        "    y_train.append(train_data[i])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "# Membagi data validation menjadi data input dan data target\n",
        "X_val, y_val = [], []\n",
        "for i in range(time_step, len(val_data)):\n",
        "    X_val.append(val_data[i-time_step:i])\n",
        "    y_val.append(val_data[i])\n",
        "X_val, y_val = np.array(X_val), np.array(y_val)\n",
        "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n",
        "\n",
        "# Membagi data testing menjadi data input dan data target\n",
        "X_test, y_test = [], []\n",
        "for i in range(time_step, len(test_data)):\n",
        "    X_test.append(test_data[i-time_step:i])\n",
        "    y_test.append(test_data[i])\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Jika diperlukan reshape data test agar sesuai dengan format model\n",
        "if len(X_test.shape) < 2:\n",
        "    X_test = np.expand_dims(X_test, axis=1)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Data training, validation, dan test siap digunakan\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRrmUbjfZyfj",
        "outputId": "17efc9c8-2dd0-4189-f6ea-6781e4e8eb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JUMLAH PEMBAGIAN DATA\n",
            "\n",
            "Jumlah data training: 1123 dari 02/01/2019 hingga 14/06/2023\n",
            "Jumlah data validation: 125 dari 15/06/2023 hingga 07/12/2023\n",
            "Jumlah data testing: 139 dari 08/12/2023 hingga 28/06/2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWJE7KR7qi5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f70c63-2eb7-4c16-acbf-77e4da851f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (1001, 20, 1)\n",
            "y_train:  (1001,)\n",
            "X_test:  (107, 20, 1)\n",
            "y_test (107,)\n",
            "X_val:  (94, 20, 1)\n",
            "y_val:  (94,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)\n",
        "print(\"X_val: \", X_val.shape)\n",
        "print(\"y_val: \", y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg90j_FYL1Vx"
      },
      "source": [
        "## **MODEL BUILDING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeLkhzIA2Sqe"
      },
      "source": [
        "> ## **Pemodelan GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hBmZDrL2byc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Random seed : agar nilai random tidak berubah\n",
        "tf.random.set_seed(123)\n",
        "random.seed(123)\n",
        "\n",
        "# FUNGSI UNTUK MEMBUAT MODEL GRU\n",
        "# Membangun model NN dan Mendefinisikan hyperparameter\n",
        "def create_model(units, learning_rate, epochs, batch_size, optimizer):\n",
        "    # Membuat model sequential\n",
        "    model = Sequential()\n",
        "    # Layer GRU pertama\n",
        "    model.add(GRU(units=units, input_shape=(X_train.shape[1], 1), activation='tanh'))\n",
        "    # Layer Dropout\n",
        "    model.add(Dropout(0.3)) # Dropout 0.3 artinya 30% unit dinonaktifkan secara acak selama pembelajaran\n",
        "    # Layer Output tunggal\n",
        "    model.add(Dense(units=1)) # Layer output terdiri atas 1 unit/neuron\n",
        "\n",
        "   #OPTIMIZER\n",
        "    if optimizer == 'RMSprop':\n",
        "        model.compile(loss='mean_squared_error', optimizer=RMSprop(learning_rate=learning_rate), metrics='mean_absolute_percentage_error')\n",
        "    else:\n",
        "        model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=learning_rate), metrics='mean_absolute_percentage_error')\n",
        "\n",
        "    return model # mengembalikan objek model yang telah dikonfigurasi sehingga bisa digunakan di tempat lain dalam kode.\n",
        "    # Sehingga bisa memanggil fungsi tersebut beberapa kali dengan parameter yang berbeda untuk membuat dan melatih beberapa\n",
        "    # Model dengan konfigurasi hyperparameter yang berbeda.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuUZkuvF2laV"
      },
      "source": [
        "> ## **Tuning Hyperparameter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e0OKiGLZIETN",
        "outputId": "484a8983-c75e-47bb-d439-64e32051dbee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0177 - mean_absolute_percentage_error: 70667.6172\n",
            "Epoch 1: val_loss improved from inf to 0.00024, saving model to best_model.h5\n",
            "35/35 [==============================] - 5s 28ms/step - loss: 0.0168 - mean_absolute_percentage_error: 65608.3047 - val_loss: 2.4349e-04 - val_mean_absolute_percentage_error: 3.3924\n",
            "Epoch 2/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0066 - mean_absolute_percentage_error: 17802.0508\n",
            "Epoch 2: val_loss did not improve from 0.00024\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0063 - mean_absolute_percentage_error: 16012.3242 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 9.3788\n",
            "Epoch 3/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0053 - mean_absolute_percentage_error: 44946.7891\n",
            "Epoch 3: val_loss improved from 0.00024 to 0.00017, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0053 - mean_absolute_percentage_error: 44335.7422 - val_loss: 1.7254e-04 - val_mean_absolute_percentage_error: 3.0347\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_percentage_error: 81724.2969\n",
            "Epoch 4: val_loss did not improve from 0.00017\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0044 - mean_absolute_percentage_error: 81724.2969 - val_loss: 8.4067e-04 - val_mean_absolute_percentage_error: 7.6931\n",
            "Epoch 5/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0038 - mean_absolute_percentage_error: 22142.2793\n",
            "Epoch 5: val_loss did not improve from 0.00017\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0037 - mean_absolute_percentage_error: 20557.5762 - val_loss: 1.8366e-04 - val_mean_absolute_percentage_error: 3.1750\n",
            "Epoch 6/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 44689.1875\n",
            "Epoch 6: val_loss improved from 0.00017 to 0.00015, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0031 - mean_absolute_percentage_error: 44081.5508 - val_loss: 1.4857e-04 - val_mean_absolute_percentage_error: 2.7594\n",
            "Epoch 7/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 35932.5781\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0028 - mean_absolute_percentage_error: 34402.3672 - val_loss: 2.0360e-04 - val_mean_absolute_percentage_error: 3.1680\n",
            "Epoch 8/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 20059.6387\n",
            "Epoch 8: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0031 - mean_absolute_percentage_error: 18044.4180 - val_loss: 1.8861e-04 - val_mean_absolute_percentage_error: 3.2844\n",
            "Epoch 9/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 128926.4531\n",
            "Epoch 9: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0031 - mean_absolute_percentage_error: 127173.3984 - val_loss: 0.0010 - val_mean_absolute_percentage_error: 8.4279\n",
            "Epoch 9: early stopping\n",
            "Train Loss Terendah:  0.0028277526143938303\n",
            "Epoch Stop:  6\n",
            "Val Loss Terendah:  0.00014856908819638193\n",
            "Epoch Val Loss Stop:  6\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0256 - mean_absolute_percentage_error: 62173.0234\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 3s 30ms/step - loss: 0.0234 - mean_absolute_percentage_error: 55918.4180 - val_loss: 2.2221e-04 - val_mean_absolute_percentage_error: 3.2502\n",
            "Epoch 2/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0043 - mean_absolute_percentage_error: 45531.8281\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0043 - mean_absolute_percentage_error: 42272.0312 - val_loss: 1.8054e-04 - val_mean_absolute_percentage_error: 3.0127\n",
            "Epoch 3/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 1252.8608\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0031 - mean_absolute_percentage_error: 1236.0507 - val_loss: 1.5373e-04 - val_mean_absolute_percentage_error: 2.8521\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 30668.3730\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0027 - mean_absolute_percentage_error: 30668.3730 - val_loss: 1.5609e-04 - val_mean_absolute_percentage_error: 2.8196\n",
            "Epoch 5/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 38752.5742\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0026 - mean_absolute_percentage_error: 37101.8555 - val_loss: 1.6554e-04 - val_mean_absolute_percentage_error: 3.0584\n",
            "Epoch 6/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 40202.3828\n",
            "Epoch 6: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0026 - mean_absolute_percentage_error: 39655.7812 - val_loss: 2.9994e-04 - val_mean_absolute_percentage_error: 3.8698\n",
            "Epoch 6: early stopping\n",
            "Train Loss Terendah:  0.0025703394785523415\n",
            "Epoch Stop:  5\n",
            "Val Loss Terendah:  0.00015372992493212223\n",
            "Epoch Val Loss Stop:  3\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0089 - mean_absolute_percentage_error: 34398.4062\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 3s 29ms/step - loss: 0.0089 - mean_absolute_percentage_error: 34398.4062 - val_loss: 8.3278e-04 - val_mean_absolute_percentage_error: 7.6701\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 12122.4834\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0031 - mean_absolute_percentage_error: 12122.4834 - val_loss: 1.5191e-04 - val_mean_absolute_percentage_error: 2.7382\n",
            "Epoch 3/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 34491.7891\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0025 - mean_absolute_percentage_error: 34022.8281 - val_loss: 6.1206e-04 - val_mean_absolute_percentage_error: 6.5191\n",
            "Epoch 4/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0016 - mean_absolute_percentage_error: 16004.6719\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0016 - mean_absolute_percentage_error: 15323.2275 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 10.1052\n",
            "Epoch 5/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0019 - mean_absolute_percentage_error: 18352.4922\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0019 - mean_absolute_percentage_error: 17038.9023 - val_loss: 4.3450e-04 - val_mean_absolute_percentage_error: 5.4106\n",
            "Epoch 5: early stopping\n",
            "Train Loss Terendah:  0.0015772052574902773\n",
            "Epoch Stop:  3\n",
            "Val Loss Terendah:  0.0001519051584182307\n",
            "Epoch Val Loss Stop:  2\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1032 - mean_absolute_percentage_error: 105697.7344\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 3s 28ms/step - loss: 0.0960 - mean_absolute_percentage_error: 95070.4609 - val_loss: 8.8229e-04 - val_mean_absolute_percentage_error: 6.7363\n",
            "Epoch 2/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0325 - mean_absolute_percentage_error: 214443.2812\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0323 - mean_absolute_percentage_error: 199091.7656 - val_loss: 6.9456e-04 - val_mean_absolute_percentage_error: 5.4720\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0221 - mean_absolute_percentage_error: 124198.6016\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0221 - mean_absolute_percentage_error: 124198.6016 - val_loss: 4.0694e-04 - val_mean_absolute_percentage_error: 4.5248\n",
            "Epoch 4/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0141 - mean_absolute_percentage_error: 49233.2383\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0141 - mean_absolute_percentage_error: 48564.1055 - val_loss: 5.5177e-04 - val_mean_absolute_percentage_error: 5.8399\n",
            "Epoch 5/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0106 - mean_absolute_percentage_error: 52615.9297\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0106 - mean_absolute_percentage_error: 50374.7617 - val_loss: 3.7931e-04 - val_mean_absolute_percentage_error: 4.7777\n",
            "Epoch 6/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0104 - mean_absolute_percentage_error: 22785.8223\n",
            "Epoch 6: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0104 - mean_absolute_percentage_error: 22785.8223 - val_loss: 3.3749e-04 - val_mean_absolute_percentage_error: 4.4442\n",
            "Epoch 7/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0088 - mean_absolute_percentage_error: 50552.0586\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0092 - mean_absolute_percentage_error: 48399.2148 - val_loss: 2.9238e-04 - val_mean_absolute_percentage_error: 4.0366\n",
            "Epoch 8/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0085 - mean_absolute_percentage_error: 76383.4766\n",
            "Epoch 8: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0085 - mean_absolute_percentage_error: 68700.0312 - val_loss: 2.7866e-04 - val_mean_absolute_percentage_error: 3.8630\n",
            "Epoch 9/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0079 - mean_absolute_percentage_error: 19681.0977\n",
            "Epoch 9: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0079 - mean_absolute_percentage_error: 19413.6777 - val_loss: 6.6408e-04 - val_mean_absolute_percentage_error: 6.5612\n",
            "Epoch 10/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_percentage_error: 22575.6113\n",
            "Epoch 10: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0077 - mean_absolute_percentage_error: 22575.6113 - val_loss: 2.6882e-04 - val_mean_absolute_percentage_error: 3.7788\n",
            "Epoch 11/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0069 - mean_absolute_percentage_error: 20.7585\n",
            "Epoch 11: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0068 - mean_absolute_percentage_error: 25362.2324 - val_loss: 3.2525e-04 - val_mean_absolute_percentage_error: 4.3397\n",
            "Epoch 12/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0064 - mean_absolute_percentage_error: 131017.0078\n",
            "Epoch 12: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0064 - mean_absolute_percentage_error: 131017.0078 - val_loss: 2.6831e-04 - val_mean_absolute_percentage_error: 3.6811\n",
            "Epoch 13/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0061 - mean_absolute_percentage_error: 84830.5312\n",
            "Epoch 13: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 84830.5312 - val_loss: 2.5896e-04 - val_mean_absolute_percentage_error: 3.7031\n",
            "Epoch 14/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0065 - mean_absolute_percentage_error: 48816.4844\n",
            "Epoch 14: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0065 - mean_absolute_percentage_error: 48152.9258 - val_loss: 2.5290e-04 - val_mean_absolute_percentage_error: 3.6650\n",
            "Epoch 15/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0054 - mean_absolute_percentage_error: 11521.5811\n",
            "Epoch 15: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0054 - mean_absolute_percentage_error: 10363.8369 - val_loss: 4.2028e-04 - val_mean_absolute_percentage_error: 5.0888\n",
            "Epoch 16/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0051 - mean_absolute_percentage_error: 37925.7969\n",
            "Epoch 16: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0051 - mean_absolute_percentage_error: 36310.5273 - val_loss: 7.7070e-04 - val_mean_absolute_percentage_error: 7.1109\n",
            "Epoch 17/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0061 - mean_absolute_percentage_error: 70926.3906\n",
            "Epoch 17: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0058 - mean_absolute_percentage_error: 63790.3906 - val_loss: 4.7996e-04 - val_mean_absolute_percentage_error: 5.5203\n",
            "Epoch 17: early stopping\n",
            "Train Loss Terendah:  0.005087966565042734\n",
            "Epoch Stop:  15\n",
            "Val Loss Terendah:  0.00025289709446951747\n",
            "Epoch Val Loss Stop:  14\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0595 - mean_absolute_percentage_error: 142398.8594\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 3s 31ms/step - loss: 0.0595 - mean_absolute_percentage_error: 142398.8594 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 18.1342\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0163 - mean_absolute_percentage_error: 78693.0469\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0163 - mean_absolute_percentage_error: 78693.0469 - val_loss: 3.6348e-04 - val_mean_absolute_percentage_error: 4.1965\n",
            "Epoch 3/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0070 - mean_absolute_percentage_error: 45622.0156\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0069 - mean_absolute_percentage_error: 45001.8164 - val_loss: 5.1217e-04 - val_mean_absolute_percentage_error: 5.6787\n",
            "Epoch 4/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0059 - mean_absolute_percentage_error: 19029.6133\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_absolute_percentage_error: 17116.8730 - val_loss: 2.8491e-04 - val_mean_absolute_percentage_error: 3.8372\n",
            "Epoch 5/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0057 - mean_absolute_percentage_error: 24129.1953\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0056 - mean_absolute_percentage_error: 23101.7148 - val_loss: 4.1915e-04 - val_mean_absolute_percentage_error: 5.0502\n",
            "Epoch 6/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0046 - mean_absolute_percentage_error: 12138.2842\n",
            "Epoch 6: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0049 - mean_absolute_percentage_error: 11269.9316 - val_loss: 2.8510e-04 - val_mean_absolute_percentage_error: 3.9340\n",
            "Epoch 7/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0050 - mean_absolute_percentage_error: 54472.9023\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0048 - mean_absolute_percentage_error: 50573.2070 - val_loss: 3.8230e-04 - val_mean_absolute_percentage_error: 4.7911\n",
            "Epoch 7: early stopping\n",
            "Train Loss Terendah:  0.004839087370783091\n",
            "Epoch Stop:  6\n",
            "Val Loss Terendah:  0.00028490746626630425\n",
            "Epoch Val Loss Stop:  4\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0280 - mean_absolute_percentage_error: 209048.1562\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 4s 29ms/step - loss: 0.0270 - mean_absolute_percentage_error: 200141.9219 - val_loss: 5.7893e-04 - val_mean_absolute_percentage_error: 5.8227\n",
            "Epoch 2/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0050 - mean_absolute_percentage_error: 11117.4082\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0050 - mean_absolute_percentage_error: 10644.3477 - val_loss: 2.7621e-04 - val_mean_absolute_percentage_error: 3.8786\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0039 - mean_absolute_percentage_error: 19969.1152\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0039 - mean_absolute_percentage_error: 19969.1152 - val_loss: 2.5260e-04 - val_mean_absolute_percentage_error: 3.6937\n",
            "Epoch 4/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 27692.5547\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0029 - mean_absolute_percentage_error: 25710.0000 - val_loss: 2.4128e-04 - val_mean_absolute_percentage_error: 3.4751\n",
            "Epoch 5/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 30123.2539\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0029 - mean_absolute_percentage_error: 27966.5879 - val_loss: 2.6093e-04 - val_mean_absolute_percentage_error: 3.5498\n",
            "Epoch 6/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 31795.7910\n",
            "Epoch 6: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0026 - mean_absolute_percentage_error: 31363.5059 - val_loss: 3.9229e-04 - val_mean_absolute_percentage_error: 4.9370\n",
            "Epoch 7/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 3962.5840\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0028 - mean_absolute_percentage_error: 3795.2153 - val_loss: 3.4858e-04 - val_mean_absolute_percentage_error: 4.1348\n",
            "Epoch 7: early stopping\n",
            "Train Loss Terendah:  0.002575972583144903\n",
            "Epoch Stop:  5\n",
            "Val Loss Terendah:  0.00024127862707246095\n",
            "Epoch Val Loss Stop:  4\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0891 - mean_absolute_percentage_error: 19183.0918\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 3s 32ms/step - loss: 0.0856 - mean_absolute_percentage_error: 17812.4688 - val_loss: 0.0480 - val_mean_absolute_percentage_error: 61.6685\n",
            "Epoch 2/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0724 - mean_absolute_percentage_error: 61658.4141\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0715 - mean_absolute_percentage_error: 57246.5195 - val_loss: 0.0316 - val_mean_absolute_percentage_error: 49.7059\n",
            "Epoch 3/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0566 - mean_absolute_percentage_error: 90238.0547\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0564 - mean_absolute_percentage_error: 89011.3750 - val_loss: 0.0197 - val_mean_absolute_percentage_error: 38.8296\n",
            "Epoch 4/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0425 - mean_absolute_percentage_error: 79733.3125\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0419 - mean_absolute_percentage_error: 76337.5469 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 29.5405\n",
            "Epoch 5/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0343 - mean_absolute_percentage_error: 105884.5625\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0342 - mean_absolute_percentage_error: 104445.0547 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 21.5446\n",
            "Epoch 6/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0325 - mean_absolute_percentage_error: 121980.1406\n",
            "Epoch 6: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0325 - mean_absolute_percentage_error: 121980.1406 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 15.1701\n",
            "Epoch 7/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0271 - mean_absolute_percentage_error: 107517.9141\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0269 - mean_absolute_percentage_error: 96705.8047 - val_loss: 0.0020 - val_mean_absolute_percentage_error: 10.5440\n",
            "Epoch 8/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0299 - mean_absolute_percentage_error: 169307.5625\n",
            "Epoch 8: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0294 - mean_absolute_percentage_error: 157185.5312 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 7.4907\n",
            "Epoch 9/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0281 - mean_absolute_percentage_error: 245914.9219\n",
            "Epoch 9: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0273 - mean_absolute_percentage_error: 221173.1094 - val_loss: 7.2702e-04 - val_mean_absolute_percentage_error: 5.7635\n",
            "Epoch 10/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0209 - mean_absolute_percentage_error: 59.7348\n",
            "Epoch 10: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0207 - mean_absolute_percentage_error: 138655.7188 - val_loss: 6.2684e-04 - val_mean_absolute_percentage_error: 5.2949\n",
            "Epoch 11/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0223 - mean_absolute_percentage_error: 123463.6328\n",
            "Epoch 11: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0223 - mean_absolute_percentage_error: 121789.3594 - val_loss: 6.3293e-04 - val_mean_absolute_percentage_error: 5.4149\n",
            "Epoch 12/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0193 - mean_absolute_percentage_error: 132576.2656\n",
            "Epoch 12: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0196 - mean_absolute_percentage_error: 130773.8594 - val_loss: 5.8482e-04 - val_mean_absolute_percentage_error: 5.2115\n",
            "Epoch 13/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0205 - mean_absolute_percentage_error: 121944.0469\n",
            "Epoch 13: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0205 - mean_absolute_percentage_error: 121944.0469 - val_loss: 5.1375e-04 - val_mean_absolute_percentage_error: 4.8508\n",
            "Epoch 14/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0192 - mean_absolute_percentage_error: 169414.4062\n",
            "Epoch 14: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0192 - mean_absolute_percentage_error: 167111.2656 - val_loss: 5.1732e-04 - val_mean_absolute_percentage_error: 4.9609\n",
            "Epoch 15/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0187 - mean_absolute_percentage_error: 120392.1641\n",
            "Epoch 15: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0187 - mean_absolute_percentage_error: 120392.1641 - val_loss: 4.8324e-04 - val_mean_absolute_percentage_error: 4.8206\n",
            "Epoch 16/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0161 - mean_absolute_percentage_error: 109045.4141\n",
            "Epoch 16: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0161 - mean_absolute_percentage_error: 109045.4141 - val_loss: 5.5609e-04 - val_mean_absolute_percentage_error: 5.3923\n",
            "Epoch 17/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0171 - mean_absolute_percentage_error: 106447.8828\n",
            "Epoch 17: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0171 - mean_absolute_percentage_error: 106447.8828 - val_loss: 5.4064e-04 - val_mean_absolute_percentage_error: 5.3675\n",
            "Epoch 18/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0177 - mean_absolute_percentage_error: 69971.0156\n",
            "Epoch 18: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0177 - mean_absolute_percentage_error: 69971.0156 - val_loss: 3.5242e-04 - val_mean_absolute_percentage_error: 4.0805\n",
            "Epoch 19/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0147 - mean_absolute_percentage_error: 72523.8047\n",
            "Epoch 19: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0145 - mean_absolute_percentage_error: 69434.8438 - val_loss: 3.5588e-04 - val_mean_absolute_percentage_error: 4.1787\n",
            "Epoch 20/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0145 - mean_absolute_percentage_error: 100592.7734\n",
            "Epoch 20: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0145 - mean_absolute_percentage_error: 100592.7734 - val_loss: 3.2078e-04 - val_mean_absolute_percentage_error: 3.9532\n",
            "Epoch 21/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0153 - mean_absolute_percentage_error: 45611.6641\n",
            "Epoch 21: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0153 - mean_absolute_percentage_error: 43670.0625 - val_loss: 3.1532e-04 - val_mean_absolute_percentage_error: 3.9755\n",
            "Epoch 22/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0142 - mean_absolute_percentage_error: 116668.3281\n",
            "Epoch 22: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0141 - mean_absolute_percentage_error: 108314.2812 - val_loss: 3.6748e-04 - val_mean_absolute_percentage_error: 4.4654\n",
            "Epoch 23/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0116 - mean_absolute_percentage_error: 75303.1562\n",
            "Epoch 23: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0114 - mean_absolute_percentage_error: 72095.2578 - val_loss: 3.6974e-04 - val_mean_absolute_percentage_error: 4.5248\n",
            "Epoch 24/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0127 - mean_absolute_percentage_error: 73046.2422\n",
            "Epoch 24: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0127 - mean_absolute_percentage_error: 65698.7656 - val_loss: 3.5315e-04 - val_mean_absolute_percentage_error: 4.4432\n",
            "Epoch 24: early stopping\n",
            "Train Loss Terendah:  0.011400519870221615\n",
            "Epoch Stop:  22\n",
            "Val Loss Terendah:  0.00031532254070043564\n",
            "Epoch Val Loss Stop:  21\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1048 - mean_absolute_percentage_error: 18066.2090\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 6s 103ms/step - loss: 0.1031 - mean_absolute_percentage_error: 17298.6523 - val_loss: 0.0590 - val_mean_absolute_percentage_error: 68.3844\n",
            "Epoch 2/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0718 - mean_absolute_percentage_error: 54797.5352\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0718 - mean_absolute_percentage_error: 54797.5352 - val_loss: 0.0346 - val_mean_absolute_percentage_error: 51.8985\n",
            "Epoch 3/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0497 - mean_absolute_percentage_error: 87473.0547\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0494 - mean_absolute_percentage_error: 78673.9453 - val_loss: 0.0179 - val_mean_absolute_percentage_error: 36.7705\n",
            "Epoch 4/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0359 - mean_absolute_percentage_error: 91663.8828 \n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0359 - mean_absolute_percentage_error: 91663.8828 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 22.9438\n",
            "Epoch 5/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0262 - mean_absolute_percentage_error: 154499.4375\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0262 - mean_absolute_percentage_error: 143437.3906 - val_loss: 0.0025 - val_mean_absolute_percentage_error: 12.0333\n",
            "Epoch 6/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0198 - mean_absolute_percentage_error: 148770.8438\n",
            "Epoch 6: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0210 - mean_absolute_percentage_error: 133804.3750 - val_loss: 8.9697e-04 - val_mean_absolute_percentage_error: 6.4850\n",
            "Epoch 7/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0181 - mean_absolute_percentage_error: 170477.6719\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0183 - mean_absolute_percentage_error: 158275.0156 - val_loss: 5.1771e-04 - val_mean_absolute_percentage_error: 4.7115\n",
            "Epoch 8/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0182 - mean_absolute_percentage_error: 222900.8438\n",
            "Epoch 8: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0182 - mean_absolute_percentage_error: 200479.2188 - val_loss: 4.8096e-04 - val_mean_absolute_percentage_error: 4.8681\n",
            "Epoch 9/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0149 - mean_absolute_percentage_error: 140958.2500\n",
            "Epoch 9: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0149 - mean_absolute_percentage_error: 134954.0156 - val_loss: 4.4811e-04 - val_mean_absolute_percentage_error: 4.6772\n",
            "Epoch 10/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0152 - mean_absolute_percentage_error: 141582.8906\n",
            "Epoch 10: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0152 - mean_absolute_percentage_error: 141582.8906 - val_loss: 4.3462e-04 - val_mean_absolute_percentage_error: 4.6495\n",
            "Epoch 11/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0134 - mean_absolute_percentage_error: 50.9113\n",
            "Epoch 11: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0132 - mean_absolute_percentage_error: 96249.8516 - val_loss: 4.3755e-04 - val_mean_absolute_percentage_error: 4.7375\n",
            "Epoch 12/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0116 - mean_absolute_percentage_error: 117819.4219\n",
            "Epoch 12: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0115 - mean_absolute_percentage_error: 105967.5547 - val_loss: 3.6812e-04 - val_mean_absolute_percentage_error: 4.2175\n",
            "Epoch 13/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0109 - mean_absolute_percentage_error: 162471.6250\n",
            "Epoch 13: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0109 - mean_absolute_percentage_error: 146126.0156 - val_loss: 3.3742e-04 - val_mean_absolute_percentage_error: 4.0073\n",
            "Epoch 14/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0087 - mean_absolute_percentage_error: 88992.3203 \n",
            "Epoch 14: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0088 - mean_absolute_percentage_error: 85201.6719 - val_loss: 3.2507e-04 - val_mean_absolute_percentage_error: 3.9883\n",
            "Epoch 15/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0092 - mean_absolute_percentage_error: 114356.2891\n",
            "Epoch 15: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0090 - mean_absolute_percentage_error: 106168.1484 - val_loss: 3.0643e-04 - val_mean_absolute_percentage_error: 3.8984\n",
            "Epoch 16/50\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0082 - mean_absolute_percentage_error: 80081.0625\n",
            "Epoch 16: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0083 - mean_absolute_percentage_error: 72025.3594 - val_loss: 2.9987e-04 - val_mean_absolute_percentage_error: 3.9070\n",
            "Epoch 17/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0077 - mean_absolute_percentage_error: 81245.1875\n",
            "Epoch 17: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0077 - mean_absolute_percentage_error: 81245.1875 - val_loss: 2.9196e-04 - val_mean_absolute_percentage_error: 3.8504\n",
            "Epoch 18/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0074 - mean_absolute_percentage_error: 81906.1172\n",
            "Epoch 18: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0074 - mean_absolute_percentage_error: 80792.4688 - val_loss: 3.0266e-04 - val_mean_absolute_percentage_error: 4.0323\n",
            "Epoch 19/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0072 - mean_absolute_percentage_error: 59134.9258\n",
            "Epoch 19: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0071 - mean_absolute_percentage_error: 58331.0195 - val_loss: 4.3025e-04 - val_mean_absolute_percentage_error: 5.1012\n",
            "Epoch 20/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0070 - mean_absolute_percentage_error: 48385.4883\n",
            "Epoch 20: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 0.0070 - mean_absolute_percentage_error: 46324.6133 - val_loss: 5.1473e-04 - val_mean_absolute_percentage_error: 5.6452\n",
            "Epoch 20: early stopping\n",
            "Train Loss Terendah:  0.006972817238420248\n",
            "Epoch Stop:  19\n",
            "Val Loss Terendah:  0.00029196133255027235\n",
            "Epoch Val Loss Stop:  17\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1350 - mean_absolute_percentage_error: 23906.5430\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 4s 34ms/step - loss: 0.1311 - mean_absolute_percentage_error: 22198.3965 - val_loss: 0.0649 - val_mean_absolute_percentage_error: 71.5578\n",
            "Epoch 2/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0734 - mean_absolute_percentage_error: 119540.8438\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0726 - mean_absolute_percentage_error: 114448.8438 - val_loss: 0.0236 - val_mean_absolute_percentage_error: 42.3867\n",
            "Epoch 3/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0370 - mean_absolute_percentage_error: 151794.1719\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0370 - mean_absolute_percentage_error: 151794.1719 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 16.5994\n",
            "Epoch 4/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0202 - mean_absolute_percentage_error: 163389.0625\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0201 - mean_absolute_percentage_error: 151691.3594 - val_loss: 5.7191e-04 - val_mean_absolute_percentage_error: 5.0441\n",
            "Epoch 5/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0151 - mean_absolute_percentage_error: 207006.3125\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0151 - mean_absolute_percentage_error: 207006.3125 - val_loss: 7.3193e-04 - val_mean_absolute_percentage_error: 6.6262\n",
            "Epoch 6/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0136 - mean_absolute_percentage_error: 183523.7969\n",
            "Epoch 6: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0134 - mean_absolute_percentage_error: 170382.1250 - val_loss: 5.7933e-04 - val_mean_absolute_percentage_error: 5.6356\n",
            "Epoch 7/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0105 - mean_absolute_percentage_error: 122585.8516\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0105 - mean_absolute_percentage_error: 122585.8516 - val_loss: 4.7524e-04 - val_mean_absolute_percentage_error: 4.9065\n",
            "Epoch 8/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0093 - mean_absolute_percentage_error: 123789.2266\n",
            "Epoch 8: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0090 - mean_absolute_percentage_error: 114925.9219 - val_loss: 5.6479e-04 - val_mean_absolute_percentage_error: 5.4866\n",
            "Epoch 9/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0076 - mean_absolute_percentage_error: 91714.6484 \n",
            "Epoch 9: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0076 - mean_absolute_percentage_error: 91714.6484 - val_loss: 4.5366e-04 - val_mean_absolute_percentage_error: 4.7498\n",
            "Epoch 10/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0056 - mean_absolute_percentage_error: 114462.1484\n",
            "Epoch 10: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0057 - mean_absolute_percentage_error: 112905.9688 - val_loss: 3.3769e-04 - val_mean_absolute_percentage_error: 4.0984\n",
            "Epoch 11/50\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0060 - mean_absolute_percentage_error: 27.3100\n",
            "Epoch 11: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0059 - mean_absolute_percentage_error: 67835.2109 - val_loss: 3.4674e-04 - val_mean_absolute_percentage_error: 4.0934\n",
            "Epoch 12/50\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0050 - mean_absolute_percentage_error: 71372.3281\n",
            "Epoch 12: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0050 - mean_absolute_percentage_error: 70401.9297 - val_loss: 3.3456e-04 - val_mean_absolute_percentage_error: 4.2251\n",
            "Epoch 13/50\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0047 - mean_absolute_percentage_error: 69055.4297\n",
            "Epoch 13: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0046 - mean_absolute_percentage_error: 64111.2148 - val_loss: 3.7506e-04 - val_mean_absolute_percentage_error: 4.6831\n",
            "Epoch 14/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_percentage_error: 60867.0469\n",
            "Epoch 14: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0048 - mean_absolute_percentage_error: 60867.0469 - val_loss: 3.6020e-04 - val_mean_absolute_percentage_error: 4.5615\n",
            "Epoch 15/50\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0043 - mean_absolute_percentage_error: 60651.5195\n",
            "Epoch 15: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0043 - mean_absolute_percentage_error: 60651.5195 - val_loss: 3.5255e-04 - val_mean_absolute_percentage_error: 4.4944\n",
            "Epoch 15: early stopping\n",
            "Train Loss Terendah:  0.0043028779327869415\n",
            "Epoch Stop:  14\n",
            "Val Loss Terendah:  0.0003345584264025092\n",
            "Epoch Val Loss Stop:  12\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0205 - mean_absolute_percentage_error: 36627.7617\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 4s 29ms/step - loss: 0.0198 - mean_absolute_percentage_error: 35067.8594 - val_loss: 2.3777e-04 - val_mean_absolute_percentage_error: 3.6596\n",
            "Epoch 2/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0065 - mean_absolute_percentage_error: 24126.5938\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0065 - mean_absolute_percentage_error: 23798.8145 - val_loss: 2.5816e-04 - val_mean_absolute_percentage_error: 3.8848\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0054 - mean_absolute_percentage_error: 105313.2734\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0054 - mean_absolute_percentage_error: 105313.2734 - val_loss: 8.4684e-04 - val_mean_absolute_percentage_error: 7.7328\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_percentage_error: 24424.7832\n",
            "Epoch 4: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0047 - mean_absolute_percentage_error: 24424.7832 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 9.3902\n",
            "Epoch 4: early stopping\n",
            "Train Loss Terendah:  0.004668080247938633\n",
            "Epoch Stop:  3\n",
            "Val Loss Terendah:  0.00023777213937137276\n",
            "Epoch Val Loss Stop:  1\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0218 - mean_absolute_percentage_error: 43962.3750\n",
            "Epoch 1: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 3s 28ms/step - loss: 0.0202 - mean_absolute_percentage_error: 39540.8398 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 11.7970\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_percentage_error: 57429.2891\n",
            "Epoch 2: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0048 - mean_absolute_percentage_error: 57429.2891 - val_loss: 1.8563e-04 - val_mean_absolute_percentage_error: 2.9882\n",
            "Epoch 3/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0037 - mean_absolute_percentage_error: 17218.4590\n",
            "Epoch 3: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0037 - mean_absolute_percentage_error: 16485.2051 - val_loss: 1.4876e-04 - val_mean_absolute_percentage_error: 2.7055\n",
            "Epoch 4/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 81077.7500\n",
            "Epoch 4: val_loss improved from 0.00015 to 0.00014, saving model to best_model.h5\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0026 - mean_absolute_percentage_error: 77623.4062 - val_loss: 1.4315e-04 - val_mean_absolute_percentage_error: 2.7901\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 53094.4023\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0025 - mean_absolute_percentage_error: 53094.4023 - val_loss: 5.3313e-04 - val_mean_absolute_percentage_error: 5.8224\n",
            "Epoch 6/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 37024.0195\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0026 - mean_absolute_percentage_error: 36520.6875 - val_loss: 2.4128e-04 - val_mean_absolute_percentage_error: 3.4619\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0021 - mean_absolute_percentage_error: 11006.5449\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0021 - mean_absolute_percentage_error: 11006.5449 - val_loss: 1.5598e-04 - val_mean_absolute_percentage_error: 2.7587\n",
            "Epoch 7: early stopping\n",
            "Train Loss Terendah:  0.0020624157041311264\n",
            "Epoch Stop:  6\n",
            "Val Loss Terendah:  0.00014314847066998482\n",
            "Epoch Val Loss Stop:  4\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0133 - mean_absolute_percentage_error: 17860.1758\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 4s 30ms/step - loss: 0.0131 - mean_absolute_percentage_error: 17617.4141 - val_loss: 1.5899e-04 - val_mean_absolute_percentage_error: 2.9036\n",
            "Epoch 2/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 6921.6123\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0028 - mean_absolute_percentage_error: 6827.6177 - val_loss: 1.5168e-04 - val_mean_absolute_percentage_error: 2.8667\n",
            "Epoch 3/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 3008.2512\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0023 - mean_absolute_percentage_error: 2793.5337 - val_loss: 5.8605e-04 - val_mean_absolute_percentage_error: 6.3473\n",
            "Epoch 4/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0017 - mean_absolute_percentage_error: 25045.9512\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0017 - mean_absolute_percentage_error: 24705.4355 - val_loss: 2.8665e-04 - val_mean_absolute_percentage_error: 3.8483\n",
            "Epoch 5/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0018 - mean_absolute_percentage_error: 21477.0215\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0018 - mean_absolute_percentage_error: 20562.3770 - val_loss: 5.6838e-04 - val_mean_absolute_percentage_error: 6.2610\n",
            "Epoch 5: early stopping\n",
            "Train Loss Terendah:  0.0017354373121634126\n",
            "Epoch Stop:  3\n",
            "Val Loss Terendah:  0.0001516775955678895\n",
            "Epoch Val Loss Stop:  2\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0543 - mean_absolute_percentage_error: 85563.3516\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 3s 31ms/step - loss: 0.0534 - mean_absolute_percentage_error: 81921.4141 - val_loss: 8.1727e-04 - val_mean_absolute_percentage_error: 7.3608\n",
            "Epoch 2/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0224 - mean_absolute_percentage_error: 126252.0938\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0219 - mean_absolute_percentage_error: 120873.7812 - val_loss: 9.3308e-04 - val_mean_absolute_percentage_error: 7.0930\n",
            "Epoch 3/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0166 - mean_absolute_percentage_error: 99830.6016\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0161 - mean_absolute_percentage_error: 95577.7734 - val_loss: 7.5687e-04 - val_mean_absolute_percentage_error: 6.7677\n",
            "Epoch 4/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0119 - mean_absolute_percentage_error: 70232.9922\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0119 - mean_absolute_percentage_error: 69278.1172 - val_loss: 5.1950e-04 - val_mean_absolute_percentage_error: 5.7014\n",
            "Epoch 5/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0088 - mean_absolute_percentage_error: 2023.2355\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0087 - mean_absolute_percentage_error: 1995.9746 - val_loss: 4.1420e-04 - val_mean_absolute_percentage_error: 5.0412\n",
            "Epoch 6/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0087 - mean_absolute_percentage_error: 38133.7383\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0088 - mean_absolute_percentage_error: 35403.8242 - val_loss: 4.6915e-04 - val_mean_absolute_percentage_error: 5.4617\n",
            "Epoch 7/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0082 - mean_absolute_percentage_error: 2118.8489\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0082 - mean_absolute_percentage_error: 2090.3896 - val_loss: 2.0755e-04 - val_mean_absolute_percentage_error: 3.3295\n",
            "Epoch 8/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0081 - mean_absolute_percentage_error: 15883.8330\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0081 - mean_absolute_percentage_error: 15668.2119 - val_loss: 2.8643e-04 - val_mean_absolute_percentage_error: 4.0917\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0074 - mean_absolute_percentage_error: 8863.3955 \n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0074 - mean_absolute_percentage_error: 8863.3955 - val_loss: 4.3203e-04 - val_mean_absolute_percentage_error: 5.2185\n",
            "Epoch 10/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0068 - mean_absolute_percentage_error: 20.4522\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0065 - mean_absolute_percentage_error: 31636.8262 - val_loss: 2.0968e-04 - val_mean_absolute_percentage_error: 3.3724\n",
            "Epoch 10: early stopping\n",
            "Train Loss Terendah:  0.006475759670138359\n",
            "Epoch Stop:  9\n",
            "Val Loss Terendah:  0.00020754603610839695\n",
            "Epoch Val Loss Stop:  7\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0488 - mean_absolute_percentage_error: 189613.2188\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 3s 28ms/step - loss: 0.0488 - mean_absolute_percentage_error: 189613.2188 - val_loss: 0.0032 - val_mean_absolute_percentage_error: 15.7267\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0144 - mean_absolute_percentage_error: 92594.4531 \n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0144 - mean_absolute_percentage_error: 92594.4531 - val_loss: 4.0261e-04 - val_mean_absolute_percentage_error: 4.7036\n",
            "Epoch 3/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0091 - mean_absolute_percentage_error: 27130.0273\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0090 - mean_absolute_percentage_error: 26761.3164 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 8.6016\n",
            "Epoch 4/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0069 - mean_absolute_percentage_error: 13633.2412\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0067 - mean_absolute_percentage_error: 12263.5352 - val_loss: 4.5433e-04 - val_mean_absolute_percentage_error: 5.3402\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0061 - mean_absolute_percentage_error: 344.9257\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0061 - mean_absolute_percentage_error: 344.9257 - val_loss: 3.1199e-04 - val_mean_absolute_percentage_error: 4.2314\n",
            "Epoch 6/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0055 - mean_absolute_percentage_error: 50925.5117\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0056 - mean_absolute_percentage_error: 50233.1914 - val_loss: 2.4259e-04 - val_mean_absolute_percentage_error: 3.5947\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_percentage_error: 55767.6211\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0049 - mean_absolute_percentage_error: 55767.6211 - val_loss: 4.6265e-04 - val_mean_absolute_percentage_error: 5.4192\n",
            "Epoch 8/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0048 - mean_absolute_percentage_error: 43834.4414\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0047 - mean_absolute_percentage_error: 43238.4883 - val_loss: 2.4629e-04 - val_mean_absolute_percentage_error: 3.5164\n",
            "Epoch 9/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0043 - mean_absolute_percentage_error: 39270.5781\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0044 - mean_absolute_percentage_error: 38736.7500 - val_loss: 3.4258e-04 - val_mean_absolute_percentage_error: 4.5192\n",
            "Epoch 9: early stopping\n",
            "Train Loss Terendah:  0.00435737706720829\n",
            "Epoch Stop:  8\n",
            "Val Loss Terendah:  0.0002425938000669703\n",
            "Epoch Val Loss Stop:  6\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0420 - mean_absolute_percentage_error: 200594.8438\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 4s 42ms/step - loss: 0.0417 - mean_absolute_percentage_error: 197867.4531 - val_loss: 8.0787e-04 - val_mean_absolute_percentage_error: 6.7532\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0065 - mean_absolute_percentage_error: 38613.0703\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0065 - mean_absolute_percentage_error: 38613.0703 - val_loss: 6.3039e-04 - val_mean_absolute_percentage_error: 6.3586\n",
            "Epoch 3/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0049 - mean_absolute_percentage_error: 52526.8281\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0047 - mean_absolute_percentage_error: 48765.4648 - val_loss: 3.0966e-04 - val_mean_absolute_percentage_error: 3.9721\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 28156.0977\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0033 - mean_absolute_percentage_error: 28156.0977 - val_loss: 3.0964e-04 - val_mean_absolute_percentage_error: 4.0960\n",
            "Epoch 5/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0036 - mean_absolute_percentage_error: 65624.9297\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0037 - mean_absolute_percentage_error: 60925.5703 - val_loss: 2.8826e-04 - val_mean_absolute_percentage_error: 3.8467\n",
            "Epoch 6/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 41388.5469\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0032 - mean_absolute_percentage_error: 38425.0273 - val_loss: 3.7717e-04 - val_mean_absolute_percentage_error: 4.6909\n",
            "Epoch 7/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 13242.4121\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0027 - mean_absolute_percentage_error: 13062.4824 - val_loss: 2.9370e-04 - val_mean_absolute_percentage_error: 3.9884\n",
            "Epoch 8/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 49151.4961\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0025 - mean_absolute_percentage_error: 45631.9766 - val_loss: 2.9106e-04 - val_mean_absolute_percentage_error: 3.9588\n",
            "Epoch 8: early stopping\n",
            "Train Loss Terendah:  0.0025318667758256197\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.00028825641493313015\n",
            "Epoch Val Loss Stop:  5\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.1295 - mean_absolute_percentage_error: 15505.4150\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 4s 43ms/step - loss: 0.1289 - mean_absolute_percentage_error: 15295.2744 - val_loss: 0.0756 - val_mean_absolute_percentage_error: 77.5726\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1018 - mean_absolute_percentage_error: 66259.8516\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.1018 - mean_absolute_percentage_error: 66259.8516 - val_loss: 0.0550 - val_mean_absolute_percentage_error: 65.8752\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0865 - mean_absolute_percentage_error: 82120.9219\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0865 - mean_absolute_percentage_error: 82120.9219 - val_loss: 0.0384 - val_mean_absolute_percentage_error: 54.7404\n",
            "Epoch 4/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0689 - mean_absolute_percentage_error: 62270.4766\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0687 - mean_absolute_percentage_error: 61424.2461 - val_loss: 0.0253 - val_mean_absolute_percentage_error: 44.0546\n",
            "Epoch 5/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0512 - mean_absolute_percentage_error: 126870.2969\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0511 - mean_absolute_percentage_error: 125145.4297 - val_loss: 0.0162 - val_mean_absolute_percentage_error: 34.8431\n",
            "Epoch 6/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0436 - mean_absolute_percentage_error: 132095.0938\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0432 - mean_absolute_percentage_error: 130299.2891 - val_loss: 0.0097 - val_mean_absolute_percentage_error: 26.4126\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0390 - mean_absolute_percentage_error: 134539.1406\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0390 - mean_absolute_percentage_error: 134539.1406 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 19.2521\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0338 - mean_absolute_percentage_error: 141072.4219\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0338 - mean_absolute_percentage_error: 141072.4219 - val_loss: 0.0031 - val_mean_absolute_percentage_error: 13.6099\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0309 - mean_absolute_percentage_error: 205478.6562\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0309 - mean_absolute_percentage_error: 205478.6562 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 10.0420\n",
            "Epoch 10/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0312 - mean_absolute_percentage_error: 144833.4688\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0310 - mean_absolute_percentage_error: 142864.8906 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.8996\n",
            "Epoch 11/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0317 - mean_absolute_percentage_error: 170170.5000\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0318 - mean_absolute_percentage_error: 167861.0625 - val_loss: 9.7530e-04 - val_mean_absolute_percentage_error: 6.7881\n",
            "Epoch 12/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0300 - mean_absolute_percentage_error: 137623.2031\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0290 - mean_absolute_percentage_error: 123779.9922 - val_loss: 8.0905e-04 - val_mean_absolute_percentage_error: 6.1311\n",
            "Epoch 13/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0285 - mean_absolute_percentage_error: 182507.2344\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0284 - mean_absolute_percentage_error: 164147.4062 - val_loss: 6.9834e-04 - val_mean_absolute_percentage_error: 5.6582\n",
            "Epoch 14/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0246 - mean_absolute_percentage_error: 177174.6875\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0246 - mean_absolute_percentage_error: 174766.0938 - val_loss: 6.0762e-04 - val_mean_absolute_percentage_error: 5.2400\n",
            "Epoch 15/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0255 - mean_absolute_percentage_error: 161952.8438\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0250 - mean_absolute_percentage_error: 150357.4844 - val_loss: 5.2127e-04 - val_mean_absolute_percentage_error: 4.8202\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0198 - mean_absolute_percentage_error: 100537.1094\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0198 - mean_absolute_percentage_error: 100537.1094 - val_loss: 6.4338e-04 - val_mean_absolute_percentage_error: 5.6557\n",
            "Epoch 17/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0198 - mean_absolute_percentage_error: 114185.5781\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0198 - mean_absolute_percentage_error: 112633.3203 - val_loss: 6.2884e-04 - val_mean_absolute_percentage_error: 5.6667\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0197 - mean_absolute_percentage_error: 102125.3047\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0197 - mean_absolute_percentage_error: 102125.3047 - val_loss: 5.1202e-04 - val_mean_absolute_percentage_error: 5.0326\n",
            "Epoch 19/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0185 - mean_absolute_percentage_error: 158299.8125\n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0184 - mean_absolute_percentage_error: 156147.4688 - val_loss: 5.5052e-04 - val_mean_absolute_percentage_error: 5.3744\n",
            "Epoch 20/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0178 - mean_absolute_percentage_error: 155209.0781\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0180 - mean_absolute_percentage_error: 139593.8750 - val_loss: 4.8857e-04 - val_mean_absolute_percentage_error: 5.0507\n",
            "Epoch 21/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0184 - mean_absolute_percentage_error: 122646.0469\n",
            "Epoch 21: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0181 - mean_absolute_percentage_error: 113864.9609 - val_loss: 4.0435e-04 - val_mean_absolute_percentage_error: 4.5281\n",
            "Epoch 22/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0183 - mean_absolute_percentage_error: 168846.8750\n",
            "Epoch 22: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0180 - mean_absolute_percentage_error: 151858.5312 - val_loss: 4.6169e-04 - val_mean_absolute_percentage_error: 5.0179\n",
            "Epoch 23/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0132 - mean_absolute_percentage_error: 100861.5625\n",
            "Epoch 23: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0129 - mean_absolute_percentage_error: 96564.7500 - val_loss: 6.0618e-04 - val_mean_absolute_percentage_error: 5.9677\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0159 - mean_absolute_percentage_error: 145157.5312\n",
            "Epoch 24: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0159 - mean_absolute_percentage_error: 145157.5312 - val_loss: 4.8030e-04 - val_mean_absolute_percentage_error: 5.2506\n",
            "Epoch 24: early stopping\n",
            "Train Loss Terendah:  0.012857960537075996\n",
            "Epoch Stop:  22\n",
            "Val Loss Terendah:  0.00040434952825307846\n",
            "Epoch Val Loss Stop:  21\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1334 - mean_absolute_percentage_error: 13754.1494\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 3s 28ms/step - loss: 0.1334 - mean_absolute_percentage_error: 13754.1494 - val_loss: 0.0837 - val_mean_absolute_percentage_error: 81.5775\n",
            "Epoch 2/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1036 - mean_absolute_percentage_error: 33629.1562\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.1031 - mean_absolute_percentage_error: 31225.9473 - val_loss: 0.0576 - val_mean_absolute_percentage_error: 67.3599\n",
            "Epoch 3/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0759 - mean_absolute_percentage_error: 79492.7578\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0752 - mean_absolute_percentage_error: 76107.2891 - val_loss: 0.0368 - val_mean_absolute_percentage_error: 53.4476\n",
            "Epoch 4/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0543 - mean_absolute_percentage_error: 91006.9297 \n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0541 - mean_absolute_percentage_error: 89769.7266 - val_loss: 0.0208 - val_mean_absolute_percentage_error: 39.6451\n",
            "Epoch 5/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0414 - mean_absolute_percentage_error: 108311.0781\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0413 - mean_absolute_percentage_error: 103697.8984 - val_loss: 0.0099 - val_mean_absolute_percentage_error: 26.4840\n",
            "Epoch 6/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0299 - mean_absolute_percentage_error: 131150.9375\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0299 - mean_absolute_percentage_error: 129368.0781 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 15.1178\n",
            "Epoch 7/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0227 - mean_absolute_percentage_error: 163078.0312\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.0232 - mean_absolute_percentage_error: 156135.3281 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.7573\n",
            "Epoch 8/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0221 - mean_absolute_percentage_error: 182706.6094\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 0.0220 - mean_absolute_percentage_error: 180222.7656 - val_loss: 6.2891e-04 - val_mean_absolute_percentage_error: 5.1005\n",
            "Epoch 9/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0192 - mean_absolute_percentage_error: 195848.2031\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0192 - mean_absolute_percentage_error: 193185.5000 - val_loss: 5.4329e-04 - val_mean_absolute_percentage_error: 5.0030\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0184 - mean_absolute_percentage_error: 185605.0781\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0184 - mean_absolute_percentage_error: 185605.0781 - val_loss: 5.3932e-04 - val_mean_absolute_percentage_error: 5.2735\n",
            "Epoch 11/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0159 - mean_absolute_percentage_error: 135442.4531\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0162 - mean_absolute_percentage_error: 133603.3281 - val_loss: 4.7592e-04 - val_mean_absolute_percentage_error: 4.7921\n",
            "Epoch 12/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0141 - mean_absolute_percentage_error: 93071.6406\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0141 - mean_absolute_percentage_error: 91806.5156 - val_loss: 4.4371e-04 - val_mean_absolute_percentage_error: 4.6359\n",
            "Epoch 13/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0136 - mean_absolute_percentage_error: 200290.7969\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0136 - mean_absolute_percentage_error: 197568.1562 - val_loss: 3.9869e-04 - val_mean_absolute_percentage_error: 4.2778\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0118 - mean_absolute_percentage_error: 143563.0469\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0118 - mean_absolute_percentage_error: 143563.0469 - val_loss: 3.7382e-04 - val_mean_absolute_percentage_error: 4.1942\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0104 - mean_absolute_percentage_error: 148735.9531\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0104 - mean_absolute_percentage_error: 148735.9531 - val_loss: 3.5358e-04 - val_mean_absolute_percentage_error: 4.0929\n",
            "Epoch 16/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0092 - mean_absolute_percentage_error: 96646.1875 \n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 14ms/step - loss: 0.0089 - mean_absolute_percentage_error: 86924.0938 - val_loss: 3.3041e-04 - val_mean_absolute_percentage_error: 3.9977\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_percentage_error: 103284.9922\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0085 - mean_absolute_percentage_error: 103284.9922 - val_loss: 3.2303e-04 - val_mean_absolute_percentage_error: 4.0354\n",
            "Epoch 18/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0079 - mean_absolute_percentage_error: 97268.0859\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0081 - mean_absolute_percentage_error: 93124.4766 - val_loss: 3.3654e-04 - val_mean_absolute_percentage_error: 4.2577\n",
            "Epoch 19/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0076 - mean_absolute_percentage_error: 84305.5938 \n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0075 - mean_absolute_percentage_error: 75823.8516 - val_loss: 4.8105e-04 - val_mean_absolute_percentage_error: 5.4131\n",
            "Epoch 20/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0077 - mean_absolute_percentage_error: 66213.6016\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0076 - mean_absolute_percentage_error: 65313.4648 - val_loss: 4.8525e-04 - val_mean_absolute_percentage_error: 5.4719\n",
            "Epoch 20: early stopping\n",
            "Train Loss Terendah:  0.007450484205037355\n",
            "Epoch Stop:  18\n",
            "Val Loss Terendah:  0.0003230278380215168\n",
            "Epoch Val Loss Stop:  17\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1404 - mean_absolute_percentage_error: 28579.6113\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 3s 30ms/step - loss: 0.1386 - mean_absolute_percentage_error: 27364.2812 - val_loss: 0.0651 - val_mean_absolute_percentage_error: 71.6178\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0728 - mean_absolute_percentage_error: 119806.1875\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0728 - mean_absolute_percentage_error: 119806.1875 - val_loss: 0.0215 - val_mean_absolute_percentage_error: 40.2702\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0369 - mean_absolute_percentage_error: 158359.8438\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0369 - mean_absolute_percentage_error: 158359.8438 - val_loss: 0.0029 - val_mean_absolute_percentage_error: 12.8007\n",
            "Epoch 4/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0201 - mean_absolute_percentage_error: 158652.0000\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0201 - mean_absolute_percentage_error: 156495.2656 - val_loss: 6.9786e-04 - val_mean_absolute_percentage_error: 6.1839\n",
            "Epoch 5/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0169 - mean_absolute_percentage_error: 209714.2500\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0167 - mean_absolute_percentage_error: 206863.0625 - val_loss: 8.6122e-04 - val_mean_absolute_percentage_error: 7.2902\n",
            "Epoch 6/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0143 - mean_absolute_percentage_error: 166567.8750\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0144 - mean_absolute_percentage_error: 164303.2656 - val_loss: 5.6472e-04 - val_mean_absolute_percentage_error: 5.3990\n",
            "Epoch 7/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0106 - mean_absolute_percentage_error: 118413.3203\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0107 - mean_absolute_percentage_error: 116803.6797 - val_loss: 5.4185e-04 - val_mean_absolute_percentage_error: 5.2719\n",
            "Epoch 8/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0096 - mean_absolute_percentage_error: 116808.9141\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0096 - mean_absolute_percentage_error: 115221.1484 - val_loss: 4.8785e-04 - val_mean_absolute_percentage_error: 4.9150\n",
            "Epoch 9/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0085 - mean_absolute_percentage_error: 90846.9375\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 0.0085 - mean_absolute_percentage_error: 89611.9922 - val_loss: 4.9056e-04 - val_mean_absolute_percentage_error: 4.8983\n",
            "Epoch 10/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0076 - mean_absolute_percentage_error: 33.4614\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0076 - mean_absolute_percentage_error: 93875.5000 - val_loss: 4.0224e-04 - val_mean_absolute_percentage_error: 4.6631\n",
            "Epoch 11/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0072 - mean_absolute_percentage_error: 58092.2383\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.0074 - mean_absolute_percentage_error: 57303.9453 - val_loss: 3.8335e-04 - val_mean_absolute_percentage_error: 4.3112\n",
            "Epoch 12/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0064 - mean_absolute_percentage_error: 77299.8516\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.0065 - mean_absolute_percentage_error: 74006.8594 - val_loss: 3.8884e-04 - val_mean_absolute_percentage_error: 4.6824\n",
            "Epoch 13/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0057 - mean_absolute_percentage_error: 65619.7969\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 25ms/step - loss: 0.0058 - mean_absolute_percentage_error: 62824.7773 - val_loss: 3.6684e-04 - val_mean_absolute_percentage_error: 4.3228\n",
            "Epoch 14/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0048 - mean_absolute_percentage_error: 65634.8281\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 0.0048 - mean_absolute_percentage_error: 64742.4492 - val_loss: 3.7968e-04 - val_mean_absolute_percentage_error: 4.6165\n",
            "Epoch 15/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0048 - mean_absolute_percentage_error: 56894.0469\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0047 - mean_absolute_percentage_error: 54470.3281 - val_loss: 4.2414e-04 - val_mean_absolute_percentage_error: 5.0562\n",
            "Epoch 16/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0050 - mean_absolute_percentage_error: 60341.7344\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0051 - mean_absolute_percentage_error: 59521.4023 - val_loss: 4.0094e-04 - val_mean_absolute_percentage_error: 4.8594\n",
            "Epoch 16: early stopping\n",
            "Train Loss Terendah:  0.004690796136856079\n",
            "Epoch Stop:  14\n",
            "Val Loss Terendah:  0.00036683870712295175\n",
            "Epoch Val Loss Stop:  13\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0272 - mean_absolute_percentage_error: 86722.8828 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 43ms/step - loss: 0.0260 - mean_absolute_percentage_error: 80514.5859 - val_loss: 0.0027 - val_mean_absolute_percentage_error: 14.6330\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_percentage_error: 2341.7998\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0091 - mean_absolute_percentage_error: 2341.7998 - val_loss: 1.9342e-04 - val_mean_absolute_percentage_error: 3.2575\n",
            "Epoch 3/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0059 - mean_absolute_percentage_error: 62510.5664\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0058 - mean_absolute_percentage_error: 58034.8164 - val_loss: 4.5008e-04 - val_mean_absolute_percentage_error: 5.4313\n",
            "Epoch 4/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0065 - mean_absolute_percentage_error: 77381.8281 \n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0062 - mean_absolute_percentage_error: 71840.6094 - val_loss: 3.4465e-04 - val_mean_absolute_percentage_error: 4.7121\n",
            "Epoch 5/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0050 - mean_absolute_percentage_error: 33176.3398\n",
            "Epoch 5: val_loss improved from 0.00014 to 0.00014, saving model to best_model.h5\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0048 - mean_absolute_percentage_error: 30801.4141 - val_loss: 1.3529e-04 - val_mean_absolute_percentage_error: 2.5394\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0049 - mean_absolute_percentage_error: 17875.9199\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0049 - mean_absolute_percentage_error: 17875.9199 - val_loss: 8.2098e-04 - val_mean_absolute_percentage_error: 7.6841\n",
            "Epoch 7/50\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0039 - mean_absolute_percentage_error: 18.0850\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0038 - mean_absolute_percentage_error: 60172.1484 - val_loss: 1.8537e-04 - val_mean_absolute_percentage_error: 3.2010\n",
            "Epoch 8/50\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0034 - mean_absolute_percentage_error: 62873.7383\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0033 - mean_absolute_percentage_error: 51079.3164 - val_loss: 3.4776e-04 - val_mean_absolute_percentage_error: 4.7562\n",
            "Epoch 8: early stopping\n",
            "Train Loss Terendah:  0.0033186383079737425\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.00013529161515180022\n",
            "Epoch Val Loss Stop:  5\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0228 - mean_absolute_percentage_error: 89797.4531 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 4s 75ms/step - loss: 0.0217 - mean_absolute_percentage_error: 83368.4922 - val_loss: 2.6743e-04 - val_mean_absolute_percentage_error: 3.9509\n",
            "Epoch 2/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0054 - mean_absolute_percentage_error: 15929.5771\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0052 - mean_absolute_percentage_error: 13867.6895 - val_loss: 6.4287e-04 - val_mean_absolute_percentage_error: 6.6444\n",
            "Epoch 3/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_absolute_percentage_error: 42813.2734\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0035 - mean_absolute_percentage_error: 39747.9531 - val_loss: 1.4873e-04 - val_mean_absolute_percentage_error: 2.7758\n",
            "Epoch 4/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 31703.5215\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0032 - mean_absolute_percentage_error: 27595.2695 - val_loss: 2.0712e-04 - val_mean_absolute_percentage_error: 3.4655\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 27951.2383\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0033 - mean_absolute_percentage_error: 27951.2383 - val_loss: 1.5986e-04 - val_mean_absolute_percentage_error: 2.9808\n",
            "Epoch 6/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 34904.8789\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0026 - mean_absolute_percentage_error: 32405.8457 - val_loss: 1.9762e-04 - val_mean_absolute_percentage_error: 3.1009\n",
            "Epoch 6: early stopping\n",
            "Train Loss Terendah:  0.002593098906800151\n",
            "Epoch Stop:  5\n",
            "Val Loss Terendah:  0.000148729799548164\n",
            "Epoch Val Loss Stop:  3\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0232 - mean_absolute_percentage_error: 61274.4453\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 48ms/step - loss: 0.0230 - mean_absolute_percentage_error: 60441.4844 - val_loss: 0.0031 - val_mean_absolute_percentage_error: 15.5047\n",
            "Epoch 2/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0039 - mean_absolute_percentage_error: 28705.3477\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0038 - mean_absolute_percentage_error: 26650.6211 - val_loss: 2.0668e-04 - val_mean_absolute_percentage_error: 3.4059\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 27106.2188\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0023 - mean_absolute_percentage_error: 27106.2188 - val_loss: 3.0733e-04 - val_mean_absolute_percentage_error: 4.3842\n",
            "Epoch 4/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0021 - mean_absolute_percentage_error: 11049.5068\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0020 - mean_absolute_percentage_error: 10258.9375 - val_loss: 1.5501e-04 - val_mean_absolute_percentage_error: 2.8817\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_percentage_error: 6204.3594\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0020 - mean_absolute_percentage_error: 6204.3594 - val_loss: 2.0528e-04 - val_mean_absolute_percentage_error: 3.4622\n",
            "Epoch 6/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0016 - mean_absolute_percentage_error: 18295.1777\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0018 - mean_absolute_percentage_error: 16985.5625 - val_loss: 2.0080e-04 - val_mean_absolute_percentage_error: 3.4422\n",
            "Epoch 7/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0020 - mean_absolute_percentage_error: 13.1264\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0019 - mean_absolute_percentage_error: 54547.0156 - val_loss: 2.7692e-04 - val_mean_absolute_percentage_error: 3.7498\n",
            "Epoch 7: early stopping\n",
            "Train Loss Terendah:  0.0018155704019591212\n",
            "Epoch Stop:  5\n",
            "Val Loss Terendah:  0.00015501321468036622\n",
            "Epoch Val Loss Stop:  4\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.1443 - mean_absolute_percentage_error: 66989.3516\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 4s 60ms/step - loss: 0.1376 - mean_absolute_percentage_error: 62195.4961 - val_loss: 0.0310 - val_mean_absolute_percentage_error: 48.3990\n",
            "Epoch 2/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0526 - mean_absolute_percentage_error: 190238.6406\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0512 - mean_absolute_percentage_error: 165590.2344 - val_loss: 9.0343e-04 - val_mean_absolute_percentage_error: 6.3820\n",
            "Epoch 3/50\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0343 - mean_absolute_percentage_error: 102.1712\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0343 - mean_absolute_percentage_error: 251167.8906 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 8.5023\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0252 - mean_absolute_percentage_error: 206899.2812\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0252 - mean_absolute_percentage_error: 206899.2812 - val_loss: 9.0151e-04 - val_mean_absolute_percentage_error: 6.5298\n",
            "Epoch 5/50\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0199 - mean_absolute_percentage_error: 223929.2812\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0200 - mean_absolute_percentage_error: 181914.4062 - val_loss: 5.2370e-04 - val_mean_absolute_percentage_error: 5.0070\n",
            "Epoch 6/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0164 - mean_absolute_percentage_error: 132699.8125\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0162 - mean_absolute_percentage_error: 123197.5938 - val_loss: 3.2885e-04 - val_mean_absolute_percentage_error: 4.0363\n",
            "Epoch 7/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0114 - mean_absolute_percentage_error: 31.6865\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0113 - mean_absolute_percentage_error: 60043.6797 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 8.2599\n",
            "Epoch 8/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0098 - mean_absolute_percentage_error: 425.2732\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0095 - mean_absolute_percentage_error: 396.5072 - val_loss: 3.0194e-04 - val_mean_absolute_percentage_error: 4.0738\n",
            "Epoch 9/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0125 - mean_absolute_percentage_error: 74397.0312 \n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0121 - mean_absolute_percentage_error: 69070.4766 - val_loss: 9.2490e-04 - val_mean_absolute_percentage_error: 7.7858\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0090 - mean_absolute_percentage_error: 14007.4854\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0090 - mean_absolute_percentage_error: 14007.4854 - val_loss: 7.5213e-04 - val_mean_absolute_percentage_error: 6.9795\n",
            "Epoch 11/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0093 - mean_absolute_percentage_error: 101920.6328\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0093 - mean_absolute_percentage_error: 100535.7578 - val_loss: 6.4512e-04 - val_mean_absolute_percentage_error: 6.4403\n",
            "Epoch 11: early stopping\n",
            "Train Loss Terendah:  0.008993144147098064\n",
            "Epoch Stop:  9\n",
            "Val Loss Terendah:  0.00030193597194738686\n",
            "Epoch Val Loss Stop:  8\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.1412 - mean_absolute_percentage_error: 98096.0078 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 6s 51ms/step - loss: 0.1346 - mean_absolute_percentage_error: 91074.3047 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 30.9771\n",
            "Epoch 2/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0357 - mean_absolute_percentage_error: 317573.9062\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0347 - mean_absolute_percentage_error: 276417.5625 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 16.5081\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0255 - mean_absolute_percentage_error: 155490.9531\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0255 - mean_absolute_percentage_error: 155490.9531 - val_loss: 6.3929e-04 - val_mean_absolute_percentage_error: 5.2980\n",
            "Epoch 4/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0164 - mean_absolute_percentage_error: 149433.1250\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0161 - mean_absolute_percentage_error: 138733.8125 - val_loss: 3.7107e-04 - val_mean_absolute_percentage_error: 4.1834\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0121 - mean_absolute_percentage_error: 87933.7891 \n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0121 - mean_absolute_percentage_error: 87933.7891 - val_loss: 3.6975e-04 - val_mean_absolute_percentage_error: 4.5789\n",
            "Epoch 6/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0093 - mean_absolute_percentage_error: 6666.6074\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0093 - mean_absolute_percentage_error: 6576.1802 - val_loss: 8.0910e-04 - val_mean_absolute_percentage_error: 7.2476\n",
            "Epoch 7/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0072 - mean_absolute_percentage_error: 46201.4883\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0073 - mean_absolute_percentage_error: 45573.4492 - val_loss: 3.6154e-04 - val_mean_absolute_percentage_error: 4.6084\n",
            "Epoch 8/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0075 - mean_absolute_percentage_error: 68864.0234\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0073 - mean_absolute_percentage_error: 63932.9883 - val_loss: 4.5668e-04 - val_mean_absolute_percentage_error: 5.3025\n",
            "Epoch 9/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0069 - mean_absolute_percentage_error: 48111.3516\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0069 - mean_absolute_percentage_error: 44666.8086 - val_loss: 6.8478e-04 - val_mean_absolute_percentage_error: 6.6652\n",
            "Epoch 10/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0063 - mean_absolute_percentage_error: 20.3750\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0061 - mean_absolute_percentage_error: 68209.4062 - val_loss: 4.1286e-04 - val_mean_absolute_percentage_error: 4.9953\n",
            "Epoch 10: early stopping\n",
            "Train Loss Terendah:  0.00614903261885047\n",
            "Epoch Stop:  9\n",
            "Val Loss Terendah:  0.00036154105328023434\n",
            "Epoch Val Loss Stop:  7\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0669 - mean_absolute_percentage_error: 124286.2344\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 52ms/step - loss: 0.0644 - mean_absolute_percentage_error: 115393.5156 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 31.2513\n",
            "Epoch 2/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0167 - mean_absolute_percentage_error: 122520.7969\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0160 - mean_absolute_percentage_error: 113749.5156 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 9.2786\n",
            "Epoch 3/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0080 - mean_absolute_percentage_error: 82417.5469\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0078 - mean_absolute_percentage_error: 76516.3984 - val_loss: 6.8685e-04 - val_mean_absolute_percentage_error: 6.1842\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_percentage_error: 56942.3867\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_absolute_percentage_error: 56942.3867 - val_loss: 4.3654e-04 - val_mean_absolute_percentage_error: 5.1563\n",
            "Epoch 5/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0045 - mean_absolute_percentage_error: 33303.1406\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_absolute_percentage_error: 30918.8828 - val_loss: 3.2951e-04 - val_mean_absolute_percentage_error: 4.3264\n",
            "Epoch 6/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0034 - mean_absolute_percentage_error: 35310.7578\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_absolute_percentage_error: 32782.7383 - val_loss: 2.7697e-04 - val_mean_absolute_percentage_error: 3.7392\n",
            "Epoch 7/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0032 - mean_absolute_percentage_error: 34852.8672\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0031 - mean_absolute_percentage_error: 32358.0312 - val_loss: 3.6727e-04 - val_mean_absolute_percentage_error: 4.2320\n",
            "Epoch 8/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 44099.4336\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0033 - mean_absolute_percentage_error: 43499.9844 - val_loss: 3.8227e-04 - val_mean_absolute_percentage_error: 4.7591\n",
            "Epoch 9/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 17706.2363\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0033 - mean_absolute_percentage_error: 17465.6348 - val_loss: 2.5854e-04 - val_mean_absolute_percentage_error: 3.7030\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 22486.3672\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0031 - mean_absolute_percentage_error: 22486.3672 - val_loss: 4.0474e-04 - val_mean_absolute_percentage_error: 4.9628\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 53594.6875\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0029 - mean_absolute_percentage_error: 53594.6875 - val_loss: 2.6796e-04 - val_mean_absolute_percentage_error: 3.7928\n",
            "Epoch 12/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 50612.1680\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0027 - mean_absolute_percentage_error: 49924.0625 - val_loss: 3.8998e-04 - val_mean_absolute_percentage_error: 4.3835\n",
            "Epoch 12: early stopping\n",
            "Train Loss Terendah:  0.0026795705780386925\n",
            "Epoch Stop:  11\n",
            "Val Loss Terendah:  0.0002585444017313421\n",
            "Epoch Val Loss Stop:  9\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.1667 - mean_absolute_percentage_error: 2413.8660\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 46ms/step - loss: 0.1670 - mean_absolute_percentage_error: 2382.3801 - val_loss: 0.1219 - val_mean_absolute_percentage_error: 98.6992\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1563 - mean_absolute_percentage_error: 26362.6016\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.1563 - mean_absolute_percentage_error: 26362.6016 - val_loss: 0.1095 - val_mean_absolute_percentage_error: 93.4479\n",
            "Epoch 3/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.1479 - mean_absolute_percentage_error: 84.7964\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.1452 - mean_absolute_percentage_error: 28012.9199 - val_loss: 0.0980 - val_mean_absolute_percentage_error: 88.2862\n",
            "Epoch 4/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.1355 - mean_absolute_percentage_error: 35463.9297\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.1349 - mean_absolute_percentage_error: 34982.6172 - val_loss: 0.0874 - val_mean_absolute_percentage_error: 83.2407\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1216 - mean_absolute_percentage_error: 50072.4062\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.1216 - mean_absolute_percentage_error: 50072.4062 - val_loss: 0.0777 - val_mean_absolute_percentage_error: 78.3817\n",
            "Epoch 6/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.1084 - mean_absolute_percentage_error: 31207.6758\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.1088 - mean_absolute_percentage_error: 30784.3086 - val_loss: 0.0688 - val_mean_absolute_percentage_error: 73.6064\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1015 - mean_absolute_percentage_error: 54843.7344\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.1015 - mean_absolute_percentage_error: 54843.7344 - val_loss: 0.0602 - val_mean_absolute_percentage_error: 68.7560\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0927 - mean_absolute_percentage_error: 75120.6406\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0927 - mean_absolute_percentage_error: 75120.6406 - val_loss: 0.0525 - val_mean_absolute_percentage_error: 64.0328\n",
            "Epoch 9/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0873 - mean_absolute_percentage_error: 115970.9219\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0861 - mean_absolute_percentage_error: 107668.7734 - val_loss: 0.0455 - val_mean_absolute_percentage_error: 59.4689\n",
            "Epoch 10/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0843 - mean_absolute_percentage_error: 62913.8438\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0841 - mean_absolute_percentage_error: 62058.9805 - val_loss: 0.0391 - val_mean_absolute_percentage_error: 54.9516\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0771 - mean_absolute_percentage_error: 113979.6328\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0771 - mean_absolute_percentage_error: 113979.6328 - val_loss: 0.0336 - val_mean_absolute_percentage_error: 50.7147\n",
            "Epoch 12/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0688 - mean_absolute_percentage_error: 112346.3516\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0693 - mean_absolute_percentage_error: 110819.3438 - val_loss: 0.0284 - val_mean_absolute_percentage_error: 46.4456\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0656 - mean_absolute_percentage_error: 117455.0078\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0656 - mean_absolute_percentage_error: 117455.0078 - val_loss: 0.0239 - val_mean_absolute_percentage_error: 42.3337\n",
            "Epoch 14/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0583 - mean_absolute_percentage_error: 167549.6094\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0586 - mean_absolute_percentage_error: 165271.7344 - val_loss: 0.0199 - val_mean_absolute_percentage_error: 38.4049\n",
            "Epoch 15/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0589 - mean_absolute_percentage_error: 162546.1875\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0581 - mean_absolute_percentage_error: 150909.3125 - val_loss: 0.0164 - val_mean_absolute_percentage_error: 34.6312\n",
            "Epoch 16/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0568 - mean_absolute_percentage_error: 117595.5547\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0540 - mean_absolute_percentage_error: 102357.7188 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 31.2001\n",
            "Epoch 17/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0523 - mean_absolute_percentage_error: 181803.3594\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0506 - mean_absolute_percentage_error: 168785.7656 - val_loss: 0.0112 - val_mean_absolute_percentage_error: 27.9899\n",
            "Epoch 18/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0453 - mean_absolute_percentage_error: 190242.1250\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0455 - mean_absolute_percentage_error: 187655.5469 - val_loss: 0.0092 - val_mean_absolute_percentage_error: 25.0096\n",
            "Epoch 19/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0493 - mean_absolute_percentage_error: 129656.2031\n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0491 - mean_absolute_percentage_error: 127893.4375 - val_loss: 0.0075 - val_mean_absolute_percentage_error: 22.1864\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0456 - mean_absolute_percentage_error: 170172.4688\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0456 - mean_absolute_percentage_error: 170172.4688 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 19.3451\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0422 - mean_absolute_percentage_error: 161635.1875\n",
            "Epoch 21: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0422 - mean_absolute_percentage_error: 161635.1875 - val_loss: 0.0049 - val_mean_absolute_percentage_error: 17.2601\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0429 - mean_absolute_percentage_error: 242169.6094\n",
            "Epoch 22: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0429 - mean_absolute_percentage_error: 242169.6094 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 15.3176\n",
            "Epoch 23/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0432 - mean_absolute_percentage_error: 163382.5781\n",
            "Epoch 23: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0422 - mean_absolute_percentage_error: 151685.7031 - val_loss: 0.0034 - val_mean_absolute_percentage_error: 13.5406\n",
            "Epoch 24/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0390 - mean_absolute_percentage_error: 257556.4531\n",
            "Epoch 24: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0400 - mean_absolute_percentage_error: 224177.8438 - val_loss: 0.0029 - val_mean_absolute_percentage_error: 12.3642\n",
            "Epoch 25/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0414 - mean_absolute_percentage_error: 90816.6562\n",
            "Epoch 25: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0412 - mean_absolute_percentage_error: 84316.9141 - val_loss: 0.0026 - val_mean_absolute_percentage_error: 11.5039\n",
            "Epoch 26/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0410 - mean_absolute_percentage_error: 157762.0312\n",
            "Epoch 26: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0413 - mean_absolute_percentage_error: 137317.5469 - val_loss: 0.0022 - val_mean_absolute_percentage_error: 10.5821\n",
            "Epoch 27/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0348 - mean_absolute_percentage_error: 90675.3125\n",
            "Epoch 27: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0344 - mean_absolute_percentage_error: 89442.7031 - val_loss: 0.0020 - val_mean_absolute_percentage_error: 9.9134\n",
            "Epoch 28/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0362 - mean_absolute_percentage_error: 140582.3438\n",
            "Epoch 28: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0362 - mean_absolute_percentage_error: 130517.6562 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 9.4842\n",
            "Epoch 29/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0333 - mean_absolute_percentage_error: 173241.8906\n",
            "Epoch 29: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0333 - mean_absolute_percentage_error: 170887.1250 - val_loss: 0.0017 - val_mean_absolute_percentage_error: 9.0703\n",
            "Epoch 30/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0353 - mean_absolute_percentage_error: 73.1545\n",
            "Epoch 30: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0355 - mean_absolute_percentage_error: 236779.3906 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 8.5833\n",
            "Epoch 31/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0340 - mean_absolute_percentage_error: 224584.6406\n",
            "Epoch 31: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0342 - mean_absolute_percentage_error: 208504.6562 - val_loss: 0.0015 - val_mean_absolute_percentage_error: 8.3195\n",
            "Epoch 32/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0371 - mean_absolute_percentage_error: 163253.3125\n",
            "Epoch 32: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0372 - mean_absolute_percentage_error: 151566.5938 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 8.1588\n",
            "Epoch 33/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0339 - mean_absolute_percentage_error: 143549.8281\n",
            "Epoch 33: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0330 - mean_absolute_percentage_error: 133272.2656 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 8.2050\n",
            "Epoch 34/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0343 - mean_absolute_percentage_error: 146694.3125\n",
            "Epoch 34: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0347 - mean_absolute_percentage_error: 144700.3906 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.9530\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0303 - mean_absolute_percentage_error: 175204.5469\n",
            "Epoch 35: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0303 - mean_absolute_percentage_error: 175204.5469 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.7140\n",
            "Epoch 36/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0299 - mean_absolute_percentage_error: 209165.4219\n",
            "Epoch 36: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0305 - mean_absolute_percentage_error: 194188.4531 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.9840\n",
            "Epoch 37/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0312 - mean_absolute_percentage_error: 205333.4688\n",
            "Epoch 37: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0309 - mean_absolute_percentage_error: 202541.5312 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 8.1150\n",
            "Epoch 38/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0297 - mean_absolute_percentage_error: 185274.4219\n",
            "Epoch 38: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0292 - mean_absolute_percentage_error: 172009.1250 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.9173\n",
            "Epoch 38: early stopping\n",
            "Train Loss Terendah:  0.02917659282684326\n",
            "Epoch Stop:  37\n",
            "Val Loss Terendah:  0.0012680860236287117\n",
            "Epoch Val Loss Stop:  35\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0903 - mean_absolute_percentage_error: 8395.8223 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 47ms/step - loss: 0.0894 - mean_absolute_percentage_error: 7799.0718 - val_loss: 0.0565 - val_mean_absolute_percentage_error: 67.0262\n",
            "Epoch 2/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0710 - mean_absolute_percentage_error: 36963.7891\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0713 - mean_absolute_percentage_error: 36461.8711 - val_loss: 0.0436 - val_mean_absolute_percentage_error: 58.7416\n",
            "Epoch 3/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0608 - mean_absolute_percentage_error: 45860.9375\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0607 - mean_absolute_percentage_error: 45237.8438 - val_loss: 0.0328 - val_mean_absolute_percentage_error: 50.7174\n",
            "Epoch 4/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0490 - mean_absolute_percentage_error: 56313.0625\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0488 - mean_absolute_percentage_error: 55547.7383 - val_loss: 0.0239 - val_mean_absolute_percentage_error: 43.0208\n",
            "Epoch 5/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0409 - mean_absolute_percentage_error: 58395.5117\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0409 - mean_absolute_percentage_error: 57601.8867 - val_loss: 0.0167 - val_mean_absolute_percentage_error: 35.7213\n",
            "Epoch 6/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0325 - mean_absolute_percentage_error: 112405.9062\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0325 - mean_absolute_percentage_error: 110877.5781 - val_loss: 0.0111 - val_mean_absolute_percentage_error: 28.6538\n",
            "Epoch 7/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0279 - mean_absolute_percentage_error: 118391.0078\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0283 - mean_absolute_percentage_error: 116781.6172 - val_loss: 0.0069 - val_mean_absolute_percentage_error: 22.0938\n",
            "Epoch 8/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0265 - mean_absolute_percentage_error: 133322.5625\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0259 - mean_absolute_percentage_error: 123776.8984 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 16.1732\n",
            "Epoch 9/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0233 - mean_absolute_percentage_error: 87110.9531 \n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0232 - mean_absolute_percentage_error: 85926.9062 - val_loss: 0.0022 - val_mean_absolute_percentage_error: 11.2738\n",
            "Epoch 10/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0207 - mean_absolute_percentage_error: 52.5016\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0202 - mean_absolute_percentage_error: 173501.4531 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 7.7081\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0182 - mean_absolute_percentage_error: 143559.4375\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0182 - mean_absolute_percentage_error: 143559.4375 - val_loss: 7.2382e-04 - val_mean_absolute_percentage_error: 5.7994\n",
            "Epoch 12/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0176 - mean_absolute_percentage_error: 115213.0156\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0174 - mean_absolute_percentage_error: 106965.8672 - val_loss: 5.0578e-04 - val_mean_absolute_percentage_error: 4.6312\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0162 - mean_absolute_percentage_error: 182597.0156\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0162 - mean_absolute_percentage_error: 182597.0156 - val_loss: 4.3886e-04 - val_mean_absolute_percentage_error: 4.3182\n",
            "Epoch 14/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0158 - mean_absolute_percentage_error: 141877.6250\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0157 - mean_absolute_percentage_error: 131719.8281 - val_loss: 3.9988e-04 - val_mean_absolute_percentage_error: 4.1975\n",
            "Epoch 15/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0161 - mean_absolute_percentage_error: 154159.0156\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0157 - mean_absolute_percentage_error: 143121.2812 - val_loss: 3.8279e-04 - val_mean_absolute_percentage_error: 4.1328\n",
            "Epoch 16/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0144 - mean_absolute_percentage_error: 129420.8203\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0143 - mean_absolute_percentage_error: 127661.2188 - val_loss: 3.7646e-04 - val_mean_absolute_percentage_error: 4.0805\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0142 - mean_absolute_percentage_error: 130893.5625\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0142 - mean_absolute_percentage_error: 130893.5625 - val_loss: 3.5675e-04 - val_mean_absolute_percentage_error: 4.0068\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0147 - mean_absolute_percentage_error: 111671.5938\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0147 - mean_absolute_percentage_error: 111671.5938 - val_loss: 3.4322e-04 - val_mean_absolute_percentage_error: 3.9393\n",
            "Epoch 19/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0135 - mean_absolute_percentage_error: 101480.0391\n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0134 - mean_absolute_percentage_error: 100100.4609 - val_loss: 3.3228e-04 - val_mean_absolute_percentage_error: 3.8761\n",
            "Epoch 20/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0126 - mean_absolute_percentage_error: 141144.1250\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0122 - mean_absolute_percentage_error: 131038.4219 - val_loss: 3.2867e-04 - val_mean_absolute_percentage_error: 3.8614\n",
            "Epoch 21/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0114 - mean_absolute_percentage_error: 105248.0078\n",
            "Epoch 21: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0116 - mean_absolute_percentage_error: 97713.0234 - val_loss: 3.2953e-04 - val_mean_absolute_percentage_error: 3.9003\n",
            "Epoch 22/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0118 - mean_absolute_percentage_error: 94951.8125 \n",
            "Epoch 22: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0118 - mean_absolute_percentage_error: 93660.9609 - val_loss: 2.9556e-04 - val_mean_absolute_percentage_error: 3.7111\n",
            "Epoch 23/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0107 - mean_absolute_percentage_error: 111860.3516\n",
            "Epoch 23: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0105 - mean_absolute_percentage_error: 103850.9141 - val_loss: 2.8326e-04 - val_mean_absolute_percentage_error: 3.6659\n",
            "Epoch 24/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0103 - mean_absolute_percentage_error: 100844.3828\n",
            "Epoch 24: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0102 - mean_absolute_percentage_error: 93624.4688 - val_loss: 2.8064e-04 - val_mean_absolute_percentage_error: 3.6587\n",
            "Epoch 25/50\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0093 - mean_absolute_percentage_error: 101875.3281\n",
            "Epoch 25: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0093 - mean_absolute_percentage_error: 100490.2266 - val_loss: 2.7602e-04 - val_mean_absolute_percentage_error: 3.6613\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0091 - mean_absolute_percentage_error: 105639.9531\n",
            "Epoch 26: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0091 - mean_absolute_percentage_error: 105639.9531 - val_loss: 2.6299e-04 - val_mean_absolute_percentage_error: 3.5788\n",
            "Epoch 27/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0086 - mean_absolute_percentage_error: 85022.8672\n",
            "Epoch 27: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0088 - mean_absolute_percentage_error: 78935.0781 - val_loss: 2.8110e-04 - val_mean_absolute_percentage_error: 3.7700\n",
            "Epoch 28/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0083 - mean_absolute_percentage_error: 78918.2109 \n",
            "Epoch 28: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0086 - mean_absolute_percentage_error: 73268.0547 - val_loss: 2.9876e-04 - val_mean_absolute_percentage_error: 3.9446\n",
            "Epoch 29/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0075 - mean_absolute_percentage_error: 29.5584\n",
            "Epoch 29: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0072 - mean_absolute_percentage_error: 52948.2773 - val_loss: 3.2689e-04 - val_mean_absolute_percentage_error: 4.2286\n",
            "Epoch 29: early stopping\n",
            "Train Loss Terendah:  0.00721429567784071\n",
            "Epoch Stop:  28\n",
            "Val Loss Terendah:  0.00026298631564714015\n",
            "Epoch Val Loss Stop:  26\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.1146 - mean_absolute_percentage_error: 21435.0312\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 54ms/step - loss: 0.1127 - mean_absolute_percentage_error: 18665.0352 - val_loss: 0.0685 - val_mean_absolute_percentage_error: 73.7734\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0825 - mean_absolute_percentage_error: 49589.6836\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0825 - mean_absolute_percentage_error: 49589.6836 - val_loss: 0.0432 - val_mean_absolute_percentage_error: 58.2538\n",
            "Epoch 3/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0584 - mean_absolute_percentage_error: 82897.8047\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0571 - mean_absolute_percentage_error: 76962.9922 - val_loss: 0.0250 - val_mean_absolute_percentage_error: 43.8768\n",
            "Epoch 4/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0407 - mean_absolute_percentage_error: 94152.2500 \n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0403 - mean_absolute_percentage_error: 87411.7969 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 30.7130\n",
            "Epoch 5/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0257 - mean_absolute_percentage_error: 141044.4844\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0257 - mean_absolute_percentage_error: 130945.4219 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 19.2939\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0193 - mean_absolute_percentage_error: 118630.7969\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0193 - mean_absolute_percentage_error: 118630.7969 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 10.2594\n",
            "Epoch 7/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0150 - mean_absolute_percentage_error: 139790.8281\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0151 - mean_absolute_percentage_error: 129785.4453 - val_loss: 6.1890e-04 - val_mean_absolute_percentage_error: 5.2599\n",
            "Epoch 8/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0142 - mean_absolute_percentage_error: 152681.8125\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0140 - mean_absolute_percentage_error: 141750.1719 - val_loss: 4.7747e-04 - val_mean_absolute_percentage_error: 4.8894\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0115 - mean_absolute_percentage_error: 113506.6328\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0115 - mean_absolute_percentage_error: 113506.6328 - val_loss: 5.3436e-04 - val_mean_absolute_percentage_error: 5.4345\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0109 - mean_absolute_percentage_error: 135660.4375\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0109 - mean_absolute_percentage_error: 135660.4375 - val_loss: 5.4409e-04 - val_mean_absolute_percentage_error: 5.5213\n",
            "Epoch 11/50\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0107 - mean_absolute_percentage_error: 51.1182\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0107 - mean_absolute_percentage_error: 126152.8906 - val_loss: 5.0628e-04 - val_mean_absolute_percentage_error: 5.2457\n",
            "Epoch 11: early stopping\n",
            "Train Loss Terendah:  0.010665198788046837\n",
            "Epoch Stop:  10\n",
            "Val Loss Terendah:  0.00047746882773935795\n",
            "Epoch Val Loss Stop:  8\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0264 - mean_absolute_percentage_error: 95300.5156 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 47ms/step - loss: 0.0264 - mean_absolute_percentage_error: 95300.5156 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 9.2658\n",
            "Epoch 2/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0087 - mean_absolute_percentage_error: 1230.2069\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0086 - mean_absolute_percentage_error: 1145.5585 - val_loss: 1.7856e-04 - val_mean_absolute_percentage_error: 3.1157\n",
            "Epoch 3/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0057 - mean_absolute_percentage_error: 53289.4727\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0057 - mean_absolute_percentage_error: 52565.0391 - val_loss: 2.6190e-04 - val_mean_absolute_percentage_error: 3.9591\n",
            "Epoch 4/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0060 - mean_absolute_percentage_error: 58621.6758\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0060 - mean_absolute_percentage_error: 57824.6562 - val_loss: 3.5937e-04 - val_mean_absolute_percentage_error: 4.7932\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_percentage_error: 10208.4561\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0047 - mean_absolute_percentage_error: 10208.4561 - val_loss: 1.4946e-04 - val_mean_absolute_percentage_error: 2.8532\n",
            "Epoch 6/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0045 - mean_absolute_percentage_error: 40246.7812\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0045 - mean_absolute_percentage_error: 39699.6836 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 8.7791\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0034 - mean_absolute_percentage_error: 46445.8984\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0034 - mean_absolute_percentage_error: 46445.8984 - val_loss: 1.5178e-04 - val_mean_absolute_percentage_error: 2.8762\n",
            "Epoch 8/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 3575.3142\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0030 - mean_absolute_percentage_error: 3320.4062 - val_loss: 2.8245e-04 - val_mean_absolute_percentage_error: 4.1645\n",
            "Epoch 8: early stopping\n",
            "Train Loss Terendah:  0.0029829361010342836\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.0001494602911407128\n",
            "Epoch Val Loss Stop:  5\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0226 - mean_absolute_percentage_error: 32648.0078\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 4s 49ms/step - loss: 0.0223 - mean_absolute_percentage_error: 32204.1992 - val_loss: 3.1446e-04 - val_mean_absolute_percentage_error: 4.3316\n",
            "Epoch 2/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0052 - mean_absolute_percentage_error: 32167.1387\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0052 - mean_absolute_percentage_error: 29865.7520 - val_loss: 3.9249e-04 - val_mean_absolute_percentage_error: 4.9531\n",
            "Epoch 3/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0037 - mean_absolute_percentage_error: 21003.8086\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0036 - mean_absolute_percentage_error: 19500.4766 - val_loss: 1.6503e-04 - val_mean_absolute_percentage_error: 2.8878\n",
            "Epoch 4/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 47456.2969\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0030 - mean_absolute_percentage_error: 46811.0938 - val_loss: 2.3189e-04 - val_mean_absolute_percentage_error: 3.6836\n",
            "Epoch 5/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 81153.9844 \n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0031 - mean_absolute_percentage_error: 75342.3906 - val_loss: 1.7185e-04 - val_mean_absolute_percentage_error: 3.1003\n",
            "Epoch 6/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 788.4064\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0025 - mean_absolute_percentage_error: 732.7252 - val_loss: 2.7014e-04 - val_mean_absolute_percentage_error: 3.7057\n",
            "Epoch 6: early stopping\n",
            "Train Loss Terendah:  0.0025431488174945116\n",
            "Epoch Stop:  5\n",
            "Val Loss Terendah:  0.00016503127699252218\n",
            "Epoch Val Loss Stop:  3\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0227 - mean_absolute_percentage_error: 72163.5312\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 51ms/step - loss: 0.0214 - mean_absolute_percentage_error: 66996.4766 - val_loss: 0.0044 - val_mean_absolute_percentage_error: 18.6742\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_percentage_error: 22085.5371\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0041 - mean_absolute_percentage_error: 22085.5371 - val_loss: 1.9091e-04 - val_mean_absolute_percentage_error: 3.0121\n",
            "Epoch 3/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 39934.5898\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0030 - mean_absolute_percentage_error: 37075.2734 - val_loss: 1.8337e-04 - val_mean_absolute_percentage_error: 3.2549\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0022 - mean_absolute_percentage_error: 27554.9238\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0022 - mean_absolute_percentage_error: 27554.9238 - val_loss: 4.4981e-04 - val_mean_absolute_percentage_error: 5.4738\n",
            "Epoch 5/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 1556.3987\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0022 - mean_absolute_percentage_error: 1445.8358 - val_loss: 2.6685e-04 - val_mean_absolute_percentage_error: 4.0424\n",
            "Epoch 6/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0018 - mean_absolute_percentage_error: 10054.7461\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0018 - mean_absolute_percentage_error: 9918.1523 - val_loss: 3.5319e-04 - val_mean_absolute_percentage_error: 4.7641\n",
            "Epoch 6: early stopping\n",
            "Train Loss Terendah:  0.0017941914265975356\n",
            "Epoch Stop:  5\n",
            "Val Loss Terendah:  0.00018336836365051568\n",
            "Epoch Val Loss Stop:  3\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0764 - mean_absolute_percentage_error: 96593.1641 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 4s 45ms/step - loss: 0.0696 - mean_absolute_percentage_error: 78477.0469 - val_loss: 0.0027 - val_mean_absolute_percentage_error: 12.3617\n",
            "Epoch 2/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0343 - mean_absolute_percentage_error: 195969.8438\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0342 - mean_absolute_percentage_error: 193305.6250 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 10.8272\n",
            "Epoch 3/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0230 - mean_absolute_percentage_error: 131793.2969\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0229 - mean_absolute_percentage_error: 122356.9141 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 7.8044\n",
            "Epoch 4/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0213 - mean_absolute_percentage_error: 115260.8281\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0211 - mean_absolute_percentage_error: 113693.8438 - val_loss: 3.3029e-04 - val_mean_absolute_percentage_error: 3.9208\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0149 - mean_absolute_percentage_error: 91940.1641 \n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0149 - mean_absolute_percentage_error: 91940.1641 - val_loss: 6.0221e-04 - val_mean_absolute_percentage_error: 6.0580\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0130 - mean_absolute_percentage_error: 24692.0996\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0130 - mean_absolute_percentage_error: 24692.0996 - val_loss: 2.4609e-04 - val_mean_absolute_percentage_error: 3.6735\n",
            "Epoch 7/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0102 - mean_absolute_percentage_error: 30635.2070\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0102 - mean_absolute_percentage_error: 30218.8555 - val_loss: 4.1373e-04 - val_mean_absolute_percentage_error: 5.0608\n",
            "Epoch 8/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0095 - mean_absolute_percentage_error: 32855.9375\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0095 - mean_absolute_percentage_error: 32409.4395 - val_loss: 2.9354e-04 - val_mean_absolute_percentage_error: 4.1310\n",
            "Epoch 9/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0091 - mean_absolute_percentage_error: 36496.5312\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0090 - mean_absolute_percentage_error: 36000.4258 - val_loss: 4.5711e-04 - val_mean_absolute_percentage_error: 5.3782\n",
            "Epoch 9: early stopping\n",
            "Train Loss Terendah:  0.009023395366966724\n",
            "Epoch Stop:  8\n",
            "Val Loss Terendah:  0.00024608735111542046\n",
            "Epoch Val Loss Stop:  6\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.1098 - mean_absolute_percentage_error: 82832.6094 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 47ms/step - loss: 0.1088 - mean_absolute_percentage_error: 81707.1406 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 17.4868\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0304 - mean_absolute_percentage_error: 281499.1875\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0304 - mean_absolute_percentage_error: 281499.1875 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 18.3791\n",
            "Epoch 3/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0212 - mean_absolute_percentage_error: 81.4237\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0201 - mean_absolute_percentage_error: 140780.9688 - val_loss: 8.6666e-04 - val_mean_absolute_percentage_error: 6.6203\n",
            "Epoch 4/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0129 - mean_absolute_percentage_error: 147845.5156\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0125 - mean_absolute_percentage_error: 137259.8438 - val_loss: 4.0272e-04 - val_mean_absolute_percentage_error: 4.4997\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0085 - mean_absolute_percentage_error: 47000.6602\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0085 - mean_absolute_percentage_error: 47000.6602 - val_loss: 3.2892e-04 - val_mean_absolute_percentage_error: 4.2661\n",
            "Epoch 6/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0064 - mean_absolute_percentage_error: 72182.4688\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0066 - mean_absolute_percentage_error: 62826.3281 - val_loss: 3.9742e-04 - val_mean_absolute_percentage_error: 4.8750\n",
            "Epoch 7/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0055 - mean_absolute_percentage_error: 60778.2930\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0056 - mean_absolute_percentage_error: 56426.3945 - val_loss: 3.8678e-04 - val_mean_absolute_percentage_error: 4.7935\n",
            "Epoch 8/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0057 - mean_absolute_percentage_error: 62667.4805\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_absolute_percentage_error: 58180.0469 - val_loss: 3.4071e-04 - val_mean_absolute_percentage_error: 4.4160\n",
            "Epoch 8: early stopping\n",
            "Train Loss Terendah:  0.005484042223542929\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.00032891504815779626\n",
            "Epoch Val Loss Stop:  5\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0564 - mean_absolute_percentage_error: 142131.0156\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 52ms/step - loss: 0.0546 - mean_absolute_percentage_error: 131960.0938 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 31.2005\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0134 - mean_absolute_percentage_error: 110333.8750\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0134 - mean_absolute_percentage_error: 110333.8750 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 8.7860\n",
            "Epoch 3/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0066 - mean_absolute_percentage_error: 96822.3359\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0066 - mean_absolute_percentage_error: 95505.8750 - val_loss: 5.1672e-04 - val_mean_absolute_percentage_error: 5.0622\n",
            "Epoch 4/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0037 - mean_absolute_percentage_error: 24553.4980\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0036 - mean_absolute_percentage_error: 22795.7852 - val_loss: 3.0937e-04 - val_mean_absolute_percentage_error: 4.1602\n",
            "Epoch 5/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0038 - mean_absolute_percentage_error: 54103.8164\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0038 - mean_absolute_percentage_error: 50229.5156 - val_loss: 4.0997e-04 - val_mean_absolute_percentage_error: 4.9972\n",
            "Epoch 6/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 47077.2695\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0033 - mean_absolute_percentage_error: 43706.4531 - val_loss: 2.7043e-04 - val_mean_absolute_percentage_error: 3.8208\n",
            "Epoch 7/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 61050.5195\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0033 - mean_absolute_percentage_error: 60220.4570 - val_loss: 4.2301e-04 - val_mean_absolute_percentage_error: 4.5236\n",
            "Epoch 8/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 32833.7656\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_absolute_percentage_error: 30482.9043 - val_loss: 2.9057e-04 - val_mean_absolute_percentage_error: 3.9970\n",
            "Epoch 9/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 14758.5000\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0031 - mean_absolute_percentage_error: 13702.3906 - val_loss: 2.6486e-04 - val_mean_absolute_percentage_error: 3.6269\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 22510.3418\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0029 - mean_absolute_percentage_error: 22510.3418 - val_loss: 4.0407e-04 - val_mean_absolute_percentage_error: 4.9781\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 34619.7969\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_absolute_percentage_error: 34619.7969 - val_loss: 2.6061e-04 - val_mean_absolute_percentage_error: 3.7516\n",
            "Epoch 12/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 12.6287\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0025 - mean_absolute_percentage_error: 30492.7695 - val_loss: 3.1087e-04 - val_mean_absolute_percentage_error: 3.9058\n",
            "Epoch 13/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 29456.4883\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0025 - mean_absolute_percentage_error: 25639.3379 - val_loss: 3.4233e-04 - val_mean_absolute_percentage_error: 4.4952\n",
            "Epoch 14/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 39772.8672\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0026 - mean_absolute_percentage_error: 36925.2500 - val_loss: 2.8011e-04 - val_mean_absolute_percentage_error: 3.9241\n",
            "Epoch 14: early stopping\n",
            "Train Loss Terendah:  0.002456407528370619\n",
            "Epoch Stop:  12\n",
            "Val Loss Terendah:  0.00026061461539939046\n",
            "Epoch Val Loss Stop:  11\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.2676 - mean_absolute_percentage_error: 8341.5088 \n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 44ms/step - loss: 0.2626 - mean_absolute_percentage_error: 7275.2490 - val_loss: 0.1868 - val_mean_absolute_percentage_error: 122.1675\n",
            "Epoch 2/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.2504 - mean_absolute_percentage_error: 33748.3047\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.2467 - mean_absolute_percentage_error: 29387.5293 - val_loss: 0.1662 - val_mean_absolute_percentage_error: 115.1143\n",
            "Epoch 3/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.2237 - mean_absolute_percentage_error: 28902.1113\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.2229 - mean_absolute_percentage_error: 28510.4219 - val_loss: 0.1473 - val_mean_absolute_percentage_error: 108.2335\n",
            "Epoch 4/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.1971 - mean_absolute_percentage_error: 28533.0605\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.1960 - mean_absolute_percentage_error: 28146.1094 - val_loss: 0.1304 - val_mean_absolute_percentage_error: 101.7040\n",
            "Epoch 5/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.1796 - mean_absolute_percentage_error: 72762.8359\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.1787 - mean_absolute_percentage_error: 71774.3281 - val_loss: 0.1153 - val_mean_absolute_percentage_error: 95.4564\n",
            "Epoch 6/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.1593 - mean_absolute_percentage_error: 73481.9609\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.1626 - mean_absolute_percentage_error: 63965.6055 - val_loss: 0.1015 - val_mean_absolute_percentage_error: 89.4266\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1557 - mean_absolute_percentage_error: 83390.7266\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.1557 - mean_absolute_percentage_error: 83390.7266 - val_loss: 0.0885 - val_mean_absolute_percentage_error: 83.3336\n",
            "Epoch 8/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.1435 - mean_absolute_percentage_error: 101000.7188\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.1397 - mean_absolute_percentage_error: 93770.9844 - val_loss: 0.0767 - val_mean_absolute_percentage_error: 77.3925\n",
            "Epoch 9/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.1330 - mean_absolute_percentage_error: 172160.6406\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.1321 - mean_absolute_percentage_error: 159835.1875 - val_loss: 0.0661 - val_mean_absolute_percentage_error: 71.6603\n",
            "Epoch 10/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.1226 - mean_absolute_percentage_error: 68.8792\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.1199 - mean_absolute_percentage_error: 79112.6016 - val_loss: 0.0566 - val_mean_absolute_percentage_error: 66.0998\n",
            "Epoch 11/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.1151 - mean_absolute_percentage_error: 66.5576\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.1149 - mean_absolute_percentage_error: 126168.5000 - val_loss: 0.0483 - val_mean_absolute_percentage_error: 60.8257\n",
            "Epoch 12/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.1038 - mean_absolute_percentage_error: 71.0811\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.1026 - mean_absolute_percentage_error: 127170.2344 - val_loss: 0.0407 - val_mean_absolute_percentage_error: 55.5914\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0912 - mean_absolute_percentage_error: 110230.9609\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0912 - mean_absolute_percentage_error: 110230.9609 - val_loss: 0.0342 - val_mean_absolute_percentage_error: 50.6772\n",
            "Epoch 14/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0877 - mean_absolute_percentage_error: 185921.2656\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0879 - mean_absolute_percentage_error: 183393.7500 - val_loss: 0.0286 - val_mean_absolute_percentage_error: 46.0748\n",
            "Epoch 15/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0837 - mean_absolute_percentage_error: 180833.7500\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0814 - mean_absolute_percentage_error: 167887.2031 - val_loss: 0.0237 - val_mean_absolute_percentage_error: 41.6008\n",
            "Epoch 16/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0727 - mean_absolute_percentage_error: 215697.2812\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0727 - mean_absolute_percentage_error: 212764.6562 - val_loss: 0.0196 - val_mean_absolute_percentage_error: 37.5425\n",
            "Epoch 17/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0708 - mean_absolute_percentage_error: 217162.6250\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0707 - mean_absolute_percentage_error: 214210.5781 - val_loss: 0.0161 - val_mean_absolute_percentage_error: 33.6837\n",
            "Epoch 18/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0645 - mean_absolute_percentage_error: 229116.9844\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0646 - mean_absolute_percentage_error: 226001.7188 - val_loss: 0.0132 - val_mean_absolute_percentage_error: 30.1101\n",
            "Epoch 19/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0688 - mean_absolute_percentage_error: 169202.9844\n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0687 - mean_absolute_percentage_error: 166902.5625 - val_loss: 0.0106 - val_mean_absolute_percentage_error: 26.5333\n",
            "Epoch 20/100\n",
            "14/18 [======================>.......] - ETA: 0s - loss: 0.0688 - mean_absolute_percentage_error: 276648.0312\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0668 - mean_absolute_percentage_error: 224745.5781 - val_loss: 0.0084 - val_mean_absolute_percentage_error: 23.0792\n",
            "Epoch 21/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0612 - mean_absolute_percentage_error: 131210.1094\n",
            "Epoch 21: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0612 - mean_absolute_percentage_error: 121819.0859 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 20.2145\n",
            "Epoch 22/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0597 - mean_absolute_percentage_error: 286602.9375\n",
            "Epoch 22: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0586 - mean_absolute_percentage_error: 266081.0000 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 17.5683\n",
            "Epoch 23/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0570 - mean_absolute_percentage_error: 241789.8906\n",
            "Epoch 23: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0560 - mean_absolute_percentage_error: 224478.2656 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 15.1826\n",
            "Epoch 24/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0512 - mean_absolute_percentage_error: 247202.9688\n",
            "Epoch 24: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0518 - mean_absolute_percentage_error: 243842.9531 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 13.6874\n",
            "Epoch 25/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0490 - mean_absolute_percentage_error: 194344.2812\n",
            "Epoch 25: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0490 - mean_absolute_percentage_error: 180429.7344 - val_loss: 0.0032 - val_mean_absolute_percentage_error: 12.5521\n",
            "Epoch 26/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0506 - mean_absolute_percentage_error: 83982.6875 \n",
            "Epoch 26: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0504 - mean_absolute_percentage_error: 77972.7656 - val_loss: 0.0027 - val_mean_absolute_percentage_error: 11.3651\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0479 - mean_absolute_percentage_error: 135243.9062\n",
            "Epoch 27: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0479 - mean_absolute_percentage_error: 135243.9062 - val_loss: 0.0024 - val_mean_absolute_percentage_error: 10.3555\n",
            "Epoch 28/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0488 - mean_absolute_percentage_error: 244790.1250\n",
            "Epoch 28: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0488 - mean_absolute_percentage_error: 227262.9219 - val_loss: 0.0021 - val_mean_absolute_percentage_error: 9.5296\n",
            "Epoch 29/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0479 - mean_absolute_percentage_error: 271533.3750\n",
            "Epoch 29: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0478 - mean_absolute_percentage_error: 267841.8750 - val_loss: 0.0018 - val_mean_absolute_percentage_error: 8.8668\n",
            "Epoch 30/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0443 - mean_absolute_percentage_error: 260126.5625\n",
            "Epoch 30: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0441 - mean_absolute_percentage_error: 256590.0781 - val_loss: 0.0017 - val_mean_absolute_percentage_error: 8.3328\n",
            "Epoch 31/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0470 - mean_absolute_percentage_error: 222009.7812\n",
            "Epoch 31: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0467 - mean_absolute_percentage_error: 218991.6562 - val_loss: 0.0015 - val_mean_absolute_percentage_error: 7.9276\n",
            "Epoch 32/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0475 - mean_absolute_percentage_error: 215847.7500\n",
            "Epoch 32: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0479 - mean_absolute_percentage_error: 187876.5156 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 7.4329\n",
            "Epoch 33/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0443 - mean_absolute_percentage_error: 140294.9219\n",
            "Epoch 33: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0434 - mean_absolute_percentage_error: 130252.0000 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.3006\n",
            "Epoch 34/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0419 - mean_absolute_percentage_error: 87.9270\n",
            "Epoch 34: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0419 - mean_absolute_percentage_error: 171888.0938 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.1876\n",
            "Epoch 35/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0411 - mean_absolute_percentage_error: 93580.3438\n",
            "Epoch 35: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0407 - mean_absolute_percentage_error: 92308.9141 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 7.0934\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0390 - mean_absolute_percentage_error: 165276.1562\n",
            "Epoch 36: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0390 - mean_absolute_percentage_error: 165276.1562 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 7.0551\n",
            "Epoch 37/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0381 - mean_absolute_percentage_error: 204084.6250\n",
            "Epoch 37: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0379 - mean_absolute_percentage_error: 201309.9531 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 6.8834\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0369 - mean_absolute_percentage_error: 202006.4062\n",
            "Epoch 38: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.0369 - mean_absolute_percentage_error: 202006.4062 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 6.6050\n",
            "Epoch 39/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0355 - mean_absolute_percentage_error: 153989.3594\n",
            "Epoch 39: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0354 - mean_absolute_percentage_error: 151896.1406 - val_loss: 9.9993e-04 - val_mean_absolute_percentage_error: 6.3793\n",
            "Epoch 40/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0315 - mean_absolute_percentage_error: 277253.0625\n",
            "Epoch 40: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0313 - mean_absolute_percentage_error: 273483.3438 - val_loss: 9.5345e-04 - val_mean_absolute_percentage_error: 6.2296\n",
            "Epoch 41/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0328 - mean_absolute_percentage_error: 134957.3594\n",
            "Epoch 41: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0332 - mean_absolute_percentage_error: 133123.2656 - val_loss: 9.7066e-04 - val_mean_absolute_percentage_error: 6.3573\n",
            "Epoch 42/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0364 - mean_absolute_percentage_error: 212824.7344\n",
            "Epoch 42: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0361 - mean_absolute_percentage_error: 209931.2344 - val_loss: 9.3202e-04 - val_mean_absolute_percentage_error: 6.2430\n",
            "Epoch 43/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0313 - mean_absolute_percentage_error: 190219.5938\n",
            "Epoch 43: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0312 - mean_absolute_percentage_error: 187633.4062 - val_loss: 9.3444e-04 - val_mean_absolute_percentage_error: 6.3111\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0329 - mean_absolute_percentage_error: 195634.7500\n",
            "Epoch 44: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0329 - mean_absolute_percentage_error: 195634.7500 - val_loss: 8.7784e-04 - val_mean_absolute_percentage_error: 6.1051\n",
            "Epoch 45/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0322 - mean_absolute_percentage_error: 73.9758\n",
            "Epoch 45: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0320 - mean_absolute_percentage_error: 177242.9688 - val_loss: 8.6746e-04 - val_mean_absolute_percentage_error: 6.1150\n",
            "Epoch 46/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0292 - mean_absolute_percentage_error: 179635.4844\n",
            "Epoch 46: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0294 - mean_absolute_percentage_error: 177193.5000 - val_loss: 8.3789e-04 - val_mean_absolute_percentage_error: 6.0311\n",
            "Epoch 47/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0308 - mean_absolute_percentage_error: 151717.0156\n",
            "Epoch 47: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0292 - mean_absolute_percentage_error: 132054.6719 - val_loss: 7.9636e-04 - val_mean_absolute_percentage_error: 5.8819\n",
            "Epoch 48/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0271 - mean_absolute_percentage_error: 131458.1406\n",
            "Epoch 48: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0271 - mean_absolute_percentage_error: 129671.3516 - val_loss: 8.0986e-04 - val_mean_absolute_percentage_error: 6.0109\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0283 - mean_absolute_percentage_error: 219428.1562\n",
            "Epoch 49: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0283 - mean_absolute_percentage_error: 219428.1562 - val_loss: 7.8672e-04 - val_mean_absolute_percentage_error: 5.9549\n",
            "Epoch 50/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0257 - mean_absolute_percentage_error: 186523.5312\n",
            "Epoch 50: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0249 - mean_absolute_percentage_error: 173168.5000 - val_loss: 7.8456e-04 - val_mean_absolute_percentage_error: 6.0053\n",
            "Epoch 51/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0232 - mean_absolute_percentage_error: 133376.7812\n",
            "Epoch 51: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0232 - mean_absolute_percentage_error: 131563.9531 - val_loss: 8.1137e-04 - val_mean_absolute_percentage_error: 6.2034\n",
            "Epoch 52/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0260 - mean_absolute_percentage_error: 202680.0000\n",
            "Epoch 52: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0255 - mean_absolute_percentage_error: 188167.8281 - val_loss: 7.3785e-04 - val_mean_absolute_percentage_error: 5.8841\n",
            "Epoch 53/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0251 - mean_absolute_percentage_error: 154717.1719\n",
            "Epoch 53: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0249 - mean_absolute_percentage_error: 143642.7031 - val_loss: 6.9109e-04 - val_mean_absolute_percentage_error: 5.6883\n",
            "Epoch 54/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0229 - mean_absolute_percentage_error: 57.4367\n",
            "Epoch 54: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0231 - mean_absolute_percentage_error: 95760.7656 - val_loss: 6.7663e-04 - val_mean_absolute_percentage_error: 5.6682\n",
            "Epoch 55/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0229 - mean_absolute_percentage_error: 85022.0859 \n",
            "Epoch 55: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0228 - mean_absolute_percentage_error: 83866.6875 - val_loss: 6.5950e-04 - val_mean_absolute_percentage_error: 5.6293\n",
            "Epoch 56/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0222 - mean_absolute_percentage_error: 175483.9844\n",
            "Epoch 56: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0222 - mean_absolute_percentage_error: 162919.4219 - val_loss: 7.1251e-04 - val_mean_absolute_percentage_error: 5.9876\n",
            "Epoch 57/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0227 - mean_absolute_percentage_error: 133404.1562\n",
            "Epoch 57: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0224 - mean_absolute_percentage_error: 123852.5312 - val_loss: 7.5437e-04 - val_mean_absolute_percentage_error: 6.2613\n",
            "Epoch 58/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0209 - mean_absolute_percentage_error: 127964.8438\n",
            "Epoch 58: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0203 - mean_absolute_percentage_error: 118802.6406 - val_loss: 8.2295e-04 - val_mean_absolute_percentage_error: 6.6572\n",
            "Epoch 58: early stopping\n",
            "Train Loss Terendah:  0.020295361056923866\n",
            "Epoch Stop:  57\n",
            "Val Loss Terendah:  0.0006594951846636832\n",
            "Epoch Val Loss Stop:  55\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0818 - mean_absolute_percentage_error: 16905.1875\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 3s 48ms/step - loss: 0.0820 - mean_absolute_percentage_error: 16676.1738 - val_loss: 0.0505 - val_mean_absolute_percentage_error: 63.3442\n",
            "Epoch 2/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0653 - mean_absolute_percentage_error: 48351.7148\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0653 - mean_absolute_percentage_error: 47694.7969 - val_loss: 0.0349 - val_mean_absolute_percentage_error: 52.3828\n",
            "Epoch 3/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0496 - mean_absolute_percentage_error: 43.5583\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0497 - mean_absolute_percentage_error: 61715.2148 - val_loss: 0.0228 - val_mean_absolute_percentage_error: 42.0329\n",
            "Epoch 4/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0393 - mean_absolute_percentage_error: 71383.2812\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0383 - mean_absolute_percentage_error: 62134.1016 - val_loss: 0.0140 - val_mean_absolute_percentage_error: 32.5683\n",
            "Epoch 5/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0294 - mean_absolute_percentage_error: 90176.7578 \n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0297 - mean_absolute_percentage_error: 83720.9688 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 24.0555\n",
            "Epoch 6/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0229 - mean_absolute_percentage_error: 103620.0156\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.0234 - mean_absolute_percentage_error: 96201.2500 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 16.9169\n",
            "Epoch 7/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0211 - mean_absolute_percentage_error: 43.5453\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0202 - mean_absolute_percentage_error: 122383.2422 - val_loss: 0.0021 - val_mean_absolute_percentage_error: 11.1515\n",
            "Epoch 8/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0188 - mean_absolute_percentage_error: 143695.9062\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0187 - mean_absolute_percentage_error: 141742.3906 - val_loss: 9.8354e-04 - val_mean_absolute_percentage_error: 7.1426\n",
            "Epoch 9/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0170 - mean_absolute_percentage_error: 120646.8281\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0171 - mean_absolute_percentage_error: 112009.9844 - val_loss: 5.5979e-04 - val_mean_absolute_percentage_error: 5.0339\n",
            "Epoch 10/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0184 - mean_absolute_percentage_error: 52.9583\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0177 - mean_absolute_percentage_error: 147855.0625 - val_loss: 4.1594e-04 - val_mean_absolute_percentage_error: 4.2706\n",
            "Epoch 11/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0143 - mean_absolute_percentage_error: 49.4250\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0142 - mean_absolute_percentage_error: 154048.8906 - val_loss: 3.8458e-04 - val_mean_absolute_percentage_error: 4.1823\n",
            "Epoch 12/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0148 - mean_absolute_percentage_error: 109172.6484\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0147 - mean_absolute_percentage_error: 101357.5391 - val_loss: 3.7149e-04 - val_mean_absolute_percentage_error: 4.1725\n",
            "Epoch 13/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0129 - mean_absolute_percentage_error: 158221.2344\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0128 - mean_absolute_percentage_error: 156070.6719 - val_loss: 3.5637e-04 - val_mean_absolute_percentage_error: 4.0419\n",
            "Epoch 14/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0117 - mean_absolute_percentage_error: 109588.5078\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0119 - mean_absolute_percentage_error: 108098.7812 - val_loss: 3.4678e-04 - val_mean_absolute_percentage_error: 3.9846\n",
            "Epoch 15/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0134 - mean_absolute_percentage_error: 139410.8750\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.0129 - mean_absolute_percentage_error: 129428.6875 - val_loss: 3.3259e-04 - val_mean_absolute_percentage_error: 3.9243\n",
            "Epoch 16/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0121 - mean_absolute_percentage_error: 108004.6562\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0120 - mean_absolute_percentage_error: 106536.2578 - val_loss: 3.2170e-04 - val_mean_absolute_percentage_error: 3.8726\n",
            "Epoch 17/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0116 - mean_absolute_percentage_error: 107368.4453\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0115 - mean_absolute_percentage_error: 99681.2266 - val_loss: 3.1034e-04 - val_mean_absolute_percentage_error: 3.8407\n",
            "Epoch 18/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0106 - mean_absolute_percentage_error: 118014.8438\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0106 - mean_absolute_percentage_error: 109564.4062 - val_loss: 3.0196e-04 - val_mean_absolute_percentage_error: 3.8049\n",
            "Epoch 19/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0100 - mean_absolute_percentage_error: 92991.9375 \n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0102 - mean_absolute_percentage_error: 86334.3047 - val_loss: 2.9419e-04 - val_mean_absolute_percentage_error: 3.7685\n",
            "Epoch 20/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0100 - mean_absolute_percentage_error: 85291.9297 \n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0099 - mean_absolute_percentage_error: 84132.4766 - val_loss: 2.8462e-04 - val_mean_absolute_percentage_error: 3.7172\n",
            "Epoch 21/100\n",
            "15/18 [========================>.....] - ETA: 0s - loss: 0.0096 - mean_absolute_percentage_error: 108260.6016\n",
            "Epoch 21: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0094 - mean_absolute_percentage_error: 94228.6875 - val_loss: 2.9479e-04 - val_mean_absolute_percentage_error: 3.8384\n",
            "Epoch 22/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0097 - mean_absolute_percentage_error: 87091.8359 \n",
            "Epoch 22: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0096 - mean_absolute_percentage_error: 80856.0391 - val_loss: 3.0062e-04 - val_mean_absolute_percentage_error: 3.9212\n",
            "Epoch 23/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0090 - mean_absolute_percentage_error: 91804.0469 \n",
            "Epoch 23: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0087 - mean_absolute_percentage_error: 85230.6250 - val_loss: 2.8929e-04 - val_mean_absolute_percentage_error: 3.8625\n",
            "Epoch 23: early stopping\n",
            "Train Loss Terendah:  0.008730030618607998\n",
            "Epoch Stop:  22\n",
            "Val Loss Terendah:  0.0002846211427822709\n",
            "Epoch Val Loss Stop:  20\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 64, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.1677 - mean_absolute_percentage_error: 15214.7295\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 4s 52ms/step - loss: 0.1653 - mean_absolute_percentage_error: 14131.0312 - val_loss: 0.1055 - val_mean_absolute_percentage_error: 91.6555\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.1253 - mean_absolute_percentage_error: 53466.3516\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.1253 - mean_absolute_percentage_error: 53466.3516 - val_loss: 0.0746 - val_mean_absolute_percentage_error: 76.7903\n",
            "Epoch 3/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0981 - mean_absolute_percentage_error: 86248.1562\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0965 - mean_absolute_percentage_error: 80074.2812 - val_loss: 0.0496 - val_mean_absolute_percentage_error: 62.2324\n",
            "Epoch 4/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0733 - mean_absolute_percentage_error: 101460.5859\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0723 - mean_absolute_percentage_error: 94197.2422 - val_loss: 0.0299 - val_mean_absolute_percentage_error: 47.8423\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - ETA: 0s - loss: 0.0502 - mean_absolute_percentage_error: 148699.5781\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0502 - mean_absolute_percentage_error: 148699.5781 - val_loss: 0.0158 - val_mean_absolute_percentage_error: 34.0334\n",
            "Epoch 6/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0365 - mean_absolute_percentage_error: 136700.6719\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 21ms/step - loss: 0.0371 - mean_absolute_percentage_error: 126913.2891 - val_loss: 0.0066 - val_mean_absolute_percentage_error: 20.8126\n",
            "Epoch 7/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0254 - mean_absolute_percentage_error: 144240.0000\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0258 - mean_absolute_percentage_error: 142279.3438 - val_loss: 0.0020 - val_mean_absolute_percentage_error: 9.9172\n",
            "Epoch 8/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0226 - mean_absolute_percentage_error: 172869.5156\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0223 - mean_absolute_percentage_error: 160493.0781 - val_loss: 6.8504e-04 - val_mean_absolute_percentage_error: 5.3947\n",
            "Epoch 9/100\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.0191 - mean_absolute_percentage_error: 149911.6250\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.0191 - mean_absolute_percentage_error: 147873.8750 - val_loss: 7.5072e-04 - val_mean_absolute_percentage_error: 6.5727\n",
            "Epoch 10/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0181 - mean_absolute_percentage_error: 73.6934\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0178 - mean_absolute_percentage_error: 211706.0312 - val_loss: 8.4910e-04 - val_mean_absolute_percentage_error: 7.2369\n",
            "Epoch 11/100\n",
            "16/18 [=========================>....] - ETA: 0s - loss: 0.0159 - mean_absolute_percentage_error: 67.8492\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.0157 - mean_absolute_percentage_error: 201711.2344 - val_loss: 6.9220e-04 - val_mean_absolute_percentage_error: 6.2672\n",
            "Epoch 11: early stopping\n",
            "Train Loss Terendah:  0.015722697600722313\n",
            "Epoch Stop:  10\n",
            "Val Loss Terendah:  0.0006850374047644436\n",
            "Epoch Val Loss Stop:  8\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0893 - mean_absolute_percentage_error: 218006.1406\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 3s 87ms/step - loss: 0.0893 - mean_absolute_percentage_error: 218006.1406 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 26.6523\n",
            "Epoch 2/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0248 - mean_absolute_percentage_error: 93827.9141\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0243 - mean_absolute_percentage_error: 87111.0391 - val_loss: 0.0098 - val_mean_absolute_percentage_error: 27.5983\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0149 - mean_absolute_percentage_error: 112480.2422\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0149 - mean_absolute_percentage_error: 112480.2422 - val_loss: 0.0015 - val_mean_absolute_percentage_error: 10.5463\n",
            "Epoch 4/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0113 - mean_absolute_percentage_error: 160220.6094\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0108 - mean_absolute_percentage_error: 130157.5078 - val_loss: 0.0021 - val_mean_absolute_percentage_error: 12.5159\n",
            "Epoch 5/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0087 - mean_absolute_percentage_error: 14045.6426\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0088 - mean_absolute_percentage_error: 11414.3311 - val_loss: 1.8760e-04 - val_mean_absolute_percentage_error: 2.9690\n",
            "Epoch 6/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0079 - mean_absolute_percentage_error: 55149.9297\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0078 - mean_absolute_percentage_error: 44806.2930 - val_loss: 1.6230e-04 - val_mean_absolute_percentage_error: 2.9160\n",
            "Epoch 7/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0069 - mean_absolute_percentage_error: 47209.1484\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0067 - mean_absolute_percentage_error: 43829.4531 - val_loss: 2.9824e-04 - val_mean_absolute_percentage_error: 4.2488\n",
            "Epoch 8/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0061 - mean_absolute_percentage_error: 5712.9023 \n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0060 - mean_absolute_percentage_error: 5304.9629 - val_loss: 1.5171e-04 - val_mean_absolute_percentage_error: 2.7808\n",
            "Epoch 9/50\n",
            "6/9 [===================>..........] - ETA: 0s - loss: 0.0064 - mean_absolute_percentage_error: 42158.4258\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0065 - mean_absolute_percentage_error: 29360.9082 - val_loss: 1.9471e-04 - val_mean_absolute_percentage_error: 3.2762\n",
            "Epoch 10/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0058 - mean_absolute_percentage_error: 23.8236\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0055 - mean_absolute_percentage_error: 30171.8086 - val_loss: 1.8550e-04 - val_mean_absolute_percentage_error: 3.1919\n",
            "Epoch 11/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0061 - mean_absolute_percentage_error: 20.5524\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0062 - mean_absolute_percentage_error: 58030.5352 - val_loss: 2.2413e-04 - val_mean_absolute_percentage_error: 3.6050\n",
            "Epoch 11: early stopping\n",
            "Train Loss Terendah:  0.005540957674384117\n",
            "Epoch Stop:  9\n",
            "Val Loss Terendah:  0.00015170978440437466\n",
            "Epoch Val Loss Stop:  8\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0500 - mean_absolute_percentage_error: 252509.4531\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 3s 108ms/step - loss: 0.0437 - mean_absolute_percentage_error: 205126.4531 - val_loss: 0.0124 - val_mean_absolute_percentage_error: 31.1689\n",
            "Epoch 2/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0132 - mean_absolute_percentage_error: 30.2675\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0130 - mean_absolute_percentage_error: 85796.1875 - val_loss: 0.0024 - val_mean_absolute_percentage_error: 13.4377\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0071 - mean_absolute_percentage_error: 4665.8423\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0071 - mean_absolute_percentage_error: 4665.8423 - val_loss: 7.4572e-04 - val_mean_absolute_percentage_error: 7.2016\n",
            "Epoch 4/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0048 - mean_absolute_percentage_error: 11245.6484\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0046 - mean_absolute_percentage_error: 10441.3379 - val_loss: 2.6791e-04 - val_mean_absolute_percentage_error: 3.9891\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_percentage_error: 68892.5391\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0044 - mean_absolute_percentage_error: 68892.5391 - val_loss: 2.2717e-04 - val_mean_absolute_percentage_error: 3.3344\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_percentage_error: 11902.3057\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_absolute_percentage_error: 11902.3057 - val_loss: 2.8178e-04 - val_mean_absolute_percentage_error: 4.1611\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0036 - mean_absolute_percentage_error: 16253.6973\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_absolute_percentage_error: 16253.6973 - val_loss: 3.3561e-04 - val_mean_absolute_percentage_error: 4.6073\n",
            "Epoch 8/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_absolute_percentage_error: 9014.2344 \n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_absolute_percentage_error: 8369.6621 - val_loss: 1.4301e-04 - val_mean_absolute_percentage_error: 2.7591\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 66565.1953\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_absolute_percentage_error: 66565.1953 - val_loss: 2.0783e-04 - val_mean_absolute_percentage_error: 3.2119\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 16801.4844\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_absolute_percentage_error: 16801.4844 - val_loss: 1.5630e-04 - val_mean_absolute_percentage_error: 2.9999\n",
            "Epoch 11/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 14.0725\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0027 - mean_absolute_percentage_error: 19324.6367 - val_loss: 1.6948e-04 - val_mean_absolute_percentage_error: 3.1216\n",
            "Epoch 11: early stopping\n",
            "Train Loss Terendah:  0.0026740003377199173\n",
            "Epoch Stop:  10\n",
            "Val Loss Terendah:  0.0001430061092833057\n",
            "Epoch Val Loss Stop:  8\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0190 - mean_absolute_percentage_error: 32943.2734\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 4s 109ms/step - loss: 0.0180 - mean_absolute_percentage_error: 30586.5098 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 19.3045\n",
            "Epoch 2/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0061 - mean_absolute_percentage_error: 1545.5914\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.0059 - mean_absolute_percentage_error: 1435.8815 - val_loss: 4.8776e-04 - val_mean_absolute_percentage_error: 5.2792\n",
            "Epoch 3/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0038 - mean_absolute_percentage_error: 32707.1270\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.0038 - mean_absolute_percentage_error: 30366.0176 - val_loss: 0.0018 - val_mean_absolute_percentage_error: 11.6885\n",
            "Epoch 4/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 26944.0020\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.0031 - mean_absolute_percentage_error: 25015.0762 - val_loss: 9.1651e-04 - val_mean_absolute_percentage_error: 8.1049\n",
            "Epoch 5/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 34811.0898\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.0024 - mean_absolute_percentage_error: 32318.7207 - val_loss: 2.7336e-04 - val_mean_absolute_percentage_error: 4.1114\n",
            "Epoch 6/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0019 - mean_absolute_percentage_error: 24488.5566\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.0021 - mean_absolute_percentage_error: 22735.6582 - val_loss: 1.9175e-04 - val_mean_absolute_percentage_error: 3.3105\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_percentage_error: 29256.1699\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0019 - mean_absolute_percentage_error: 29256.1699 - val_loss: 1.5653e-04 - val_mean_absolute_percentage_error: 2.7504\n",
            "Epoch 8/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0018 - mean_absolute_percentage_error: 15103.8271\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.0017 - mean_absolute_percentage_error: 14022.6572 - val_loss: 1.6264e-04 - val_mean_absolute_percentage_error: 3.0589\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_percentage_error: 13601.6279\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.0019 - mean_absolute_percentage_error: 13601.6279 - val_loss: 1.5927e-04 - val_mean_absolute_percentage_error: 2.7678\n",
            "Epoch 10/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0018 - mean_absolute_percentage_error: 10.1738\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.0018 - mean_absolute_percentage_error: 39781.2930 - val_loss: 2.3998e-04 - val_mean_absolute_percentage_error: 3.4962\n",
            "Epoch 10: early stopping\n",
            "Train Loss Terendah:  0.001738480874337256\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.0001565311977174133\n",
            "Epoch Val Loss Stop:  7\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1295 - mean_absolute_percentage_error: 17855.0918\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 7s 145ms/step - loss: 0.1254 - mean_absolute_percentage_error: 16580.4492 - val_loss: 0.0543 - val_mean_absolute_percentage_error: 65.2956\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0781 - mean_absolute_percentage_error: 136224.0312\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0781 - mean_absolute_percentage_error: 136224.0312 - val_loss: 0.0175 - val_mean_absolute_percentage_error: 35.9881\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0532 - mean_absolute_percentage_error: 61096.3984\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0532 - mean_absolute_percentage_error: 61096.3984 - val_loss: 0.0027 - val_mean_absolute_percentage_error: 11.9070\n",
            "Epoch 4/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0384 - mean_absolute_percentage_error: 269900.0625\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0392 - mean_absolute_percentage_error: 219264.7188 - val_loss: 6.8043e-04 - val_mean_absolute_percentage_error: 5.7194\n",
            "Epoch 5/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0363 - mean_absolute_percentage_error: 244587.6406\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0347 - mean_absolute_percentage_error: 198699.3125 - val_loss: 5.9956e-04 - val_mean_absolute_percentage_error: 5.2793\n",
            "Epoch 6/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0327 - mean_absolute_percentage_error: 167446.7812\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0325 - mean_absolute_percentage_error: 136035.0469 - val_loss: 8.0096e-04 - val_mean_absolute_percentage_error: 6.1148\n",
            "Epoch 7/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0259 - mean_absolute_percentage_error: 58.1716\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0267 - mean_absolute_percentage_error: 107116.4688 - val_loss: 0.0010 - val_mean_absolute_percentage_error: 7.4771\n",
            "Epoch 8/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0270 - mean_absolute_percentage_error: 204935.1562\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0257 - mean_absolute_percentage_error: 166487.7188 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 7.8461\n",
            "Epoch 8: early stopping\n",
            "Train Loss Terendah:  0.025663897395133972\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.0005995562532916665\n",
            "Epoch Val Loss Stop:  5\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2023 - mean_absolute_percentage_error: 35082.5352\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 3s 91ms/step - loss: 0.1913 - mean_absolute_percentage_error: 28512.3340 - val_loss: 0.0842 - val_mean_absolute_percentage_error: 81.3597\n",
            "Epoch 2/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1075 - mean_absolute_percentage_error: 63.4535\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0998 - mean_absolute_percentage_error: 147146.2969 - val_loss: 0.0228 - val_mean_absolute_percentage_error: 40.8980\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0476 - mean_absolute_percentage_error: 172260.8750\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0476 - mean_absolute_percentage_error: 172260.8750 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 7.1415\n",
            "Epoch 4/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0349 - mean_absolute_percentage_error: 287785.4062\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0342 - mean_absolute_percentage_error: 233797.8125 - val_loss: 0.0038 - val_mean_absolute_percentage_error: 16.9203\n",
            "Epoch 5/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0304 - mean_absolute_percentage_error: 255740.7500\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0299 - mean_absolute_percentage_error: 207763.3594 - val_loss: 0.0020 - val_mean_absolute_percentage_error: 12.1615\n",
            "Epoch 6/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0248 - mean_absolute_percentage_error: 270202.4688\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0251 - mean_absolute_percentage_error: 219508.4219 - val_loss: 6.4977e-04 - val_mean_absolute_percentage_error: 5.7752\n",
            "Epoch 7/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0177 - mean_absolute_percentage_error: 192852.9062\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0176 - mean_absolute_percentage_error: 179047.7500 - val_loss: 5.3450e-04 - val_mean_absolute_percentage_error: 4.8294\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0158 - mean_absolute_percentage_error: 123616.7812\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0158 - mean_absolute_percentage_error: 123616.7812 - val_loss: 4.5213e-04 - val_mean_absolute_percentage_error: 4.7496\n",
            "Epoch 9/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0112 - mean_absolute_percentage_error: 177441.4688\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0113 - mean_absolute_percentage_error: 144149.2656 - val_loss: 3.6800e-04 - val_mean_absolute_percentage_error: 4.2241\n",
            "Epoch 10/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0089 - mean_absolute_percentage_error: 39.4462\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0084 - mean_absolute_percentage_error: 107362.7344 - val_loss: 3.1043e-04 - val_mean_absolute_percentage_error: 3.9504\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0062 - mean_absolute_percentage_error: 60297.9453\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_absolute_percentage_error: 60297.9453 - val_loss: 5.0446e-04 - val_mean_absolute_percentage_error: 5.5705\n",
            "Epoch 12/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0053 - mean_absolute_percentage_error: 19.8304\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0053 - mean_absolute_percentage_error: 25071.8477 - val_loss: 5.6685e-04 - val_mean_absolute_percentage_error: 5.9938\n",
            "Epoch 13/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0056 - mean_absolute_percentage_error: 51886.9023\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0054 - mean_absolute_percentage_error: 42152.7422 - val_loss: 5.1213e-04 - val_mean_absolute_percentage_error: 5.6631\n",
            "Epoch 13: early stopping\n",
            "Train Loss Terendah:  0.005282608792185783\n",
            "Epoch Stop:  11\n",
            "Val Loss Terendah:  0.00031043204944580793\n",
            "Epoch Val Loss Stop:  10\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0834 - mean_absolute_percentage_error: 66254.3281\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 4s 104ms/step - loss: 0.0834 - mean_absolute_percentage_error: 66254.3281 - val_loss: 0.0020 - val_mean_absolute_percentage_error: 10.2380\n",
            "Epoch 2/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0213 - mean_absolute_percentage_error: 226134.8125\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.0212 - mean_absolute_percentage_error: 209948.6406 - val_loss: 0.0124 - val_mean_absolute_percentage_error: 32.1750\n",
            "Epoch 3/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0148 - mean_absolute_percentage_error: 149474.2500\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.0143 - mean_absolute_percentage_error: 138771.8281 - val_loss: 3.9598e-04 - val_mean_absolute_percentage_error: 4.3836\n",
            "Epoch 4/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0096 - mean_absolute_percentage_error: 109522.6797\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.0093 - mean_absolute_percentage_error: 101680.2344 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 9.0246\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0061 - mean_absolute_percentage_error: 68757.7812\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.0061 - mean_absolute_percentage_error: 68757.7812 - val_loss: 2.9073e-04 - val_mean_absolute_percentage_error: 3.8605\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0045 - mean_absolute_percentage_error: 56404.8555\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.0045 - mean_absolute_percentage_error: 56404.8555 - val_loss: 4.5795e-04 - val_mean_absolute_percentage_error: 4.6935\n",
            "Epoch 7/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0044 - mean_absolute_percentage_error: 34035.0117\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.0043 - mean_absolute_percentage_error: 31598.9707 - val_loss: 4.4822e-04 - val_mean_absolute_percentage_error: 5.2405\n",
            "Epoch 8/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0038 - mean_absolute_percentage_error: 44287.2734\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0037 - mean_absolute_percentage_error: 41116.0742 - val_loss: 2.9324e-04 - val_mean_absolute_percentage_error: 3.8720\n",
            "Epoch 8: early stopping\n",
            "Train Loss Terendah:  0.0036953194066882133\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.0002907262241933495\n",
            "Epoch Val Loss Stop:  5\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2535 - mean_absolute_percentage_error: 2664.6943\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 3s 90ms/step - loss: 0.2498 - mean_absolute_percentage_error: 2482.1228 - val_loss: 0.1847 - val_mean_absolute_percentage_error: 121.5796\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2455 - mean_absolute_percentage_error: 2730.0720\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.2455 - mean_absolute_percentage_error: 2730.0720 - val_loss: 0.1741 - val_mean_absolute_percentage_error: 117.9862\n",
            "Epoch 3/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2257 - mean_absolute_percentage_error: 112.2617\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.2268 - mean_absolute_percentage_error: 25016.1191 - val_loss: 0.1640 - val_mean_absolute_percentage_error: 114.4315\n",
            "Epoch 4/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2255 - mean_absolute_percentage_error: 29550.0020\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.2262 - mean_absolute_percentage_error: 24024.3145 - val_loss: 0.1543 - val_mean_absolute_percentage_error: 110.9094\n",
            "Epoch 5/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2035 - mean_absolute_percentage_error: 47774.2227\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2024 - mean_absolute_percentage_error: 38826.8164 - val_loss: 0.1449 - val_mean_absolute_percentage_error: 107.4391\n",
            "Epoch 6/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1968 - mean_absolute_percentage_error: 24353.8965\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1984 - mean_absolute_percentage_error: 22616.2402 - val_loss: 0.1360 - val_mean_absolute_percentage_error: 104.0055\n",
            "Epoch 7/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1888 - mean_absolute_percentage_error: 90.1710\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.1865 - mean_absolute_percentage_error: 37620.1367 - val_loss: 0.1274 - val_mean_absolute_percentage_error: 100.5850\n",
            "Epoch 8/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1934 - mean_absolute_percentage_error: 85616.0703 \n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.1887 - mean_absolute_percentage_error: 69566.5312 - val_loss: 0.1191 - val_mean_absolute_percentage_error: 97.1629\n",
            "Epoch 9/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1731 - mean_absolute_percentage_error: 108074.2656\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1733 - mean_absolute_percentage_error: 87806.6094 - val_loss: 0.1112 - val_mean_absolute_percentage_error: 93.8129\n",
            "Epoch 10/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1685 - mean_absolute_percentage_error: 79.7620\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1641 - mean_absolute_percentage_error: 51105.3320 - val_loss: 0.1036 - val_mean_absolute_percentage_error: 90.4613\n",
            "Epoch 11/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1666 - mean_absolute_percentage_error: 75.7144\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1640 - mean_absolute_percentage_error: 62796.0391 - val_loss: 0.0964 - val_mean_absolute_percentage_error: 87.1678\n",
            "Epoch 12/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1438 - mean_absolute_percentage_error: 75.3041\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1408 - mean_absolute_percentage_error: 72554.6484 - val_loss: 0.0895 - val_mean_absolute_percentage_error: 83.9063\n",
            "Epoch 13/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1426 - mean_absolute_percentage_error: 112381.6719\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.1409 - mean_absolute_percentage_error: 91304.5781 - val_loss: 0.0830 - val_mean_absolute_percentage_error: 80.7246\n",
            "Epoch 14/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1443 - mean_absolute_percentage_error: 139295.7031\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.1376 - mean_absolute_percentage_error: 113166.2188 - val_loss: 0.0768 - val_mean_absolute_percentage_error: 77.5188\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1314 - mean_absolute_percentage_error: 80366.6328\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.1314 - mean_absolute_percentage_error: 80366.6328 - val_loss: 0.0708 - val_mean_absolute_percentage_error: 74.3470\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1261 - mean_absolute_percentage_error: 62019.7773\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.1261 - mean_absolute_percentage_error: 62019.7773 - val_loss: 0.0651 - val_mean_absolute_percentage_error: 71.2004\n",
            "Epoch 17/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1292 - mean_absolute_percentage_error: 114704.7969\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.1330 - mean_absolute_percentage_error: 93190.0391 - val_loss: 0.0598 - val_mean_absolute_percentage_error: 68.0772\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1118 - mean_absolute_percentage_error: 141403.6250\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.1118 - mean_absolute_percentage_error: 141403.6250 - val_loss: 0.0547 - val_mean_absolute_percentage_error: 65.0304\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1090 - mean_absolute_percentage_error: 86309.3359 \n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.1090 - mean_absolute_percentage_error: 86309.3359 - val_loss: 0.0500 - val_mean_absolute_percentage_error: 62.0208\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1025 - mean_absolute_percentage_error: 186773.4219\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.1025 - mean_absolute_percentage_error: 186773.4219 - val_loss: 0.0454 - val_mean_absolute_percentage_error: 58.9846\n",
            "Epoch 21/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1015 - mean_absolute_percentage_error: 159711.6562\n",
            "Epoch 21: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0988 - mean_absolute_percentage_error: 129749.8047 - val_loss: 0.0413 - val_mean_absolute_percentage_error: 56.0970\n",
            "Epoch 22/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0860 - mean_absolute_percentage_error: 202939.7969\n",
            "Epoch 22: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0864 - mean_absolute_percentage_error: 164865.4688 - val_loss: 0.0374 - val_mean_absolute_percentage_error: 53.2690\n",
            "Epoch 23/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0924 - mean_absolute_percentage_error: 185420.7969\n",
            "Epoch 23: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0884 - mean_absolute_percentage_error: 150635.0625 - val_loss: 0.0338 - val_mean_absolute_percentage_error: 50.4501\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0868 - mean_absolute_percentage_error: 189533.6406\n",
            "Epoch 24: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0868 - mean_absolute_percentage_error: 189533.6406 - val_loss: 0.0304 - val_mean_absolute_percentage_error: 47.7303\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0828 - mean_absolute_percentage_error: 174755.5156\n",
            "Epoch 25: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0828 - mean_absolute_percentage_error: 174755.5156 - val_loss: 0.0273 - val_mean_absolute_percentage_error: 45.0671\n",
            "Epoch 26/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0804 - mean_absolute_percentage_error: 116710.5859\n",
            "Epoch 26: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0796 - mean_absolute_percentage_error: 94819.5312 - val_loss: 0.0244 - val_mean_absolute_percentage_error: 42.3782\n",
            "Epoch 27/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0765 - mean_absolute_percentage_error: 76.0269\n",
            "Epoch 27: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0775 - mean_absolute_percentage_error: 201590.3750 - val_loss: 0.0217 - val_mean_absolute_percentage_error: 39.7694\n",
            "Epoch 28/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0756 - mean_absolute_percentage_error: 166036.8438\n",
            "Epoch 28: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0771 - mean_absolute_percentage_error: 154149.7500 - val_loss: 0.0192 - val_mean_absolute_percentage_error: 37.2219\n",
            "Epoch 29/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0710 - mean_absolute_percentage_error: 71.0673\n",
            "Epoch 29: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0718 - mean_absolute_percentage_error: 203719.4531 - val_loss: 0.0170 - val_mean_absolute_percentage_error: 34.7626\n",
            "Epoch 30/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0759 - mean_absolute_percentage_error: 76.5962\n",
            "Epoch 30: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0745 - mean_absolute_percentage_error: 180940.7188 - val_loss: 0.0150 - val_mean_absolute_percentage_error: 32.3892\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0635 - mean_absolute_percentage_error: 199631.3281\n",
            "Epoch 31: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0635 - mean_absolute_percentage_error: 199631.3281 - val_loss: 0.0131 - val_mean_absolute_percentage_error: 30.1114\n",
            "Epoch 32/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0689 - mean_absolute_percentage_error: 275282.5625\n",
            "Epoch 32: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0676 - mean_absolute_percentage_error: 223639.9688 - val_loss: 0.0115 - val_mean_absolute_percentage_error: 27.8932\n",
            "Epoch 33/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0633 - mean_absolute_percentage_error: 173875.5312\n",
            "Epoch 33: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0638 - mean_absolute_percentage_error: 141258.2969 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 25.8356\n",
            "Epoch 34/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0662 - mean_absolute_percentage_error: 87.8065\n",
            "Epoch 34: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0662 - mean_absolute_percentage_error: 188328.1562 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 23.8795\n",
            "Epoch 35/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0565 - mean_absolute_percentage_error: 85.7534\n",
            "Epoch 35: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0561 - mean_absolute_percentage_error: 262972.7500 - val_loss: 0.0077 - val_mean_absolute_percentage_error: 22.0126\n",
            "Epoch 36/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0602 - mean_absolute_percentage_error: 247831.2812\n",
            "Epoch 36: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0579 - mean_absolute_percentage_error: 201336.4688 - val_loss: 0.0067 - val_mean_absolute_percentage_error: 20.2450\n",
            "Epoch 37/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0564 - mean_absolute_percentage_error: 270207.9688\n",
            "Epoch 37: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0565 - mean_absolute_percentage_error: 219515.8438 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 18.5878\n",
            "Epoch 38/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0517 - mean_absolute_percentage_error: 306514.7812\n",
            "Epoch 38: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0521 - mean_absolute_percentage_error: 249008.5625 - val_loss: 0.0052 - val_mean_absolute_percentage_error: 17.1999\n",
            "Epoch 39/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0494 - mean_absolute_percentage_error: 202419.2812\n",
            "Epoch 39: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0486 - mean_absolute_percentage_error: 164445.2812 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 15.9524\n",
            "Epoch 40/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0529 - mean_absolute_percentage_error: 249463.8750\n",
            "Epoch 40: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0535 - mean_absolute_percentage_error: 202668.7344 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 14.7132\n",
            "Epoch 41/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0502 - mean_absolute_percentage_error: 88.1252\n",
            "Epoch 41: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0516 - mean_absolute_percentage_error: 171651.6094 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 13.5931\n",
            "Epoch 42/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0506 - mean_absolute_percentage_error: 250997.5000\n",
            "Epoch 42: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0507 - mean_absolute_percentage_error: 203914.8906 - val_loss: 0.0032 - val_mean_absolute_percentage_error: 12.6257\n",
            "Epoch 43/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0486 - mean_absolute_percentage_error: 302075.7500\n",
            "Epoch 43: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0493 - mean_absolute_percentage_error: 245401.6406 - val_loss: 0.0028 - val_mean_absolute_percentage_error: 11.7709\n",
            "Epoch 44/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0539 - mean_absolute_percentage_error: 268146.8750\n",
            "Epoch 44: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0521 - mean_absolute_percentage_error: 217843.0312 - val_loss: 0.0025 - val_mean_absolute_percentage_error: 10.9381\n",
            "Epoch 45/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0526 - mean_absolute_percentage_error: 95.4566\n",
            "Epoch 45: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0528 - mean_absolute_percentage_error: 265203.8750 - val_loss: 0.0023 - val_mean_absolute_percentage_error: 10.2756\n",
            "Epoch 46/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0441 - mean_absolute_percentage_error: 338486.4688\n",
            "Epoch 46: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0439 - mean_absolute_percentage_error: 274985.8438 - val_loss: 0.0021 - val_mean_absolute_percentage_error: 9.7756\n",
            "Epoch 47/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0512 - mean_absolute_percentage_error: 270633.6250\n",
            "Epoch 47: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0490 - mean_absolute_percentage_error: 219859.9062 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 9.2887\n",
            "Epoch 48/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0469 - mean_absolute_percentage_error: 261264.6719\n",
            "Epoch 48: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0466 - mean_absolute_percentage_error: 212250.3906 - val_loss: 0.0018 - val_mean_absolute_percentage_error: 8.8299\n",
            "Epoch 49/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0483 - mean_absolute_percentage_error: 315966.6562\n",
            "Epoch 49: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0461 - mean_absolute_percentage_error: 256689.7031 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 8.4532\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0432 - mean_absolute_percentage_error: 234916.8125\n",
            "Epoch 50: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0432 - mean_absolute_percentage_error: 234916.8125 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 8.2258\n",
            "Train Loss Terendah:  0.04315631464123726\n",
            "Epoch Stop:  49\n",
            "Val Loss Terendah:  0.0015680737560614944\n",
            "Epoch Val Loss Stop:  50\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1553 - mean_absolute_percentage_error: 4993.4019\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 3s 93ms/step - loss: 0.1553 - mean_absolute_percentage_error: 4993.4019 - val_loss: 0.1151 - val_mean_absolute_percentage_error: 95.9092\n",
            "Epoch 2/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1541 - mean_absolute_percentage_error: 91.9331\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1510 - mean_absolute_percentage_error: 12012.1455 - val_loss: 0.1049 - val_mean_absolute_percentage_error: 91.4807\n",
            "Epoch 3/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1367 - mean_absolute_percentage_error: 84.8870\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.1345 - mean_absolute_percentage_error: 16652.6680 - val_loss: 0.0953 - val_mean_absolute_percentage_error: 87.0977\n",
            "Epoch 4/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1285 - mean_absolute_percentage_error: 28916.7246\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1272 - mean_absolute_percentage_error: 23504.0879 - val_loss: 0.0862 - val_mean_absolute_percentage_error: 82.7586\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1139 - mean_absolute_percentage_error: 35291.6992\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.1139 - mean_absolute_percentage_error: 35291.6992 - val_loss: 0.0778 - val_mean_absolute_percentage_error: 78.5066\n",
            "Epoch 6/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1033 - mean_absolute_percentage_error: 59452.5820\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1055 - mean_absolute_percentage_error: 48308.1836 - val_loss: 0.0698 - val_mean_absolute_percentage_error: 74.2609\n",
            "Epoch 7/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1011 - mean_absolute_percentage_error: 62.5092\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1004 - mean_absolute_percentage_error: 50671.7305 - val_loss: 0.0622 - val_mean_absolute_percentage_error: 69.9881\n",
            "Epoch 8/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0943 - mean_absolute_percentage_error: 86974.9141 \n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0927 - mean_absolute_percentage_error: 70664.4531 - val_loss: 0.0551 - val_mean_absolute_percentage_error: 65.7952\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0862 - mean_absolute_percentage_error: 72170.0859\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0862 - mean_absolute_percentage_error: 72170.0859 - val_loss: 0.0486 - val_mean_absolute_percentage_error: 61.6699\n",
            "Epoch 10/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0823 - mean_absolute_percentage_error: 54.6617\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.0787 - mean_absolute_percentage_error: 99388.5391 - val_loss: 0.0425 - val_mean_absolute_percentage_error: 57.5237\n",
            "Epoch 11/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0719 - mean_absolute_percentage_error: 50.6635\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0706 - mean_absolute_percentage_error: 90296.5000 - val_loss: 0.0370 - val_mean_absolute_percentage_error: 53.4903\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0646 - mean_absolute_percentage_error: 94297.6719\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0646 - mean_absolute_percentage_error: 94297.6719 - val_loss: 0.0318 - val_mean_absolute_percentage_error: 49.4428\n",
            "Epoch 13/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0589 - mean_absolute_percentage_error: 85399.7422 \n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0592 - mean_absolute_percentage_error: 79286.9375 - val_loss: 0.0271 - val_mean_absolute_percentage_error: 45.5057\n",
            "Epoch 14/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0543 - mean_absolute_percentage_error: 125657.8047\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0537 - mean_absolute_percentage_error: 102085.3984 - val_loss: 0.0229 - val_mean_absolute_percentage_error: 41.6146\n",
            "Epoch 15/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0538 - mean_absolute_percentage_error: 176191.0312\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0526 - mean_absolute_percentage_error: 143135.0938 - val_loss: 0.0191 - val_mean_absolute_percentage_error: 37.7547\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0449 - mean_absolute_percentage_error: 101299.8828\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0449 - mean_absolute_percentage_error: 101299.8828 - val_loss: 0.0157 - val_mean_absolute_percentage_error: 33.9757\n",
            "Epoch 17/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0426 - mean_absolute_percentage_error: 180694.0938\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0419 - mean_absolute_percentage_error: 146791.6406 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 30.3090\n",
            "Epoch 18/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0381 - mean_absolute_percentage_error: 56.0846\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0404 - mean_absolute_percentage_error: 156905.2344 - val_loss: 0.0102 - val_mean_absolute_percentage_error: 26.8432\n",
            "Epoch 19/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0374 - mean_absolute_percentage_error: 131239.5625\n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0373 - mean_absolute_percentage_error: 121843.5391 - val_loss: 0.0080 - val_mean_absolute_percentage_error: 23.3792\n",
            "Epoch 20/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0338 - mean_absolute_percentage_error: 141566.7656\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0331 - mean_absolute_percentage_error: 131432.0312 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 19.9478\n",
            "Epoch 21/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0300 - mean_absolute_percentage_error: 189373.9062\n",
            "Epoch 21: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0299 - mean_absolute_percentage_error: 153844.5625 - val_loss: 0.0046 - val_mean_absolute_percentage_error: 16.8668\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0315 - mean_absolute_percentage_error: 166084.9844\n",
            "Epoch 22: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.0315 - mean_absolute_percentage_error: 166084.9844 - val_loss: 0.0034 - val_mean_absolute_percentage_error: 14.0989\n",
            "Epoch 23/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0261 - mean_absolute_percentage_error: 131027.1250\n",
            "Epoch 23: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0263 - mean_absolute_percentage_error: 121646.7344 - val_loss: 0.0025 - val_mean_absolute_percentage_error: 11.6503\n",
            "Epoch 24/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0269 - mean_absolute_percentage_error: 130548.8203\n",
            "Epoch 24: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0266 - mean_absolute_percentage_error: 121204.2266 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 9.6996\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0247 - mean_absolute_percentage_error: 192947.9375\n",
            "Epoch 25: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.0247 - mean_absolute_percentage_error: 192947.9375 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 8.2354\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0259 - mean_absolute_percentage_error: 173539.1250\n",
            "Epoch 26: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0259 - mean_absolute_percentage_error: 173539.1250 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 7.0852\n",
            "Epoch 27/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0240 - mean_absolute_percentage_error: 73.3654\n",
            "Epoch 27: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0244 - mean_absolute_percentage_error: 213535.8438 - val_loss: 9.0115e-04 - val_mean_absolute_percentage_error: 6.1911\n",
            "Epoch 28/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0220 - mean_absolute_percentage_error: 212642.9531\n",
            "Epoch 28: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.0220 - mean_absolute_percentage_error: 172749.3750 - val_loss: 7.6528e-04 - val_mean_absolute_percentage_error: 5.6105\n",
            "Epoch 29/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0222 - mean_absolute_percentage_error: 71.1332\n",
            "Epoch 29: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0218 - mean_absolute_percentage_error: 163471.8906 - val_loss: 6.8918e-04 - val_mean_absolute_percentage_error: 5.3165\n",
            "Epoch 30/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0226 - mean_absolute_percentage_error: 73.1971\n",
            "Epoch 30: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0223 - mean_absolute_percentage_error: 131530.3125 - val_loss: 6.4323e-04 - val_mean_absolute_percentage_error: 5.1849\n",
            "Epoch 31/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0210 - mean_absolute_percentage_error: 146271.2500\n",
            "Epoch 31: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0210 - mean_absolute_percentage_error: 118833.1797 - val_loss: 6.1432e-04 - val_mean_absolute_percentage_error: 5.1312\n",
            "Epoch 32/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0210 - mean_absolute_percentage_error: 202997.4688\n",
            "Epoch 32: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0205 - mean_absolute_percentage_error: 188463.4531 - val_loss: 5.8952e-04 - val_mean_absolute_percentage_error: 5.1410\n",
            "Epoch 33/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0202 - mean_absolute_percentage_error: 222118.7812\n",
            "Epoch 33: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0204 - mean_absolute_percentage_error: 180446.1406 - val_loss: 5.7542e-04 - val_mean_absolute_percentage_error: 5.1389\n",
            "Epoch 34/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0210 - mean_absolute_percentage_error: 70.9930\n",
            "Epoch 34: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0210 - mean_absolute_percentage_error: 160420.2031 - val_loss: 5.6385e-04 - val_mean_absolute_percentage_error: 5.1544\n",
            "Epoch 35/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0204 - mean_absolute_percentage_error: 69.5920\n",
            "Epoch 35: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0200 - mean_absolute_percentage_error: 155880.3750 - val_loss: 5.5727e-04 - val_mean_absolute_percentage_error: 5.2024\n",
            "Epoch 36/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0205 - mean_absolute_percentage_error: 217182.4219\n",
            "Epoch 36: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0198 - mean_absolute_percentage_error: 176435.9219 - val_loss: 5.5544e-04 - val_mean_absolute_percentage_error: 5.2580\n",
            "Epoch 37/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0177 - mean_absolute_percentage_error: 195305.8438\n",
            "Epoch 37: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0183 - mean_absolute_percentage_error: 158666.6875 - val_loss: 5.4807e-04 - val_mean_absolute_percentage_error: 5.2395\n",
            "Epoch 38/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0166 - mean_absolute_percentage_error: 159859.8750\n",
            "Epoch 38: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0175 - mean_absolute_percentage_error: 129872.5625 - val_loss: 5.3470e-04 - val_mean_absolute_percentage_error: 5.1559\n",
            "Epoch 39/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0179 - mean_absolute_percentage_error: 202275.0469\n",
            "Epoch 39: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0179 - mean_absolute_percentage_error: 164323.8750 - val_loss: 5.2783e-04 - val_mean_absolute_percentage_error: 5.1407\n",
            "Epoch 40/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0167 - mean_absolute_percentage_error: 118807.7031\n",
            "Epoch 40: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0167 - mean_absolute_percentage_error: 110302.5312 - val_loss: 5.2090e-04 - val_mean_absolute_percentage_error: 5.1170\n",
            "Epoch 41/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0176 - mean_absolute_percentage_error: 64.7506\n",
            "Epoch 41: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0179 - mean_absolute_percentage_error: 164270.0781 - val_loss: 5.0450e-04 - val_mean_absolute_percentage_error: 5.0040\n",
            "Epoch 42/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0170 - mean_absolute_percentage_error: 152186.8594\n",
            "Epoch 42: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0171 - mean_absolute_percentage_error: 123639.7344 - val_loss: 4.9008e-04 - val_mean_absolute_percentage_error: 4.9078\n",
            "Epoch 43/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0154 - mean_absolute_percentage_error: 186362.9219\n",
            "Epoch 43: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0157 - mean_absolute_percentage_error: 151398.9844 - val_loss: 4.8160e-04 - val_mean_absolute_percentage_error: 4.8697\n",
            "Epoch 44/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0141 - mean_absolute_percentage_error: 124556.0391\n",
            "Epoch 44: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0139 - mean_absolute_percentage_error: 115639.5391 - val_loss: 4.7594e-04 - val_mean_absolute_percentage_error: 4.8493\n",
            "Epoch 45/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0157 - mean_absolute_percentage_error: 56.4332\n",
            "Epoch 45: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0151 - mean_absolute_percentage_error: 157356.6406 - val_loss: 4.7060e-04 - val_mean_absolute_percentage_error: 4.8304\n",
            "Epoch 46/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0149 - mean_absolute_percentage_error: 137411.4219\n",
            "Epoch 46: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0155 - mean_absolute_percentage_error: 111637.4141 - val_loss: 4.5801e-04 - val_mean_absolute_percentage_error: 4.7539\n",
            "Epoch 47/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0150 - mean_absolute_percentage_error: 139437.4844\n",
            "Epoch 47: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0144 - mean_absolute_percentage_error: 113278.2344 - val_loss: 4.4648e-04 - val_mean_absolute_percentage_error: 4.6844\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0133 - mean_absolute_percentage_error: 157481.7969\n",
            "Epoch 48: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0133 - mean_absolute_percentage_error: 157481.7969 - val_loss: 4.2518e-04 - val_mean_absolute_percentage_error: 4.5211\n",
            "Epoch 49/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0141 - mean_absolute_percentage_error: 158634.6094\n",
            "Epoch 49: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0133 - mean_absolute_percentage_error: 128875.1250 - val_loss: 4.0893e-04 - val_mean_absolute_percentage_error: 4.4044\n",
            "Epoch 50/50\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0132 - mean_absolute_percentage_error: 135704.7812\n",
            "Epoch 50: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0130 - mean_absolute_percentage_error: 110245.4531 - val_loss: 3.9703e-04 - val_mean_absolute_percentage_error: 4.3200\n",
            "Train Loss Terendah:  0.012963286601006985\n",
            "Epoch Stop:  49\n",
            "Val Loss Terendah:  0.0003970279940403998\n",
            "Epoch Val Loss Stop:  50\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1890 - mean_absolute_percentage_error: 1767.4723\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 3s 108ms/step - loss: 0.1867 - mean_absolute_percentage_error: 1647.8589 - val_loss: 0.1305 - val_mean_absolute_percentage_error: 102.0931\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1629 - mean_absolute_percentage_error: 19351.1211\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.1629 - mean_absolute_percentage_error: 19351.1211 - val_loss: 0.1097 - val_mean_absolute_percentage_error: 93.4536\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1401 - mean_absolute_percentage_error: 33482.0156\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.1401 - mean_absolute_percentage_error: 33482.0156 - val_loss: 0.0912 - val_mean_absolute_percentage_error: 85.0696\n",
            "Epoch 4/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1198 - mean_absolute_percentage_error: 52070.8906\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.1187 - mean_absolute_percentage_error: 48345.8008 - val_loss: 0.0748 - val_mean_absolute_percentage_error: 76.8739\n",
            "Epoch 5/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1017 - mean_absolute_percentage_error: 72629.0312\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.1015 - mean_absolute_percentage_error: 67431.3750 - val_loss: 0.0603 - val_mean_absolute_percentage_error: 68.8611\n",
            "Epoch 6/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0836 - mean_absolute_percentage_error: 77620.3828\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.0850 - mean_absolute_percentage_error: 72065.0078 - val_loss: 0.0476 - val_mean_absolute_percentage_error: 60.9560\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0734 - mean_absolute_percentage_error: 82294.3125\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.0734 - mean_absolute_percentage_error: 82294.3125 - val_loss: 0.0366 - val_mean_absolute_percentage_error: 53.1784\n",
            "Epoch 8/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0621 - mean_absolute_percentage_error: 135725.0000\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.0609 - mean_absolute_percentage_error: 126006.8750 - val_loss: 0.0274 - val_mean_absolute_percentage_error: 45.6985\n",
            "Epoch 9/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0504 - mean_absolute_percentage_error: 94253.4219 \n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0499 - mean_absolute_percentage_error: 87506.1797 - val_loss: 0.0198 - val_mean_absolute_percentage_error: 38.5330\n",
            "Epoch 10/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0443 - mean_absolute_percentage_error: 51.0680\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.0431 - mean_absolute_percentage_error: 123431.3828 - val_loss: 0.0135 - val_mean_absolute_percentage_error: 31.4150\n",
            "Epoch 11/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0370 - mean_absolute_percentage_error: 51.6437\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.0367 - mean_absolute_percentage_error: 153719.0000 - val_loss: 0.0088 - val_mean_absolute_percentage_error: 24.7960\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0309 - mean_absolute_percentage_error: 159082.7500\n",
            "Epoch 12: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.0309 - mean_absolute_percentage_error: 159082.7500 - val_loss: 0.0053 - val_mean_absolute_percentage_error: 18.5643\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0271 - mean_absolute_percentage_error: 160827.6562\n",
            "Epoch 13: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.0271 - mean_absolute_percentage_error: 160827.6562 - val_loss: 0.0030 - val_mean_absolute_percentage_error: 13.0518\n",
            "Epoch 14/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0225 - mean_absolute_percentage_error: 188858.6094\n",
            "Epoch 14: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.0224 - mean_absolute_percentage_error: 175336.5469 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 8.8946\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0212 - mean_absolute_percentage_error: 143900.8438\n",
            "Epoch 15: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.0212 - mean_absolute_percentage_error: 143900.8438 - val_loss: 8.8016e-04 - val_mean_absolute_percentage_error: 6.1981\n",
            "Epoch 16/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0201 - mean_absolute_percentage_error: 202744.7812\n",
            "Epoch 16: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.0201 - mean_absolute_percentage_error: 188228.1719 - val_loss: 6.1536e-04 - val_mean_absolute_percentage_error: 5.1261\n",
            "Epoch 17/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0176 - mean_absolute_percentage_error: 193699.8125\n",
            "Epoch 17: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.0173 - mean_absolute_percentage_error: 179831.3594 - val_loss: 5.9645e-04 - val_mean_absolute_percentage_error: 5.4901\n",
            "Epoch 18/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0159 - mean_absolute_percentage_error: 201865.4844\n",
            "Epoch 18: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0161 - mean_absolute_percentage_error: 187411.3438 - val_loss: 6.3697e-04 - val_mean_absolute_percentage_error: 5.9268\n",
            "Epoch 19/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0153 - mean_absolute_percentage_error: 209795.6094\n",
            "Epoch 19: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.0153 - mean_absolute_percentage_error: 194773.7969 - val_loss: 6.7446e-04 - val_mean_absolute_percentage_error: 6.2315\n",
            "Epoch 20/50\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0151 - mean_absolute_percentage_error: 173624.2969\n",
            "Epoch 20: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0149 - mean_absolute_percentage_error: 161194.0312 - val_loss: 7.1228e-04 - val_mean_absolute_percentage_error: 6.5169\n",
            "Epoch 20: early stopping\n",
            "Train Loss Terendah:  0.01488557644188404\n",
            "Epoch Stop:  19\n",
            "Val Loss Terendah:  0.0005964540760032833\n",
            "Epoch Val Loss Stop:  17\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0865 - mean_absolute_percentage_error: 350445.2188\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 4s 90ms/step - loss: 0.0831 - mean_absolute_percentage_error: 325354.8125 - val_loss: 0.0023 - val_mean_absolute_percentage_error: 13.0159\n",
            "Epoch 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0257 - mean_absolute_percentage_error: 20099.7578\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0249 - mean_absolute_percentage_error: 18662.4355 - val_loss: 0.0061 - val_mean_absolute_percentage_error: 21.3175\n",
            "Epoch 3/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0138 - mean_absolute_percentage_error: 102548.4688\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0137 - mean_absolute_percentage_error: 95206.3281 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 9.8956\n",
            "Epoch 4/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0090 - mean_absolute_percentage_error: 13050.3076\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0089 - mean_absolute_percentage_error: 10606.6582 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 11.8808\n",
            "Epoch 5/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0075 - mean_absolute_percentage_error: 6111.4795\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0073 - mean_absolute_percentage_error: 4969.0791 - val_loss: 1.7480e-04 - val_mean_absolute_percentage_error: 2.8876\n",
            "Epoch 6/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0074 - mean_absolute_percentage_error: 7845.0249\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0072 - mean_absolute_percentage_error: 6377.6558 - val_loss: 1.9107e-04 - val_mean_absolute_percentage_error: 3.2324\n",
            "Epoch 7/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0064 - mean_absolute_percentage_error: 24.1979\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0063 - mean_absolute_percentage_error: 77627.8828 - val_loss: 2.1915e-04 - val_mean_absolute_percentage_error: 3.5238\n",
            "Epoch 8/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0058 - mean_absolute_percentage_error: 24274.7598\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0056 - mean_absolute_percentage_error: 19723.5469 - val_loss: 2.0034e-04 - val_mean_absolute_percentage_error: 3.1018\n",
            "Epoch 8: early stopping\n",
            "Train Loss Terendah:  0.0056237527169287205\n",
            "Epoch Stop:  7\n",
            "Val Loss Terendah:  0.00017480444512329996\n",
            "Epoch Val Loss Stop:  5\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0636 - mean_absolute_percentage_error: 286884.0625\n",
            "Epoch 1: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 3s 97ms/step - loss: 0.0542 - mean_absolute_percentage_error: 233055.8750 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 18.5597\n",
            "Epoch 2/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0148 - mean_absolute_percentage_error: 25.2528\n",
            "Epoch 2: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0132 - mean_absolute_percentage_error: 80938.4062 - val_loss: 0.0036 - val_mean_absolute_percentage_error: 16.9144\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0060 - mean_absolute_percentage_error: 12751.7119\n",
            "Epoch 3: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0060 - mean_absolute_percentage_error: 12751.7119 - val_loss: 0.0029 - val_mean_absolute_percentage_error: 14.9101\n",
            "Epoch 4/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0046 - mean_absolute_percentage_error: 66844.7578\n",
            "Epoch 4: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0047 - mean_absolute_percentage_error: 54304.4258 - val_loss: 2.2663e-04 - val_mean_absolute_percentage_error: 3.3058\n",
            "Epoch 5/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0045 - mean_absolute_percentage_error: 3818.7661\n",
            "Epoch 5: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_absolute_percentage_error: 3105.3362 - val_loss: 1.7197e-04 - val_mean_absolute_percentage_error: 2.8540\n",
            "Epoch 6/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0037 - mean_absolute_percentage_error: 14662.2676\n",
            "Epoch 6: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.0038 - mean_absolute_percentage_error: 13613.2305 - val_loss: 3.0290e-04 - val_mean_absolute_percentage_error: 4.3634\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 26583.0508\n",
            "Epoch 7: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_absolute_percentage_error: 26583.0508 - val_loss: 1.7510e-04 - val_mean_absolute_percentage_error: 3.1745\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 15509.3184\n",
            "Epoch 8: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_absolute_percentage_error: 15509.3184 - val_loss: 1.3995e-04 - val_mean_absolute_percentage_error: 2.6739\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_percentage_error: 32897.3594\n",
            "Epoch 9: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_absolute_percentage_error: 32897.3594 - val_loss: 1.3838e-04 - val_mean_absolute_percentage_error: 2.6659\n",
            "Epoch 10/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 16.2500\n",
            "Epoch 10: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.0028 - mean_absolute_percentage_error: 20150.8398 - val_loss: 1.3560e-04 - val_mean_absolute_percentage_error: 2.6701\n",
            "Epoch 11/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 13.7541\n",
            "Epoch 11: val_loss did not improve from 0.00014\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_absolute_percentage_error: 9767.5479 - val_loss: 1.8853e-04 - val_mean_absolute_percentage_error: 3.3278\n",
            "Epoch 12/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 14.1521\n",
            "Epoch 12: val_loss improved from 0.00014 to 0.00013, saving model to best_model.h5\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.0025 - mean_absolute_percentage_error: 38782.4336 - val_loss: 1.3092e-04 - val_mean_absolute_percentage_error: 2.6396\n",
            "Epoch 13/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 66248.4766\n",
            "Epoch 13: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0025 - mean_absolute_percentage_error: 53818.0586 - val_loss: 1.4040e-04 - val_mean_absolute_percentage_error: 2.6979\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 4452.6245\n",
            "Epoch 14: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0028 - mean_absolute_percentage_error: 4452.6245 - val_loss: 3.5341e-04 - val_mean_absolute_percentage_error: 4.7678\n",
            "Epoch 15/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 14937.9287\n",
            "Epoch 15: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.0028 - mean_absolute_percentage_error: 12137.2842 - val_loss: 2.5014e-04 - val_mean_absolute_percentage_error: 3.8938\n",
            "Epoch 15: early stopping\n",
            "Train Loss Terendah:  0.002454174682497978\n",
            "Epoch Stop:  12\n",
            "Val Loss Terendah:  0.000130919594084844\n",
            "Epoch Val Loss Stop:  12\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0453 - mean_absolute_percentage_error: 87663.3203 \n",
            "Epoch 1: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 4s 114ms/step - loss: 0.0434 - mean_absolute_percentage_error: 81387.0000 - val_loss: 0.0050 - val_mean_absolute_percentage_error: 19.5615\n",
            "Epoch 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0075 - mean_absolute_percentage_error: 1015.5985\n",
            "Epoch 2: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.0072 - mean_absolute_percentage_error: 944.1981 - val_loss: 0.0028 - val_mean_absolute_percentage_error: 14.5012\n",
            "Epoch 3/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0048 - mean_absolute_percentage_error: 54472.1445\n",
            "Epoch 3: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.0047 - mean_absolute_percentage_error: 50572.1250 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 9.5269\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 4950.5586\n",
            "Epoch 4: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.0029 - mean_absolute_percentage_error: 4950.5586 - val_loss: 3.0549e-04 - val_mean_absolute_percentage_error: 4.3960\n",
            "Epoch 5/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 42319.8945\n",
            "Epoch 5: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.0028 - mean_absolute_percentage_error: 39289.7891 - val_loss: 7.9549e-04 - val_mean_absolute_percentage_error: 7.4955\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 25910.0566\n",
            "Epoch 6: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.0023 - mean_absolute_percentage_error: 25910.0566 - val_loss: 1.4345e-04 - val_mean_absolute_percentage_error: 2.7587\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0020 - mean_absolute_percentage_error: 22339.8105\n",
            "Epoch 7: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.0020 - mean_absolute_percentage_error: 22339.8105 - val_loss: 1.6306e-04 - val_mean_absolute_percentage_error: 2.8180\n",
            "Epoch 8/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0020 - mean_absolute_percentage_error: 7067.4414\n",
            "Epoch 8: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.0019 - mean_absolute_percentage_error: 6562.1758 - val_loss: 1.6323e-04 - val_mean_absolute_percentage_error: 3.0852\n",
            "Epoch 9/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0020 - mean_absolute_percentage_error: 44858.5156\n",
            "Epoch 9: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.0019 - mean_absolute_percentage_error: 41646.5000 - val_loss: 1.3806e-04 - val_mean_absolute_percentage_error: 2.7030\n",
            "Epoch 10/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0020 - mean_absolute_percentage_error: 12.1863\n",
            "Epoch 10: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.0019 - mean_absolute_percentage_error: 19830.7383 - val_loss: 1.5288e-04 - val_mean_absolute_percentage_error: 2.9739\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_percentage_error: 33695.2070\n",
            "Epoch 11: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.0019 - mean_absolute_percentage_error: 33695.2070 - val_loss: 1.3872e-04 - val_mean_absolute_percentage_error: 2.7959\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_percentage_error: 7757.9609\n",
            "Epoch 12: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.0018 - mean_absolute_percentage_error: 7757.9609 - val_loss: 2.4093e-04 - val_mean_absolute_percentage_error: 3.5204\n",
            "Epoch 12: early stopping\n",
            "Train Loss Terendah:  0.0017932129558175802\n",
            "Epoch Stop:  11\n",
            "Val Loss Terendah:  0.00013806189235765487\n",
            "Epoch Val Loss Stop:  9\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1794 - mean_absolute_percentage_error: 35039.2539\n",
            "Epoch 1: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 3s 87ms/step - loss: 0.1715 - mean_absolute_percentage_error: 28477.2539 - val_loss: 0.0822 - val_mean_absolute_percentage_error: 80.4705\n",
            "Epoch 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1043 - mean_absolute_percentage_error: 124754.7891\n",
            "Epoch 2: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.1017 - mean_absolute_percentage_error: 115826.8438 - val_loss: 0.0295 - val_mean_absolute_percentage_error: 47.1314\n",
            "Epoch 3/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0611 - mean_absolute_percentage_error: 70.0088\n",
            "Epoch 3: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0583 - mean_absolute_percentage_error: 117075.0312 - val_loss: 0.0041 - val_mean_absolute_percentage_error: 14.9515\n",
            "Epoch 4/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0394 - mean_absolute_percentage_error: 376984.0938\n",
            "Epoch 4: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0394 - mean_absolute_percentage_error: 306256.1250 - val_loss: 0.0013 - val_mean_absolute_percentage_error: 9.4247\n",
            "Epoch 5/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0351 - mean_absolute_percentage_error: 301610.9688\n",
            "Epoch 5: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0346 - mean_absolute_percentage_error: 280015.1875 - val_loss: 0.0015 - val_mean_absolute_percentage_error: 10.0717\n",
            "Epoch 6/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0336 - mean_absolute_percentage_error: 142613.4062\n",
            "Epoch 6: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0333 - mean_absolute_percentage_error: 132403.4688 - val_loss: 7.2991e-04 - val_mean_absolute_percentage_error: 5.7350\n",
            "Epoch 7/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0293 - mean_absolute_percentage_error: 74.9212\n",
            "Epoch 7: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0279 - mean_absolute_percentage_error: 210054.0469 - val_loss: 7.7113e-04 - val_mean_absolute_percentage_error: 5.7430\n",
            "Epoch 8/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0229 - mean_absolute_percentage_error: 308396.3438\n",
            "Epoch 8: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0225 - mean_absolute_percentage_error: 250535.4531 - val_loss: 7.8232e-04 - val_mean_absolute_percentage_error: 6.1414\n",
            "Epoch 9/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0202 - mean_absolute_percentage_error: 267337.0938\n",
            "Epoch 9: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0196 - mean_absolute_percentage_error: 217175.1406 - val_loss: 6.7231e-04 - val_mean_absolute_percentage_error: 5.9104\n",
            "Epoch 10/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0180 - mean_absolute_percentage_error: 47.5849\n",
            "Epoch 10: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0168 - mean_absolute_percentage_error: 56665.7227 - val_loss: 4.1704e-04 - val_mean_absolute_percentage_error: 4.5205\n",
            "Epoch 11/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0139 - mean_absolute_percentage_error: 40.7582\n",
            "Epoch 11: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0140 - mean_absolute_percentage_error: 150380.4531 - val_loss: 6.1411e-04 - val_mean_absolute_percentage_error: 6.0974\n",
            "Epoch 12/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0124 - mean_absolute_percentage_error: 31.2690\n",
            "Epoch 12: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0118 - mean_absolute_percentage_error: 97492.8281 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 8.2350\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0123 - mean_absolute_percentage_error: 53034.2188\n",
            "Epoch 13: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0123 - mean_absolute_percentage_error: 53034.2188 - val_loss: 6.0115e-04 - val_mean_absolute_percentage_error: 6.1772\n",
            "Epoch 13: early stopping\n",
            "Train Loss Terendah:  0.011827763170003891\n",
            "Epoch Stop:  11\n",
            "Val Loss Terendah:  0.0004170393804088235\n",
            "Epoch Val Loss Stop:  10\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1862 - mean_absolute_percentage_error: 46673.6016\n",
            "Epoch 1: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 3s 89ms/step - loss: 0.1731 - mean_absolute_percentage_error: 37926.3867 - val_loss: 0.0659 - val_mean_absolute_percentage_error: 71.8123\n",
            "Epoch 2/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0891 - mean_absolute_percentage_error: 60.3977\n",
            "Epoch 2: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0807 - mean_absolute_percentage_error: 157214.7656 - val_loss: 0.0110 - val_mean_absolute_percentage_error: 27.5249\n",
            "Epoch 3/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0382 - mean_absolute_percentage_error: 78.3265\n",
            "Epoch 3: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0362 - mean_absolute_percentage_error: 176196.4219 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 9.1461\n",
            "Epoch 4/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0312 - mean_absolute_percentage_error: 240539.7188\n",
            "Epoch 4: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0308 - mean_absolute_percentage_error: 195417.2656 - val_loss: 0.0040 - val_mean_absolute_percentage_error: 17.4757\n",
            "Epoch 5/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0249 - mean_absolute_percentage_error: 252400.2656\n",
            "Epoch 5: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0240 - mean_absolute_percentage_error: 205046.4844 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 9.0857\n",
            "Epoch 6/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0186 - mean_absolute_percentage_error: 192437.5000\n",
            "Epoch 6: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0189 - mean_absolute_percentage_error: 178657.9531 - val_loss: 5.1895e-04 - val_mean_absolute_percentage_error: 4.7023\n",
            "Epoch 7/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0153 - mean_absolute_percentage_error: 55.4400\n",
            "Epoch 7: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0150 - mean_absolute_percentage_error: 158598.1719 - val_loss: 4.2210e-04 - val_mean_absolute_percentage_error: 4.3411\n",
            "Epoch 8/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0123 - mean_absolute_percentage_error: 126241.4844\n",
            "Epoch 8: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0119 - mean_absolute_percentage_error: 102561.4688 - val_loss: 3.6768e-04 - val_mean_absolute_percentage_error: 4.2472\n",
            "Epoch 9/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0093 - mean_absolute_percentage_error: 117066.2969\n",
            "Epoch 9: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0093 - mean_absolute_percentage_error: 108684.3828 - val_loss: 2.9900e-04 - val_mean_absolute_percentage_error: 3.8897\n",
            "Epoch 10/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0086 - mean_absolute_percentage_error: 29.9468\n",
            "Epoch 10: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0082 - mean_absolute_percentage_error: 73090.2500 - val_loss: 2.8548e-04 - val_mean_absolute_percentage_error: 3.8111\n",
            "Epoch 11/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0067 - mean_absolute_percentage_error: 21.6558\n",
            "Epoch 11: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0066 - mean_absolute_percentage_error: 63371.9297 - val_loss: 6.4031e-04 - val_mean_absolute_percentage_error: 6.4165\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0066 - mean_absolute_percentage_error: 41254.2031\n",
            "Epoch 12: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0066 - mean_absolute_percentage_error: 41254.2031 - val_loss: 9.8807e-04 - val_mean_absolute_percentage_error: 8.1185\n",
            "Epoch 13/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0062 - mean_absolute_percentage_error: 36707.8320\n",
            "Epoch 13: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0063 - mean_absolute_percentage_error: 34080.1875 - val_loss: 5.5838e-04 - val_mean_absolute_percentage_error: 5.9720\n",
            "Epoch 13: early stopping\n",
            "Train Loss Terendah:  0.006294602062553167\n",
            "Epoch Stop:  12\n",
            "Val Loss Terendah:  0.0002854779304470867\n",
            "Epoch Val Loss Stop:  10\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0628 - mean_absolute_percentage_error: 61865.8633\n",
            "Epoch 1: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 4s 110ms/step - loss: 0.0628 - mean_absolute_percentage_error: 61865.8633 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 7.5003\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0171 - mean_absolute_percentage_error: 207826.6094\n",
            "Epoch 2: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.0171 - mean_absolute_percentage_error: 207826.6094 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 24.3303\n",
            "Epoch 3/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0114 - mean_absolute_percentage_error: 99242.7891\n",
            "Epoch 3: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.0111 - mean_absolute_percentage_error: 92137.1641 - val_loss: 4.6889e-04 - val_mean_absolute_percentage_error: 4.9299\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0082 - mean_absolute_percentage_error: 96825.1641 \n",
            "Epoch 4: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.0082 - mean_absolute_percentage_error: 96825.1641 - val_loss: 6.1701e-04 - val_mean_absolute_percentage_error: 6.0976\n",
            "Epoch 5/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0053 - mean_absolute_percentage_error: 69142.0312\n",
            "Epoch 5: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 46ms/step - loss: 0.0053 - mean_absolute_percentage_error: 64191.5156 - val_loss: 3.2361e-04 - val_mean_absolute_percentage_error: 3.9072\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0042 - mean_absolute_percentage_error: 28707.2480\n",
            "Epoch 6: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.0042 - mean_absolute_percentage_error: 28707.2480 - val_loss: 3.2998e-04 - val_mean_absolute_percentage_error: 4.3760\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0041 - mean_absolute_percentage_error: 33996.1289\n",
            "Epoch 7: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.0041 - mean_absolute_percentage_error: 33996.1289 - val_loss: 3.1975e-04 - val_mean_absolute_percentage_error: 4.2749\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_percentage_error: 34674.4258\n",
            "Epoch 8: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.0040 - mean_absolute_percentage_error: 34674.4258 - val_loss: 2.6750e-04 - val_mean_absolute_percentage_error: 3.6888\n",
            "Epoch 9/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_absolute_percentage_error: 20826.9375\n",
            "Epoch 9: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0035 - mean_absolute_percentage_error: 19336.2617 - val_loss: 3.1267e-04 - val_mean_absolute_percentage_error: 4.2081\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0037 - mean_absolute_percentage_error: 27355.7793\n",
            "Epoch 10: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.0037 - mean_absolute_percentage_error: 27355.7793 - val_loss: 2.5514e-04 - val_mean_absolute_percentage_error: 3.6401\n",
            "Epoch 11/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0034 - mean_absolute_percentage_error: 13.2692\n",
            "Epoch 11: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0035 - mean_absolute_percentage_error: 43854.6758 - val_loss: 2.7014e-04 - val_mean_absolute_percentage_error: 3.6579\n",
            "Epoch 12/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0036 - mean_absolute_percentage_error: 61107.1562\n",
            "Epoch 12: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0035 - mean_absolute_percentage_error: 56731.5195 - val_loss: 2.9032e-04 - val_mean_absolute_percentage_error: 4.0086\n",
            "Epoch 13/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 1520.2697\n",
            "Epoch 13: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.0031 - mean_absolute_percentage_error: 1412.5426 - val_loss: 2.5512e-04 - val_mean_absolute_percentage_error: 3.5777\n",
            "Epoch 14/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 51469.8242\n",
            "Epoch 14: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.0029 - mean_absolute_percentage_error: 47784.2969 - val_loss: 2.6952e-04 - val_mean_absolute_percentage_error: 3.8271\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 46551.3398\n",
            "Epoch 15: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.0029 - mean_absolute_percentage_error: 46551.3398 - val_loss: 2.4555e-04 - val_mean_absolute_percentage_error: 3.5723\n",
            "Epoch 16/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 31533.3398\n",
            "Epoch 16: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.0027 - mean_absolute_percentage_error: 29275.6562 - val_loss: 2.4264e-04 - val_mean_absolute_percentage_error: 3.5421\n",
            "Epoch 17/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 60960.9492\n",
            "Epoch 17: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.0026 - mean_absolute_percentage_error: 56595.5703 - val_loss: 2.4021e-04 - val_mean_absolute_percentage_error: 3.5035\n",
            "Epoch 18/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 40676.9766\n",
            "Epoch 18: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.0028 - mean_absolute_percentage_error: 37764.3320 - val_loss: 2.9229e-04 - val_mean_absolute_percentage_error: 4.0477\n",
            "Epoch 19/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 35016.0430\n",
            "Epoch 19: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.0027 - mean_absolute_percentage_error: 32508.8164 - val_loss: 2.3549e-04 - val_mean_absolute_percentage_error: 3.5200\n",
            "Epoch 20/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 35284.5547\n",
            "Epoch 20: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.0025 - mean_absolute_percentage_error: 32758.3613 - val_loss: 2.5333e-04 - val_mean_absolute_percentage_error: 3.7130\n",
            "Epoch 21/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0021 - mean_absolute_percentage_error: 10561.8164\n",
            "Epoch 21: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.0021 - mean_absolute_percentage_error: 9806.2783 - val_loss: 2.2929e-04 - val_mean_absolute_percentage_error: 3.4125\n",
            "Epoch 22/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 35532.9961\n",
            "Epoch 22: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 73ms/step - loss: 0.0024 - mean_absolute_percentage_error: 32988.8359 - val_loss: 2.3916e-04 - val_mean_absolute_percentage_error: 3.5640\n",
            "Epoch 23/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 41944.5547\n",
            "Epoch 23: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.0024 - mean_absolute_percentage_error: 38941.3281 - val_loss: 2.5837e-04 - val_mean_absolute_percentage_error: 3.7633\n",
            "Epoch 24/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 11285.4639\n",
            "Epoch 24: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.0024 - mean_absolute_percentage_error: 10478.2080 - val_loss: 2.2577e-04 - val_mean_absolute_percentage_error: 3.3841\n",
            "Epoch 25/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 42212.0195\n",
            "Epoch 25: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0023 - mean_absolute_percentage_error: 39189.3555 - val_loss: 2.2882e-04 - val_mean_absolute_percentage_error: 3.3769\n",
            "Epoch 26/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 44904.5898\n",
            "Epoch 26: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.0025 - mean_absolute_percentage_error: 41689.2539 - val_loss: 2.5454e-04 - val_mean_absolute_percentage_error: 3.7439\n",
            "Epoch 27/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 20214.6816\n",
            "Epoch 27: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0023 - mean_absolute_percentage_error: 18767.5820 - val_loss: 2.2587e-04 - val_mean_absolute_percentage_error: 3.4268\n",
            "Epoch 27: early stopping\n",
            "Train Loss Terendah:  0.002104030456393957\n",
            "Epoch Stop:  20\n",
            "Val Loss Terendah:  0.00022576519404537976\n",
            "Epoch Val Loss Stop:  24\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.3190 - mean_absolute_percentage_error: 2355.6699\n",
            "Epoch 1: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 3s 91ms/step - loss: 0.3172 - mean_absolute_percentage_error: 2196.8687 - val_loss: 0.2415 - val_mean_absolute_percentage_error: 139.0457\n",
            "Epoch 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.3023 - mean_absolute_percentage_error: 518.9885\n",
            "Epoch 2: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.3017 - mean_absolute_percentage_error: 491.4109 - val_loss: 0.2321 - val_mean_absolute_percentage_error: 136.2634\n",
            "Epoch 3/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.3005 - mean_absolute_percentage_error: 4015.7410\n",
            "Epoch 3: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2978 - mean_absolute_percentage_error: 3737.2048 - val_loss: 0.2231 - val_mean_absolute_percentage_error: 133.5428\n",
            "Epoch 4/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2888 - mean_absolute_percentage_error: 18835.8398\n",
            "Epoch 4: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2905 - mean_absolute_percentage_error: 15324.3975 - val_loss: 0.2145 - val_mean_absolute_percentage_error: 130.8674\n",
            "Epoch 5/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2818 - mean_absolute_percentage_error: 28376.7812\n",
            "Epoch 5: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2834 - mean_absolute_percentage_error: 26353.0918 - val_loss: 0.2061 - val_mean_absolute_percentage_error: 128.2356\n",
            "Epoch 6/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2613 - mean_absolute_percentage_error: 17533.2852\n",
            "Epoch 6: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2688 - mean_absolute_percentage_error: 16285.9004 - val_loss: 0.1981 - val_mean_absolute_percentage_error: 125.6677\n",
            "Epoch 7/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2664 - mean_absolute_percentage_error: 37050.3594\n",
            "Epoch 7: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2661 - mean_absolute_percentage_error: 34405.6328 - val_loss: 0.1903 - val_mean_absolute_percentage_error: 123.1321\n",
            "Epoch 8/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2577 - mean_absolute_percentage_error: 60559.1641 \n",
            "Epoch 8: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.2536 - mean_absolute_percentage_error: 49215.1562 - val_loss: 0.1829 - val_mean_absolute_percentage_error: 120.6477\n",
            "Epoch 9/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2452 - mean_absolute_percentage_error: 75828.5156 \n",
            "Epoch 9: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.2456 - mean_absolute_percentage_error: 61617.4414 - val_loss: 0.1758 - val_mean_absolute_percentage_error: 118.2365\n",
            "Epoch 10/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2422 - mean_absolute_percentage_error: 104.0885\n",
            "Epoch 10: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.2399 - mean_absolute_percentage_error: 27109.3945 - val_loss: 0.1689 - val_mean_absolute_percentage_error: 115.8370\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.2282 - mean_absolute_percentage_error: 48876.3164\n",
            "Epoch 11: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2282 - mean_absolute_percentage_error: 48876.3164 - val_loss: 0.1624 - val_mean_absolute_percentage_error: 113.5067\n",
            "Epoch 12/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2321 - mean_absolute_percentage_error: 99.7460 \n",
            "Epoch 12: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.2265 - mean_absolute_percentage_error: 65447.8984 - val_loss: 0.1560 - val_mean_absolute_percentage_error: 111.2076\n",
            "Epoch 13/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.2299 - mean_absolute_percentage_error: 82517.1484 \n",
            "Epoch 13: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.2232 - mean_absolute_percentage_error: 67048.4844 - val_loss: 0.1499 - val_mean_absolute_percentage_error: 108.9614\n",
            "Epoch 14/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2173 - mean_absolute_percentage_error: 80283.3750\n",
            "Epoch 14: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2151 - mean_absolute_percentage_error: 74539.5781 - val_loss: 0.1440 - val_mean_absolute_percentage_error: 106.7236\n",
            "Epoch 15/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2080 - mean_absolute_percentage_error: 68830.9453 \n",
            "Epoch 15: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.2044 - mean_absolute_percentage_error: 63907.2148 - val_loss: 0.1383 - val_mean_absolute_percentage_error: 104.5207\n",
            "Epoch 16/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.2075 - mean_absolute_percentage_error: 62958.5859 \n",
            "Epoch 16: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.2040 - mean_absolute_percentage_error: 58455.5742 - val_loss: 0.1327 - val_mean_absolute_percentage_error: 102.3460\n",
            "Epoch 17/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1988 - mean_absolute_percentage_error: 106419.9609\n",
            "Epoch 17: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1950 - mean_absolute_percentage_error: 86463.0625 - val_loss: 0.1274 - val_mean_absolute_percentage_error: 100.2025\n",
            "Epoch 18/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1838 - mean_absolute_percentage_error: 84.5816\n",
            "Epoch 18: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.1921 - mean_absolute_percentage_error: 99349.6094 - val_loss: 0.1222 - val_mean_absolute_percentage_error: 98.1056\n",
            "Epoch 19/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1734 - mean_absolute_percentage_error: 90455.2656 \n",
            "Epoch 19: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1823 - mean_absolute_percentage_error: 73494.6328 - val_loss: 0.1172 - val_mean_absolute_percentage_error: 95.9992\n",
            "Epoch 20/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1826 - mean_absolute_percentage_error: 103316.3125\n",
            "Epoch 20: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1801 - mean_absolute_percentage_error: 95922.1797 - val_loss: 0.1122 - val_mean_absolute_percentage_error: 93.8760\n",
            "Epoch 21/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1671 - mean_absolute_percentage_error: 106213.7969\n",
            "Epoch 21: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.1694 - mean_absolute_percentage_error: 86295.0625 - val_loss: 0.1076 - val_mean_absolute_percentage_error: 91.8356\n",
            "Epoch 22/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1674 - mean_absolute_percentage_error: 144128.9844\n",
            "Epoch 22: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1672 - mean_absolute_percentage_error: 117094.0625 - val_loss: 0.1030 - val_mean_absolute_percentage_error: 89.8094\n",
            "Epoch 23/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1666 - mean_absolute_percentage_error: 129742.7344\n",
            "Epoch 23: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.1654 - mean_absolute_percentage_error: 120455.2188 - val_loss: 0.0986 - val_mean_absolute_percentage_error: 87.7790\n",
            "Epoch 24/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1619 - mean_absolute_percentage_error: 140120.9062\n",
            "Epoch 24: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1577 - mean_absolute_percentage_error: 113837.7734 - val_loss: 0.0943 - val_mean_absolute_percentage_error: 85.7724\n",
            "Epoch 25/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1527 - mean_absolute_percentage_error: 194340.1094\n",
            "Epoch 25: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.1586 - mean_absolute_percentage_error: 157881.7656 - val_loss: 0.0901 - val_mean_absolute_percentage_error: 83.7772\n",
            "Epoch 26/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1548 - mean_absolute_percentage_error: 64916.9453 \n",
            "Epoch 26: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.1522 - mean_absolute_percentage_error: 52747.0859 - val_loss: 0.0860 - val_mean_absolute_percentage_error: 81.7742\n",
            "Epoch 27/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1452 - mean_absolute_percentage_error: 76.3770\n",
            "Epoch 27: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.1474 - mean_absolute_percentage_error: 143601.1719 - val_loss: 0.0821 - val_mean_absolute_percentage_error: 79.8128\n",
            "Epoch 28/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1394 - mean_absolute_percentage_error: 147993.5781\n",
            "Epoch 28: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.1427 - mean_absolute_percentage_error: 137399.5312 - val_loss: 0.0783 - val_mean_absolute_percentage_error: 77.8727\n",
            "Epoch 29/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1405 - mean_absolute_percentage_error: 176986.3281\n",
            "Epoch 29: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.1387 - mean_absolute_percentage_error: 164314.9688 - val_loss: 0.0746 - val_mean_absolute_percentage_error: 75.9411\n",
            "Epoch 30/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1383 - mean_absolute_percentage_error: 72.0837\n",
            "Epoch 30: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.1340 - mean_absolute_percentage_error: 157788.5156 - val_loss: 0.0711 - val_mean_absolute_percentage_error: 74.0259\n",
            "Epoch 31/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1267 - mean_absolute_percentage_error: 178563.2500\n",
            "Epoch 31: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.1308 - mean_absolute_percentage_error: 145065.3750 - val_loss: 0.0677 - val_mean_absolute_percentage_error: 72.1600\n",
            "Epoch 32/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1325 - mean_absolute_percentage_error: 230391.2812\n",
            "Epoch 32: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.1288 - mean_absolute_percentage_error: 187170.2969 - val_loss: 0.0644 - val_mean_absolute_percentage_error: 70.2825\n",
            "Epoch 33/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1205 - mean_absolute_percentage_error: 118437.4453\n",
            "Epoch 33: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.1211 - mean_absolute_percentage_error: 109959.6172 - val_loss: 0.0612 - val_mean_absolute_percentage_error: 68.4512\n",
            "Epoch 34/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1209 - mean_absolute_percentage_error: 79.7440\n",
            "Epoch 34: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1213 - mean_absolute_percentage_error: 158703.5000 - val_loss: 0.0582 - val_mean_absolute_percentage_error: 66.6404\n",
            "Epoch 35/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1207 - mean_absolute_percentage_error: 78.9422\n",
            "Epoch 35: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1200 - mean_absolute_percentage_error: 108574.1953 - val_loss: 0.0552 - val_mean_absolute_percentage_error: 64.8436\n",
            "Epoch 36/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1182 - mean_absolute_percentage_error: 175219.9062\n",
            "Epoch 36: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.1145 - mean_absolute_percentage_error: 142349.6875 - val_loss: 0.0524 - val_mean_absolute_percentage_error: 63.0595\n",
            "Epoch 37/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1122 - mean_absolute_percentage_error: 136958.9219\n",
            "Epoch 37: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.1126 - mean_absolute_percentage_error: 111271.1016 - val_loss: 0.0496 - val_mean_absolute_percentage_error: 61.2716\n",
            "Epoch 38/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1098 - mean_absolute_percentage_error: 203133.1250\n",
            "Epoch 38: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.1107 - mean_absolute_percentage_error: 165025.2188 - val_loss: 0.0470 - val_mean_absolute_percentage_error: 59.5303\n",
            "Epoch 39/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1060 - mean_absolute_percentage_error: 210977.5469\n",
            "Epoch 39: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.1048 - mean_absolute_percentage_error: 171395.9688 - val_loss: 0.0445 - val_mean_absolute_percentage_error: 57.7804\n",
            "Epoch 40/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1049 - mean_absolute_percentage_error: 184933.9062\n",
            "Epoch 40: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.1038 - mean_absolute_percentage_error: 150247.6094 - val_loss: 0.0419 - val_mean_absolute_percentage_error: 55.9919\n",
            "Epoch 41/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0997 - mean_absolute_percentage_error: 145510.8750\n",
            "Epoch 41: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0992 - mean_absolute_percentage_error: 135094.6250 - val_loss: 0.0395 - val_mean_absolute_percentage_error: 54.2686\n",
            "Epoch 42/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0953 - mean_absolute_percentage_error: 210788.4531\n",
            "Epoch 42: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0976 - mean_absolute_percentage_error: 171249.8750 - val_loss: 0.0373 - val_mean_absolute_percentage_error: 52.5971\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0966 - mean_absolute_percentage_error: 227692.7188\n",
            "Epoch 43: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0966 - mean_absolute_percentage_error: 227692.7188 - val_loss: 0.0352 - val_mean_absolute_percentage_error: 50.9360\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0928 - mean_absolute_percentage_error: 168798.5781\n",
            "Epoch 44: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0928 - mean_absolute_percentage_error: 168798.5781 - val_loss: 0.0331 - val_mean_absolute_percentage_error: 49.2664\n",
            "Epoch 45/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0941 - mean_absolute_percentage_error: 88.1289\n",
            "Epoch 45: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0915 - mean_absolute_percentage_error: 213175.7344 - val_loss: 0.0311 - val_mean_absolute_percentage_error: 47.6177\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0894 - mean_absolute_percentage_error: 222095.9844\n",
            "Epoch 46: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0894 - mean_absolute_percentage_error: 222095.9844 - val_loss: 0.0292 - val_mean_absolute_percentage_error: 46.0215\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0875 - mean_absolute_percentage_error: 271309.3125\n",
            "Epoch 47: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0875 - mean_absolute_percentage_error: 271309.3125 - val_loss: 0.0274 - val_mean_absolute_percentage_error: 44.4303\n",
            "Epoch 48/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0880 - mean_absolute_percentage_error: 279115.5625\n",
            "Epoch 48: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0873 - mean_absolute_percentage_error: 259130.5781 - val_loss: 0.0256 - val_mean_absolute_percentage_error: 42.8577\n",
            "Epoch 49/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0843 - mean_absolute_percentage_error: 230682.8906\n",
            "Epoch 49: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0836 - mean_absolute_percentage_error: 187410.2188 - val_loss: 0.0240 - val_mean_absolute_percentage_error: 41.3051\n",
            "Epoch 50/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0845 - mean_absolute_percentage_error: 229946.0938\n",
            "Epoch 50: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0831 - mean_absolute_percentage_error: 186806.3750 - val_loss: 0.0224 - val_mean_absolute_percentage_error: 39.8060\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0810 - mean_absolute_percentage_error: 240614.7969\n",
            "Epoch 51: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0810 - mean_absolute_percentage_error: 240614.7969 - val_loss: 0.0210 - val_mean_absolute_percentage_error: 38.3083\n",
            "Epoch 52/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0794 - mean_absolute_percentage_error: 331769.0938\n",
            "Epoch 52: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0803 - mean_absolute_percentage_error: 269521.2188 - val_loss: 0.0195 - val_mean_absolute_percentage_error: 36.8210\n",
            "Epoch 53/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0792 - mean_absolute_percentage_error: 392793.8125\n",
            "Epoch 53: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0785 - mean_absolute_percentage_error: 319101.1250 - val_loss: 0.0182 - val_mean_absolute_percentage_error: 35.3360\n",
            "Epoch 54/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0778 - mean_absolute_percentage_error: 90.7789\n",
            "Epoch 54: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0760 - mean_absolute_percentage_error: 190675.6406 - val_loss: 0.0169 - val_mean_absolute_percentage_error: 33.8866\n",
            "Epoch 55/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0806 - mean_absolute_percentage_error: 191627.3594\n",
            "Epoch 55: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0781 - mean_absolute_percentage_error: 177913.0156 - val_loss: 0.0157 - val_mean_absolute_percentage_error: 32.4578\n",
            "Epoch 56/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0716 - mean_absolute_percentage_error: 230216.8750\n",
            "Epoch 56: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0746 - mean_absolute_percentage_error: 187028.2812 - val_loss: 0.0146 - val_mean_absolute_percentage_error: 31.1450\n",
            "Epoch 57/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0693 - mean_absolute_percentage_error: 354023.9375\n",
            "Epoch 57: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0720 - mean_absolute_percentage_error: 287603.2812 - val_loss: 0.0136 - val_mean_absolute_percentage_error: 29.8819\n",
            "Epoch 58/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0701 - mean_absolute_percentage_error: 337743.8438\n",
            "Epoch 58: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0713 - mean_absolute_percentage_error: 274375.5312 - val_loss: 0.0127 - val_mean_absolute_percentage_error: 28.6051\n",
            "Epoch 59/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0707 - mean_absolute_percentage_error: 308504.0625\n",
            "Epoch 59: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0713 - mean_absolute_percentage_error: 250627.5625 - val_loss: 0.0117 - val_mean_absolute_percentage_error: 27.3134\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0665 - mean_absolute_percentage_error: 165382.7656\n",
            "Epoch 60: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0665 - mean_absolute_percentage_error: 165382.7656 - val_loss: 0.0109 - val_mean_absolute_percentage_error: 26.0918\n",
            "Epoch 61/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0644 - mean_absolute_percentage_error: 324663.7812\n",
            "Epoch 61: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0684 - mean_absolute_percentage_error: 263756.5312 - val_loss: 0.0101 - val_mean_absolute_percentage_error: 24.8667\n",
            "Epoch 62/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0641 - mean_absolute_percentage_error: 297202.7188\n",
            "Epoch 62: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0660 - mean_absolute_percentage_error: 241445.6250 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 23.6308\n",
            "Epoch 63/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0645 - mean_absolute_percentage_error: 173611.4688\n",
            "Epoch 63: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0639 - mean_absolute_percentage_error: 161185.6875 - val_loss: 0.0086 - val_mean_absolute_percentage_error: 22.4370\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0666 - mean_absolute_percentage_error: 122333.1172\n",
            "Epoch 64: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0666 - mean_absolute_percentage_error: 122333.1172 - val_loss: 0.0079 - val_mean_absolute_percentage_error: 21.3407\n",
            "Epoch 65/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0687 - mean_absolute_percentage_error: 427153.4375\n",
            "Epoch 65: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0665 - mean_absolute_percentage_error: 347008.5938 - val_loss: 0.0074 - val_mean_absolute_percentage_error: 20.3497\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0617 - mean_absolute_percentage_error: 221350.4062\n",
            "Epoch 66: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0617 - mean_absolute_percentage_error: 221350.4062 - val_loss: 0.0068 - val_mean_absolute_percentage_error: 19.3871\n",
            "Epoch 67/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0617 - mean_absolute_percentage_error: 260770.2656\n",
            "Epoch 67: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0614 - mean_absolute_percentage_error: 211847.8438 - val_loss: 0.0063 - val_mean_absolute_percentage_error: 18.4227\n",
            "Epoch 68/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0623 - mean_absolute_percentage_error: 246682.5312\n",
            "Epoch 68: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0614 - mean_absolute_percentage_error: 229024.1875 - val_loss: 0.0059 - val_mean_absolute_percentage_error: 17.5384\n",
            "Epoch 69/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0613 - mean_absolute_percentage_error: 215640.9219\n",
            "Epoch 69: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0619 - mean_absolute_percentage_error: 200202.4375 - val_loss: 0.0055 - val_mean_absolute_percentage_error: 16.7106\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0598 - mean_absolute_percentage_error: 266280.1250\n",
            "Epoch 70: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0598 - mean_absolute_percentage_error: 266280.1250 - val_loss: 0.0051 - val_mean_absolute_percentage_error: 15.9449\n",
            "Epoch 71/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0578 - mean_absolute_percentage_error: 326306.9375\n",
            "Epoch 71: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0593 - mean_absolute_percentage_error: 265093.8125 - val_loss: 0.0048 - val_mean_absolute_percentage_error: 15.2526\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0568 - mean_absolute_percentage_error: 279867.6562\n",
            "Epoch 72: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0568 - mean_absolute_percentage_error: 279867.6562 - val_loss: 0.0045 - val_mean_absolute_percentage_error: 14.5883\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0574 - mean_absolute_percentage_error: 290986.5000\n",
            "Epoch 73: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0574 - mean_absolute_percentage_error: 290986.5000 - val_loss: 0.0042 - val_mean_absolute_percentage_error: 13.8978\n",
            "Epoch 74/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0566 - mean_absolute_percentage_error: 327180.9062\n",
            "Epoch 74: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0553 - mean_absolute_percentage_error: 303754.5312 - val_loss: 0.0039 - val_mean_absolute_percentage_error: 13.3059\n",
            "Epoch 75/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0614 - mean_absolute_percentage_error: 372048.5625\n",
            "Epoch 75: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0609 - mean_absolute_percentage_error: 345413.1250 - val_loss: 0.0037 - val_mean_absolute_percentage_error: 12.8132\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0551 - mean_absolute_percentage_error: 307867.8750\n",
            "Epoch 76: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0551 - mean_absolute_percentage_error: 307867.8750 - val_loss: 0.0035 - val_mean_absolute_percentage_error: 12.4234\n",
            "Epoch 77/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0559 - mean_absolute_percentage_error: 166621.0781\n",
            "Epoch 77: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0550 - mean_absolute_percentage_error: 154702.4219 - val_loss: 0.0033 - val_mean_absolute_percentage_error: 11.9670\n",
            "Epoch 78/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0547 - mean_absolute_percentage_error: 326671.0312\n",
            "Epoch 78: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0543 - mean_absolute_percentage_error: 303281.5000 - val_loss: 0.0031 - val_mean_absolute_percentage_error: 11.5471\n",
            "Epoch 79/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0565 - mean_absolute_percentage_error: 240761.4062\n",
            "Epoch 79: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0561 - mean_absolute_percentage_error: 223524.5938 - val_loss: 0.0029 - val_mean_absolute_percentage_error: 11.1778\n",
            "Epoch 80/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0543 - mean_absolute_percentage_error: 276332.5625\n",
            "Epoch 80: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0531 - mean_absolute_percentage_error: 224495.0781 - val_loss: 0.0028 - val_mean_absolute_percentage_error: 10.8434\n",
            "Epoch 81/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0561 - mean_absolute_percentage_error: 383795.8438\n",
            "Epoch 81: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0548 - mean_absolute_percentage_error: 311789.7500 - val_loss: 0.0027 - val_mean_absolute_percentage_error: 10.5583\n",
            "Epoch 82/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0500 - mean_absolute_percentage_error: 299122.1250\n",
            "Epoch 82: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0499 - mean_absolute_percentage_error: 277704.7500 - val_loss: 0.0025 - val_mean_absolute_percentage_error: 10.2508\n",
            "Epoch 83/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0528 - mean_absolute_percentage_error: 294368.2812\n",
            "Epoch 83: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0532 - mean_absolute_percentage_error: 273291.3438 - val_loss: 0.0024 - val_mean_absolute_percentage_error: 9.9354\n",
            "Epoch 84/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0554 - mean_absolute_percentage_error: 111.9915\n",
            "Epoch 84: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0539 - mean_absolute_percentage_error: 318722.3125 - val_loss: 0.0023 - val_mean_absolute_percentage_error: 9.6090\n",
            "Epoch 85/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0475 - mean_absolute_percentage_error: 107.0367\n",
            "Epoch 85: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0491 - mean_absolute_percentage_error: 322248.8750 - val_loss: 0.0022 - val_mean_absolute_percentage_error: 9.3702\n",
            "Epoch 86/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0506 - mean_absolute_percentage_error: 227919.9375\n",
            "Epoch 86: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0508 - mean_absolute_percentage_error: 211601.9375 - val_loss: 0.0021 - val_mean_absolute_percentage_error: 9.1984\n",
            "Epoch 87/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0528 - mean_absolute_percentage_error: 340195.7812\n",
            "Epoch 87: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0518 - mean_absolute_percentage_error: 315835.1562 - val_loss: 0.0021 - val_mean_absolute_percentage_error: 9.0076\n",
            "Epoch 88/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0485 - mean_absolute_percentage_error: 316057.9062\n",
            "Epoch 88: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0486 - mean_absolute_percentage_error: 256768.9844 - val_loss: 0.0020 - val_mean_absolute_percentage_error: 8.7793\n",
            "Epoch 89/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0501 - mean_absolute_percentage_error: 271713.2188\n",
            "Epoch 89: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0499 - mean_absolute_percentage_error: 220738.0000 - val_loss: 0.0019 - val_mean_absolute_percentage_error: 8.5328\n",
            "Epoch 90/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0470 - mean_absolute_percentage_error: 366063.5000\n",
            "Epoch 90: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0488 - mean_absolute_percentage_error: 297386.4062 - val_loss: 0.0018 - val_mean_absolute_percentage_error: 8.3532\n",
            "Epoch 91/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0485 - mean_absolute_percentage_error: 377135.6562\n",
            "Epoch 91: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0486 - mean_absolute_percentage_error: 306380.3438 - val_loss: 0.0018 - val_mean_absolute_percentage_error: 8.1699\n",
            "Epoch 92/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0482 - mean_absolute_percentage_error: 495702.4375\n",
            "Epoch 92: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0479 - mean_absolute_percentage_error: 402693.0000 - val_loss: 0.0017 - val_mean_absolute_percentage_error: 8.0725\n",
            "Epoch 93/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0515 - mean_absolute_percentage_error: 346684.7188\n",
            "Epoch 93: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0505 - mean_absolute_percentage_error: 281641.4375 - val_loss: 0.0017 - val_mean_absolute_percentage_error: 7.9540\n",
            "Epoch 94/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0459 - mean_absolute_percentage_error: 457700.4375\n",
            "Epoch 94: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0454 - mean_absolute_percentage_error: 371823.0625 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 7.8504\n",
            "Epoch 95/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0427 - mean_absolute_percentage_error: 106.2915\n",
            "Epoch 95: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0436 - mean_absolute_percentage_error: 264765.4688 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 7.7486\n",
            "Epoch 96/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0487 - mean_absolute_percentage_error: 261338.6250\n",
            "Epoch 96: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0470 - mean_absolute_percentage_error: 212310.7969 - val_loss: 0.0016 - val_mean_absolute_percentage_error: 7.6075\n",
            "Epoch 97/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0425 - mean_absolute_percentage_error: 276533.3750\n",
            "Epoch 97: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0434 - mean_absolute_percentage_error: 256736.2344 - val_loss: 0.0015 - val_mean_absolute_percentage_error: 7.4543\n",
            "Epoch 98/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0446 - mean_absolute_percentage_error: 362667.5000\n",
            "Epoch 98: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0450 - mean_absolute_percentage_error: 294624.5938 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 7.3475\n",
            "Epoch 99/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0413 - mean_absolute_percentage_error: 213889.7344\n",
            "Epoch 99: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0410 - mean_absolute_percentage_error: 198577.8906 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 7.2533\n",
            "Epoch 100/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0440 - mean_absolute_percentage_error: 107.6915\n",
            "Epoch 100: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0430 - mean_absolute_percentage_error: 260349.2500 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 7.1712\n",
            "Train Loss Terendah:  0.040978897362947464\n",
            "Epoch Stop:  98\n",
            "Val Loss Terendah:  0.001372330472804606\n",
            "Epoch Val Loss Stop:  100\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 32}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1335 - mean_absolute_percentage_error: 3087.5093\n",
            "Epoch 1: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 3s 93ms/step - loss: 0.1335 - mean_absolute_percentage_error: 3087.5093 - val_loss: 0.0928 - val_mean_absolute_percentage_error: 86.1044\n",
            "Epoch 2/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1239 - mean_absolute_percentage_error: 81.6739\n",
            "Epoch 2: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.1211 - mean_absolute_percentage_error: 15090.8398 - val_loss: 0.0830 - val_mean_absolute_percentage_error: 81.3024\n",
            "Epoch 3/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.1078 - mean_absolute_percentage_error: 73.5507\n",
            "Epoch 3: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.1078 - mean_absolute_percentage_error: 19602.4707 - val_loss: 0.0737 - val_mean_absolute_percentage_error: 76.5669\n",
            "Epoch 4/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0995 - mean_absolute_percentage_error: 24355.3965\n",
            "Epoch 4: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0980 - mean_absolute_percentage_error: 19796.8008 - val_loss: 0.0651 - val_mean_absolute_percentage_error: 71.8627\n",
            "Epoch 5/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0875 - mean_absolute_percentage_error: 53545.1758\n",
            "Epoch 5: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0866 - mean_absolute_percentage_error: 43507.4688 - val_loss: 0.0572 - val_mean_absolute_percentage_error: 67.2561\n",
            "Epoch 6/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0811 - mean_absolute_percentage_error: 65672.9844\n",
            "Epoch 6: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0829 - mean_absolute_percentage_error: 53359.0117 - val_loss: 0.0499 - val_mean_absolute_percentage_error: 62.6666\n",
            "Epoch 7/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0772 - mean_absolute_percentage_error: 51.9374\n",
            "Epoch 7: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0758 - mean_absolute_percentage_error: 67656.3828 - val_loss: 0.0431 - val_mean_absolute_percentage_error: 58.1151\n",
            "Epoch 8/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0700 - mean_absolute_percentage_error: 67164.3828 \n",
            "Epoch 8: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0681 - mean_absolute_percentage_error: 54570.4336 - val_loss: 0.0370 - val_mean_absolute_percentage_error: 53.6859\n",
            "Epoch 9/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0646 - mean_absolute_percentage_error: 97937.5078 \n",
            "Epoch 9: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0641 - mean_absolute_percentage_error: 79565.8984 - val_loss: 0.0314 - val_mean_absolute_percentage_error: 49.3431\n",
            "Epoch 10/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0589 - mean_absolute_percentage_error: 45.9937\n",
            "Epoch 10: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0563 - mean_absolute_percentage_error: 89720.1328 - val_loss: 0.0263 - val_mean_absolute_percentage_error: 45.0212\n",
            "Epoch 11/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0526 - mean_absolute_percentage_error: 45.1368\n",
            "Epoch 11: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0506 - mean_absolute_percentage_error: 97364.7578 - val_loss: 0.0219 - val_mean_absolute_percentage_error: 40.8976\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0451 - mean_absolute_percentage_error: 89191.6094\n",
            "Epoch 12: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0451 - mean_absolute_percentage_error: 89191.6094 - val_loss: 0.0180 - val_mean_absolute_percentage_error: 36.8561\n",
            "Epoch 13/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0427 - mean_absolute_percentage_error: 110158.8203\n",
            "Epoch 13: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0401 - mean_absolute_percentage_error: 89493.3203 - val_loss: 0.0146 - val_mean_absolute_percentage_error: 33.0109\n",
            "Epoch 14/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0386 - mean_absolute_percentage_error: 108489.8750\n",
            "Epoch 14: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0371 - mean_absolute_percentage_error: 88138.6641 - val_loss: 0.0118 - val_mean_absolute_percentage_error: 29.3259\n",
            "Epoch 15/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0364 - mean_absolute_percentage_error: 172014.7500\n",
            "Epoch 15: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0360 - mean_absolute_percentage_error: 139742.1250 - val_loss: 0.0093 - val_mean_absolute_percentage_error: 25.7994\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0311 - mean_absolute_percentage_error: 97728.8516 \n",
            "Epoch 16: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0311 - mean_absolute_percentage_error: 97728.8516 - val_loss: 0.0072 - val_mean_absolute_percentage_error: 22.4098\n",
            "Epoch 17/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0303 - mean_absolute_percentage_error: 114075.2422\n",
            "Epoch 17: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0294 - mean_absolute_percentage_error: 92675.0859 - val_loss: 0.0056 - val_mean_absolute_percentage_error: 19.3223\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0279 - mean_absolute_percentage_error: 106278.4531\n",
            "Epoch 18: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 0.0279 - mean_absolute_percentage_error: 106278.4531 - val_loss: 0.0043 - val_mean_absolute_percentage_error: 16.5036\n",
            "Epoch 19/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0251 - mean_absolute_percentage_error: 198567.7344\n",
            "Epoch 19: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0274 - mean_absolute_percentage_error: 161312.8125 - val_loss: 0.0032 - val_mean_absolute_percentage_error: 13.9230\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0236 - mean_absolute_percentage_error: 148751.5000\n",
            "Epoch 20: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0236 - mean_absolute_percentage_error: 148751.5000 - val_loss: 0.0024 - val_mean_absolute_percentage_error: 11.6349\n",
            "Epoch 21/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0228 - mean_absolute_percentage_error: 193443.7812\n",
            "Epoch 21: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0234 - mean_absolute_percentage_error: 157150.0781 - val_loss: 0.0018 - val_mean_absolute_percentage_error: 9.8693\n",
            "Epoch 22/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0253 - mean_absolute_percentage_error: 176496.2188\n",
            "Epoch 22: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0244 - mean_absolute_percentage_error: 143383.3125 - val_loss: 0.0014 - val_mean_absolute_percentage_error: 8.3889\n",
            "Epoch 23/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0217 - mean_absolute_percentage_error: 207883.9062\n",
            "Epoch 23: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0216 - mean_absolute_percentage_error: 168881.3594 - val_loss: 0.0011 - val_mean_absolute_percentage_error: 7.1120\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0200 - mean_absolute_percentage_error: 130143.4219\n",
            "Epoch 24: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0200 - mean_absolute_percentage_error: 130143.4219 - val_loss: 8.5493e-04 - val_mean_absolute_percentage_error: 6.2456\n",
            "Epoch 25/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0183 - mean_absolute_percentage_error: 217278.4062\n",
            "Epoch 25: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0194 - mean_absolute_percentage_error: 176511.2500 - val_loss: 7.2995e-04 - val_mean_absolute_percentage_error: 5.6564\n",
            "Epoch 26/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0209 - mean_absolute_percentage_error: 218911.3594\n",
            "Epoch 26: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.0210 - mean_absolute_percentage_error: 177837.9375 - val_loss: 6.3076e-04 - val_mean_absolute_percentage_error: 5.1700\n",
            "Epoch 27/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0192 - mean_absolute_percentage_error: 65.2611\n",
            "Epoch 27: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0204 - mean_absolute_percentage_error: 153202.6719 - val_loss: 5.6418e-04 - val_mean_absolute_percentage_error: 4.8644\n",
            "Epoch 28/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0186 - mean_absolute_percentage_error: 168321.6094\n",
            "Epoch 28: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0197 - mean_absolute_percentage_error: 136744.8438 - val_loss: 5.2527e-04 - val_mean_absolute_percentage_error: 4.7093\n",
            "Epoch 29/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0189 - mean_absolute_percentage_error: 61.7176\n",
            "Epoch 29: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0181 - mean_absolute_percentage_error: 167062.7188 - val_loss: 5.0486e-04 - val_mean_absolute_percentage_error: 4.6437\n",
            "Epoch 30/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0210 - mean_absolute_percentage_error: 61.5252\n",
            "Epoch 30: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0203 - mean_absolute_percentage_error: 57423.2852 - val_loss: 4.8627e-04 - val_mean_absolute_percentage_error: 4.5997\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0180 - mean_absolute_percentage_error: 143350.0781\n",
            "Epoch 31: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0180 - mean_absolute_percentage_error: 143350.0781 - val_loss: 4.7204e-04 - val_mean_absolute_percentage_error: 4.5654\n",
            "Epoch 32/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0182 - mean_absolute_percentage_error: 174371.0000\n",
            "Epoch 32: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 39ms/step - loss: 0.0178 - mean_absolute_percentage_error: 161886.4688 - val_loss: 4.5786e-04 - val_mean_absolute_percentage_error: 4.5353\n",
            "Epoch 33/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0155 - mean_absolute_percentage_error: 154972.7188\n",
            "Epoch 33: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.0159 - mean_absolute_percentage_error: 125899.1719 - val_loss: 4.4791e-04 - val_mean_absolute_percentage_error: 4.4920\n",
            "Epoch 34/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0176 - mean_absolute_percentage_error: 58.3871\n",
            "Epoch 34: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0180 - mean_absolute_percentage_error: 152991.9688 - val_loss: 4.3802e-04 - val_mean_absolute_percentage_error: 4.4504\n",
            "Epoch 35/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0164 - mean_absolute_percentage_error: 152153.0312\n",
            "Epoch 35: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0166 - mean_absolute_percentage_error: 141258.9688 - val_loss: 4.2733e-04 - val_mean_absolute_percentage_error: 4.4234\n",
            "Epoch 36/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0168 - mean_absolute_percentage_error: 125447.0234\n",
            "Epoch 36: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 34ms/step - loss: 0.0164 - mean_absolute_percentage_error: 101914.2344 - val_loss: 4.1895e-04 - val_mean_absolute_percentage_error: 4.4115\n",
            "Epoch 37/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0149 - mean_absolute_percentage_error: 156961.1406\n",
            "Epoch 37: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0150 - mean_absolute_percentage_error: 127515.4141 - val_loss: 4.1020e-04 - val_mean_absolute_percentage_error: 4.3574\n",
            "Epoch 38/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0156 - mean_absolute_percentage_error: 135820.7188\n",
            "Epoch 38: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0152 - mean_absolute_percentage_error: 110342.7891 - val_loss: 4.0159e-04 - val_mean_absolute_percentage_error: 4.2874\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0157 - mean_absolute_percentage_error: 135166.2344\n",
            "Epoch 39: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0157 - mean_absolute_percentage_error: 135166.2344 - val_loss: 3.9342e-04 - val_mean_absolute_percentage_error: 4.2371\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0148 - mean_absolute_percentage_error: 107216.9688\n",
            "Epoch 40: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 35ms/step - loss: 0.0148 - mean_absolute_percentage_error: 107216.9688 - val_loss: 3.8518e-04 - val_mean_absolute_percentage_error: 4.2076\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0141 - mean_absolute_percentage_error: 137524.6250\n",
            "Epoch 41: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0141 - mean_absolute_percentage_error: 137524.6250 - val_loss: 3.7772e-04 - val_mean_absolute_percentage_error: 4.1847\n",
            "Epoch 42/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0142 - mean_absolute_percentage_error: 147585.1562\n",
            "Epoch 42: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 0.0142 - mean_absolute_percentage_error: 137020.3750 - val_loss: 3.7005e-04 - val_mean_absolute_percentage_error: 4.1405\n",
            "Epoch 43/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0137 - mean_absolute_percentage_error: 80772.0234 \n",
            "Epoch 43: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0140 - mean_absolute_percentage_error: 74989.9062 - val_loss: 3.6274e-04 - val_mean_absolute_percentage_error: 4.1087\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0122 - mean_absolute_percentage_error: 117290.2891\n",
            "Epoch 44: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 38ms/step - loss: 0.0122 - mean_absolute_percentage_error: 117290.2891 - val_loss: 3.5594e-04 - val_mean_absolute_percentage_error: 4.0805\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.0139 - mean_absolute_percentage_error: 113849.4375\n",
            "Epoch 45: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 0.0139 - mean_absolute_percentage_error: 113849.4375 - val_loss: 3.4926e-04 - val_mean_absolute_percentage_error: 4.0466\n",
            "Epoch 46/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0130 - mean_absolute_percentage_error: 99620.9609 \n",
            "Epoch 46: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 0.0129 - mean_absolute_percentage_error: 92489.5859 - val_loss: 3.4251e-04 - val_mean_absolute_percentage_error: 4.0099\n",
            "Epoch 47/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0134 - mean_absolute_percentage_error: 136487.9688\n",
            "Epoch 47: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0133 - mean_absolute_percentage_error: 110881.2266 - val_loss: 3.3636e-04 - val_mean_absolute_percentage_error: 3.9774\n",
            "Epoch 48/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0111 - mean_absolute_percentage_error: 111904.2969\n",
            "Epoch 48: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 37ms/step - loss: 0.0111 - mean_absolute_percentage_error: 103893.1172 - val_loss: 3.3050e-04 - val_mean_absolute_percentage_error: 3.9438\n",
            "Epoch 49/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0111 - mean_absolute_percentage_error: 133974.1406\n",
            "Epoch 49: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0110 - mean_absolute_percentage_error: 124382.5078 - val_loss: 3.2711e-04 - val_mean_absolute_percentage_error: 3.9377\n",
            "Epoch 50/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0127 - mean_absolute_percentage_error: 149547.3281\n",
            "Epoch 50: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.0124 - mean_absolute_percentage_error: 121488.7812 - val_loss: 3.3108e-04 - val_mean_absolute_percentage_error: 3.9871\n",
            "Epoch 51/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0122 - mean_absolute_percentage_error: 116663.8359\n",
            "Epoch 51: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.0118 - mean_absolute_percentage_error: 94776.9609 - val_loss: 3.3474e-04 - val_mean_absolute_percentage_error: 4.0325\n",
            "Epoch 52/100\n",
            "7/9 [======================>.......] - ETA: 0s - loss: 0.0109 - mean_absolute_percentage_error: 122786.2422\n",
            "Epoch 52: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0113 - mean_absolute_percentage_error: 99749.2734 - val_loss: 3.3362e-04 - val_mean_absolute_percentage_error: 4.0444\n",
            "Epoch 52: early stopping\n",
            "Train Loss Terendah:  0.010962926782667637\n",
            "Epoch Stop:  48\n",
            "Val Loss Terendah:  0.0003271106688771397\n",
            "Epoch Val Loss Stop:  49\n",
            "==================================================================================================================\n",
            "\n",
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 128, 'epochs': 100, 'learning_rate': 0.0001, 'optimizer': 'Adam', 'units': 64}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1532 - mean_absolute_percentage_error: 2411.4155\n",
            "Epoch 1: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 4s 130ms/step - loss: 0.1532 - mean_absolute_percentage_error: 2411.4155 - val_loss: 0.1086 - val_mean_absolute_percentage_error: 93.1063\n",
            "Epoch 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1369 - mean_absolute_percentage_error: 28074.8711\n",
            "Epoch 2: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.1358 - mean_absolute_percentage_error: 26070.1543 - val_loss: 0.0918 - val_mean_absolute_percentage_error: 85.4549\n",
            "Epoch 3/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.1199 - mean_absolute_percentage_error: 37481.6172\n",
            "Epoch 3: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.1190 - mean_absolute_percentage_error: 34802.0312 - val_loss: 0.0766 - val_mean_absolute_percentage_error: 77.9086\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - ETA: 0s - loss: 0.1030 - mean_absolute_percentage_error: 41166.3203\n",
            "Epoch 4: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.1030 - mean_absolute_percentage_error: 41166.3203 - val_loss: 0.0628 - val_mean_absolute_percentage_error: 70.4024\n",
            "Epoch 5/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0894 - mean_absolute_percentage_error: 81478.3125\n",
            "Epoch 5: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.0884 - mean_absolute_percentage_error: 75646.3359 - val_loss: 0.0504 - val_mean_absolute_percentage_error: 62.8757\n",
            "Epoch 6/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0720 - mean_absolute_percentage_error: 73771.6016\n",
            "Epoch 6: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.0736 - mean_absolute_percentage_error: 68491.6172 - val_loss: 0.0394 - val_mean_absolute_percentage_error: 55.3507\n",
            "Epoch 7/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0624 - mean_absolute_percentage_error: 95985.8438\n",
            "Epoch 7: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.0610 - mean_absolute_percentage_error: 89115.9141 - val_loss: 0.0297 - val_mean_absolute_percentage_error: 47.8121\n",
            "Epoch 8/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0551 - mean_absolute_percentage_error: 138585.5625\n",
            "Epoch 8: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.0540 - mean_absolute_percentage_error: 128662.6406 - val_loss: 0.0216 - val_mean_absolute_percentage_error: 40.4504\n",
            "Epoch 9/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0426 - mean_absolute_percentage_error: 102931.1641\n",
            "Epoch 9: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.0422 - mean_absolute_percentage_error: 95562.5312 - val_loss: 0.0150 - val_mean_absolute_percentage_error: 33.2777\n",
            "Epoch 10/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0385 - mean_absolute_percentage_error: 50.6402\n",
            "Epoch 10: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 54ms/step - loss: 0.0374 - mean_absolute_percentage_error: 121757.3203 - val_loss: 0.0096 - val_mean_absolute_percentage_error: 26.0793\n",
            "Epoch 11/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0334 - mean_absolute_percentage_error: 51.4622\n",
            "Epoch 11: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.0329 - mean_absolute_percentage_error: 149989.4375 - val_loss: 0.0057 - val_mean_absolute_percentage_error: 19.3070\n",
            "Epoch 12/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0255 - mean_absolute_percentage_error: 144822.7031\n",
            "Epoch 12: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.0248 - mean_absolute_percentage_error: 134454.7500 - val_loss: 0.0030 - val_mean_absolute_percentage_error: 13.1649\n",
            "Epoch 13/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0234 - mean_absolute_percentage_error: 137449.1875\n",
            "Epoch 13: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.0234 - mean_absolute_percentage_error: 127609.6641 - val_loss: 0.0015 - val_mean_absolute_percentage_error: 8.5287\n",
            "Epoch 14/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0216 - mean_absolute_percentage_error: 183079.1875\n",
            "Epoch 14: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.0219 - mean_absolute_percentage_error: 169970.8125 - val_loss: 7.5493e-04 - val_mean_absolute_percentage_error: 5.6500\n",
            "Epoch 15/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0193 - mean_absolute_percentage_error: 172875.4062\n",
            "Epoch 15: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.0188 - mean_absolute_percentage_error: 160498.2188 - val_loss: 5.8145e-04 - val_mean_absolute_percentage_error: 5.1969\n",
            "Epoch 16/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0182 - mean_absolute_percentage_error: 213947.2500\n",
            "Epoch 16: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.0180 - mean_absolute_percentage_error: 198628.4531 - val_loss: 6.3370e-04 - val_mean_absolute_percentage_error: 5.8817\n",
            "Epoch 17/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0175 - mean_absolute_percentage_error: 188763.5156\n",
            "Epoch 17: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.0171 - mean_absolute_percentage_error: 175248.2812 - val_loss: 7.0339e-04 - val_mean_absolute_percentage_error: 6.4248\n",
            "Epoch 18/100\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.0163 - mean_absolute_percentage_error: 213037.5469\n",
            "Epoch 18: val_loss did not improve from 0.00013\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.0167 - mean_absolute_percentage_error: 197783.1875 - val_loss: 7.0926e-04 - val_mean_absolute_percentage_error: 6.4881\n",
            "Epoch 18: early stopping\n",
            "Train Loss Terendah:  0.016748035326600075\n",
            "Epoch Stop:  17\n",
            "Val Loss Terendah:  0.0005814546020701528\n",
            "Epoch Val Loss Stop:  15\n",
            "==================================================================================================================\n",
            "\n",
            "Best Model Parameters:\n",
            "{'batch_size': 128.0, 'epochs': 100.0, 'learning_rate': 0.01, 'units': 32.0, 'Training Loss': 0.002454174682497978, 'Validation Loss': 0.000130919594084844, 'Mape': 0.06698218426529055}\n",
            "Epoch Stopped: 17\n",
            "Training Loss: 0.002454174682497978\n",
            "Validation Loss: 0.000130919594084844\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(123)\n",
        "random.seed(123)\n",
        "\n",
        "# Mendefinisikan hyperparameter yang akan digunakan\n",
        "param_grid = {\n",
        "    'epochs': [50,100],  # Jumlah iterasi\n",
        "    'batch_size': [32, 64, 128], # JUmlah batch dalam setiap iterasi\n",
        "    'units': [16, 32, 64], # Jumlah hidden unit dalam setiap hidden layer\n",
        "    'learning_rate': [0.01, 0.001, 0.0001], # Learning rate\n",
        "    'optimizer' : ['Adam']\n",
        "}\n",
        "# Kombinasi hyperparameter\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "# Menyimpan hasil akhir dari model\n",
        "result = []\n",
        "# Menyimpan niali loss selama pelatihan model\n",
        "losses = []\n",
        "\n",
        "\n",
        "# MEMBUAT MODEL CHECKPOINT CALLBACK UNTUK MENYIMPAN MODEL TERBAIK SAAT PELATIHAN\n",
        "checkpoint_callback = ModelCheckpoint(filepath='best_model.h5', # model terbaik akan disimpan dengan nama best_model.h5\n",
        "                                      monitor='val_loss', # Menentukan metrik yang akan dipantau untuk menentukan model terbaik. Model dengan nilai val_loss terendah akan dianggap sebagai model terbaik.\n",
        "                                      save_best_only=True, # Hanya model terbaik yang akan disimpan.\n",
        "                                      mode='min', # min berarti bahwa metrik yang lebih rendah lebih baik, sehingga model dengan val_loss terendah akan disimpan.\n",
        "                                      verbose=1 # verbose=1 akan menampilkan pesan di konsol setiap kali model terbaik disimpan. Ini memberikan informasi mengenai kapan checkpoint diambil.\n",
        "                                      )\n",
        "# MELATIH MODEL DENGAN SEMUA KOMBINASI HYPERPARAMETER\n",
        "for params in param_combinations:\n",
        "    print(\"==================================================================================================================\")\n",
        "    print(f\"Training with params: {params}\")\n",
        "    print(\"==================================================================================================================\\n\")\n",
        "    model = create_model(\n",
        "        params['units'],\n",
        "        params['learning_rate'],\n",
        "        params['epochs'],\n",
        "        params['batch_size'],\n",
        "        params['optimizer'])\n",
        "\n",
        "    early_stopping = EarlyStopping(patience=3, monitor='val_loss', verbose=1)\n",
        "    # Early stopping digunakan untuk menghemat waktu, ini bekerja dengan menghentikan epoch ketika nilai loss tidak mengalami peningkatan\n",
        "    # patiens=3 artinya epoch akan dihentikan ketika nilai loss tidak mengalami peningkatan setelah 3 epoch\n",
        "\n",
        "    # Fungsi ini melatih model menggunakan data pelatihan (X_train dan y_train) selama beberapa epoch yang ditentukan.\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=params['epochs'], batch_size=params['batch_size'], callbacks=[early_stopping, checkpoint_callback])\n",
        "    # history berisi riwayat pelatihan model, termasuk nilai loss dan metrik lainnya untuk setiap epoch.\n",
        "    epoch_stopped = early_stopping.stopped_epoch\n",
        "    # early_stopping adalah callback yang memonitor metrik tertentu (misalnya, val_loss) dan menghentikan pelatihan jika metrik tersebut tidak membaik setelah sejumlah epoch tertentu.\n",
        "    # epoch_stopped adalah atribut dari callback early_stopping yang menyimpan nomor epoch di mana pelatihan dihentikan lebih awal.\n",
        "\n",
        "    # HASIL NILAI LOSS DARI HISTORY\n",
        "    # train_loss untuk loss dari data training pada proses pembelajaran\n",
        "    train_loss = history.history['loss']\n",
        "    # val_loss untuk loss dari data testing pada proses pengujian\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # mencatat nilai loss pada tiap epoch\n",
        "    losses.append({'train_loss': train_loss, 'val_loss': val_loss})\n",
        "    # losses = sebuah list yg menyimpan dictionary\n",
        "    # setiap dictionary berisi nilai loss pada tiap epoch\n",
        "    # append = digunakan untuk menambahkan elemen baru ke dalam list\n",
        "\n",
        "    print('Train Loss Terendah: ', min(history.history['loss']))\n",
        "    print('Epoch Stop: ', history.history['loss'].index(min(history.history['loss'])))\n",
        "    print('Val Loss Terendah: ', min(history.history['val_loss']))\n",
        "    print('Epoch Val Loss Stop: ', history.history['val_loss'].index(min(history.history['val_loss']))+1)\n",
        "    print('==================================================================================================================\\n')\n",
        "\n",
        "    # MENYIMPAN HASIL KOMBIANSI HYPERPARAMETER\n",
        "    # menyimpan hasil pemodelan berdasarkan kombinasi parameter dalam list\n",
        "    result.append({**params, \"Epoch Stopped\": epoch_stopped, \"Training Loss\": min(train_loss), \"Validation Loss\": min(history.history['val_loss']), \"Mape\":mape})\n",
        "    # nilai loss yang dicatat merupakan nilai loss minimum\n",
        "\n",
        "# MENGUBAH DALAM BENTUK EXCEL\n",
        "# membuat dataframe untuk result agar mudah untuk dianalisis (dibuat tabel)\n",
        "result_df = pd.DataFrame(result)\n",
        "# menyimpan result dalam format excel\n",
        "result_df.to_excel(f'Result GRU Best Only {params[\"optimizer\"]}.xlsx', index=False)\n",
        "\n",
        "# MEMUAT MODEL TERBAIK\n",
        "# Mencari baris dalam dataframe result_df yang memiliki nilai minimum val loss\n",
        "# Menentukan parameter terbaik berdasarkan nilai minimum val loss\n",
        "best_result = result_df.loc[result_df['Validation Loss'].idxmin()]\n",
        "# membuat dictionary tanpa optimizer dan Epoch Stopped\n",
        "best_params = best_result.drop(['Epoch Stopped','optimizer']).to_dict()\n",
        "best_params = {param: float(value) for param, value in best_params.items()}\n",
        "\n",
        "\n",
        "# MENAMPILKAN HYPERPARAMETER TERBAIK\n",
        "print(\"Best Model Parameters:\")\n",
        "print(best_params)\n",
        "print(\"Epoch Stopped:\", epoch_stopped)\n",
        "print(\"Training Loss:\", best_result['Training Loss'].min())\n",
        "print(\"Validation Loss:\", best_result['Validation Loss'].min())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ofeaBrn9K6d"
      },
      "source": [
        " ## **PREDIKSI DENGAN BEST MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4UPcfGoPG6x",
        "outputId": "0d79c63d-089d-4226-df6d-663a3bb02ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 3ms/step\n",
            "4/4 [==============================] - 0s 5ms/step\n",
            "\n",
            "\n",
            "===============================================\n",
            "Nilai MAPE :\n",
            "0.012994266107830514\n",
            "===============================================\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(123)\n",
        "random.seed(123)\n",
        "##=====================================================================================================================================================##\n",
        "# PREDIKSI DATA LATIH & UJI BERDASARKAN MODEL TERBAIK\n",
        "# Load model terbaik\n",
        "\n",
        "best_model = load_model('best_model.h5')\n",
        "\n",
        "\n",
        "# menyimpan prediksi dari model terbaik pada data train\n",
        "y_pred_train_best = best_model.predict(X_train)\n",
        "# menyimpan prediksi dari model terbaik pada data test\n",
        "y_pred_test_best = best_model.predict(X_test)\n",
        "\n",
        "# DENORMALISASI DATA\n",
        "y_train_inverse = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
        "y_pred_train_inverse = scaler.inverse_transform(y_pred_train_best.reshape(-1, 1)).flatten()\n",
        "y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "y_pred_test_inverse = scaler.inverse_transform(y_pred_test_best.reshape(-1, 1)).flatten()\n",
        "\n",
        "# MENYIMPAN PREDIKSI SEBELUM DENORMALISASI\n",
        "y_train_normalized_series = pd.Series(y_train, name='y_train_normalized')\n",
        "y_pred_train_normalized = pd.Series(y_pred_train_best.flatten(), name='y_pred_train_normalized')\n",
        "y_train_series = pd.Series(y_train_inverse, name='y_train')\n",
        "y_pred_train_series = pd.Series(y_pred_train_inverse, name='y_pred_train')\n",
        "\n",
        "y_test_normalized_series = pd.Series(y_test, name='y_test_normalized')\n",
        "y_pred_test_normalized = pd.Series(y_pred_test_best.flatten(), name='y_pred_test_normalized')\n",
        "y_test_series = pd.Series(y_test_inverse, name='y_test')\n",
        "y_pred_test_series = pd.Series(y_pred_test_inverse, name='y_pred_test')\n",
        "\n",
        "# MENGGABUNGKAN DATA DALAM SATU DATA FRAME DAN MENYIMPANNYA DALAM BENTUK EXCEL\n",
        "# Data Train\n",
        "predict_train_df = pd.concat([y_train_normalized_series, y_pred_train_normalized, y_train_series, y_pred_train_series], axis=1)\n",
        "predict_train_df['Date'] = df.iloc[time_step:time_step+len(y_train)].index\n",
        "predict_train_df.to_excel('actual vs predictions training.xlsx', index=False)\n",
        "#Data Test\n",
        "predict_test_df = pd.concat([y_test_normalized_series, y_pred_test_normalized, y_test_series, y_pred_test_series], axis=1)\n",
        "predict_test_df['Date'] = df.iloc[-len(y_test):].index\n",
        "predict_test_df.to_excel('actual vs predictions testing.xlsx', index=False)\n",
        "\n",
        "##====================================================================================================================================================##\n",
        "mape = mean_absolute_percentage_error(y_test_inverse, y_pred_test_inverse)\n",
        "print('\\n')\n",
        "print('===============================================')\n",
        "print('Nilai MAPE :')\n",
        "print(mape)\n",
        "print('===============================================')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvvV11nCikAn",
        "outputId": "3badd9b6-9710-4f42-d8f7-200dcc25c569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time_step: 20\n",
            "len(df): 1262\n",
            "len(y_train): 1115\n"
          ]
        }
      ],
      "source": [
        "# Optional, hanya checking\n",
        "# Check time_step dan panjang data dari df\n",
        "print(f\"time_step: {time_step}\")\n",
        "print(f\"len(df): {len(df)}\")\n",
        "print(f\"len(y_train): {len(y_train)}\")\n",
        "\n",
        "if time_step >= len(df) or time_step + len(y_train) <= 0:\n",
        "    print(\"Error: Invalid time_step value.\")\n",
        "else:\n",
        "    predict_train_df['Date'] = df.iloc[time_step:time_step + len(y_train)].index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez7NwzHfEiiz"
      },
      "source": [
        " ### **Menyimpan Bobot Terbaik dari Model Terbaik (Model Checkpoint)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0zbPFYbExQ4"
      },
      "outputs": [],
      "source": [
        "# Mendapatkan bobot dari model terbaik\n",
        "weights = best_model.get_weights()\n",
        "# Save weights to Excel\n",
        "with pd.ExcelWriter('best_model_weights.xlsx') as writer:\n",
        "    for i, weight in enumerate(weights):\n",
        "        bobot = pd.DataFrame(weight)\n",
        "        bobot.to_excel(writer, sheet_name=f'Layer_{i+1}', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqyJkMERODti"
      },
      "source": [
        "## **GRAFIK AKTUAL DAN PREDIKSI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "RxDCZWq7OB9D",
        "outputId": "52d5c8bd-71a1-4141-90b9-9a6af4da363b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-ce9c6661fb58>:3: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  predict_test_df['Date'] = pd.to_datetime(predict_test_df['Date'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Menentukan size gambar\n",
        "plt.figure(figsize=(12,6))\n",
        "predict_test_df['Date'] = pd.to_datetime(predict_test_df['Date'])\n",
        "plt.plot(predict_test_df['Date'], predict_test_df['y_test'], label='Aktual', color='blue')\n",
        "plt.plot(predict_test_df['Date'], predict_test_df['y_pred_test'], label='Prediksi', color='red')\n",
        "plt.xlabel('Waktu')\n",
        "plt.ylabel('Harga Penutupan Timah Harian')\n",
        "plt.title('Grafik Data Aktual dan Prediksi')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcaSjg02mkk6"
      },
      "source": [
        "## **PREDIKSI 20 HARI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FXpUkxNzKA6",
        "outputId": "cfa6c9b6-a7b4-4de2-fcb1-5b1ab24fe046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.28237288]\n",
            "  [0.29655367]\n",
            "  [0.30548023]\n",
            "  [0.30341808]\n",
            "  [0.32019774]\n",
            "  [0.32274011]\n",
            "  [0.31968927]\n",
            "  [0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]]]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "[[[0.29655367]\n",
            "  [0.30548023]\n",
            "  [0.30341808]\n",
            "  [0.32019774]\n",
            "  [0.32274011]\n",
            "  [0.31968927]\n",
            "  [0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]]]\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "[[[0.30548023]\n",
            "  [0.30341808]\n",
            "  [0.32019774]\n",
            "  [0.32274011]\n",
            "  [0.31968927]\n",
            "  [0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]]]\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "[[[0.30341808]\n",
            "  [0.32019774]\n",
            "  [0.32274011]\n",
            "  [0.31968927]\n",
            "  [0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]]]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[[0.32019774]\n",
            "  [0.32274011]\n",
            "  [0.31968927]\n",
            "  [0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]]]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "[[[0.32274011]\n",
            "  [0.31968927]\n",
            "  [0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]]]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "[[[0.31968927]\n",
            "  [0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]]]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "[[[0.31381356]\n",
            "  [0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]]]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "[[[0.3200565 ]\n",
            "  [0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]]]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[[0.32316384]\n",
            "  [0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]]]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "[[[0.34228814]\n",
            "  [0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]]]\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "[[[0.33686441]\n",
            "  [0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]]]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "[[[0.32683616]\n",
            "  [0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]]]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "[[[0.33579096]\n",
            "  [0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]\n",
            "  [0.3863613 ]]]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "[[[0.33765537]\n",
            "  [0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]\n",
            "  [0.3863613 ]\n",
            "  [0.3891235 ]]]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "[[[0.33624294]\n",
            "  [0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]\n",
            "  [0.3863613 ]\n",
            "  [0.3891235 ]\n",
            "  [0.391839  ]]]\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "[[[0.32813559]\n",
            "  [0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]\n",
            "  [0.3863613 ]\n",
            "  [0.3891235 ]\n",
            "  [0.391839  ]\n",
            "  [0.39450896]]]\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "[[[0.35011299]\n",
            "  [0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]\n",
            "  [0.3863613 ]\n",
            "  [0.3891235 ]\n",
            "  [0.391839  ]\n",
            "  [0.39450896]\n",
            "  [0.39713457]]]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "[[[0.35112994]\n",
            "  [0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]\n",
            "  [0.3863613 ]\n",
            "  [0.3891235 ]\n",
            "  [0.391839  ]\n",
            "  [0.39450896]\n",
            "  [0.39713457]\n",
            "  [0.39971712]]]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "[[[0.34364407]\n",
            "  [0.35225597]\n",
            "  [0.35306808]\n",
            "  [0.35612094]\n",
            "  [0.35927773]\n",
            "  [0.36245993]\n",
            "  [0.36562008]\n",
            "  [0.36873761]\n",
            "  [0.37180483]\n",
            "  [0.37481943]\n",
            "  [0.37778133]\n",
            "  [0.38069147]\n",
            "  [0.38355106]\n",
            "  [0.3863613 ]\n",
            "  [0.3891235 ]\n",
            "  [0.391839  ]\n",
            "  [0.39450896]\n",
            "  [0.39713457]\n",
            "  [0.39971712]\n",
            "  [0.40225756]]]\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Prediksi 20 data selanjutnya:\n",
            "[[25719.861]\n",
            " [25748.61 ]\n",
            " [25856.682]\n",
            " [25968.432]\n",
            " [26081.082]\n",
            " [26192.951]\n",
            " [26303.31 ]\n",
            " [26411.893]\n",
            " [26518.607]\n",
            " [26623.459]\n",
            " [26726.479]\n",
            " [26827.709]\n",
            " [26927.191]\n",
            " [27024.973]\n",
            " [27121.1  ]\n",
            " [27215.617]\n",
            " [27308.562]\n",
            " [27399.986]\n",
            " [27489.918]\n",
            " [27578.402]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Misalkan `model` adalah model terlatih dan `test_data` adalah data uji\n",
        "time_step = 20\n",
        "num_predictions = 20\n",
        "\n",
        "# Mengambil 20 timestep terakhir dari data uji sebagai input awal\n",
        "last_timestep_data = test_data[-time_step:]\n",
        "\n",
        "# Menyimpan prediksi di array\n",
        "predictions = []\n",
        "\n",
        "# Loop untuk menghasilkan prediksi sebanyak num_predictions\n",
        "for _ in range(num_predictions):\n",
        "    # Mengubah bentuk data menjadi (1, time_step, 1) untuk prediksi\n",
        "    input_data = np.reshape(last_timestep_data, (1, time_step, 1))\n",
        "    print(input_data)\n",
        "    # Melakukan prediksi menggunakan model\n",
        "    # l\n",
        "    predicted_value = best_model.predict(input_data)\n",
        "\n",
        "    # Menyimpan prediksi\n",
        "    predictions.append(predicted_value[0, 0])\n",
        "\n",
        "    # Memperbarui last_timestep_data dengan menambahkan prediksi terbaru dan menghapus yang tertua\n",
        "    last_timestep_data = np.append(last_timestep_data[1:], predicted_value)\n",
        "\n",
        "# Konversi prediksi ke numpy array\n",
        "predictions = np.array(predictions)\n",
        "\n",
        "# Invers transformasi untuk mendapatkan nilai asli\n",
        "predictions = scaler.inverse_transform(predictions.reshape(-1, 1))\n",
        "forecast_df = pd.DataFrame({'Prediksi': predictions.flatten()})\n",
        "\n",
        "print(\"Prediksi 20 data selanjutnya:\")\n",
        "print(predictions)\n",
        "forecast_df.to_excel('Prediksi 20 hari.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj6T9rxM0QLq"
      },
      "source": [
        "## **ANALISIS GRAFIK LOSS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NGyqxmzooRg_",
        "outputId": "6e6d03a7-2900-4e3e-d0b2-20bb3ffbc7b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================================================================================\n",
            "Training with params: {'batch_size': 32, 'epochs': 100, 'learning_rate': 0.01, 'optimizer': 'Adam', 'units': 16}\n",
            "==================================================================================================================\n",
            "\n",
            "Epoch 1/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0207 - mean_absolute_percentage_error: 270710.9688\n",
            "Epoch 1: val_loss improved from inf to 0.00019, saving model to best_model.h5\n",
            "35/35 [==============================] - 8s 34ms/step - loss: 0.0200 - mean_absolute_percentage_error: 256387.5000 - val_loss: 1.8663e-04 - val_mean_absolute_percentage_error: 3.2118\n",
            "Epoch 2/100\n",
            "12/35 [=========>....................] - ETA: 0s - loss: 0.0079 - mean_absolute_percentage_error: 26.7739"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0065 - mean_absolute_percentage_error: 404.5380\n",
            "Epoch 2: val_loss did not improve from 0.00019\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0065 - mean_absolute_percentage_error: 385.1004 - val_loss: 5.6457e-04 - val_mean_absolute_percentage_error: 6.0821\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0054 - mean_absolute_percentage_error: 11233.5869\n",
            "Epoch 3: val_loss did not improve from 0.00019\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0054 - mean_absolute_percentage_error: 11233.5869 - val_loss: 3.4733e-04 - val_mean_absolute_percentage_error: 4.8224\n",
            "Epoch 4/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0038 - mean_absolute_percentage_error: 44690.2305\n",
            "Epoch 4: val_loss improved from 0.00019 to 0.00015, saving model to best_model.h5\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 0.0038 - mean_absolute_percentage_error: 43608.3945 - val_loss: 1.5429e-04 - val_mean_absolute_percentage_error: 2.7962\n",
            "Epoch 5/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 58574.0312\n",
            "Epoch 5: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 0.0030 - mean_absolute_percentage_error: 55475.5273 - val_loss: 5.7257e-04 - val_mean_absolute_percentage_error: 6.1875\n",
            "Epoch 6/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 76083.8984\n",
            "Epoch 6: val_loss improved from 0.00015 to 0.00015, saving model to best_model.h5\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 0.0030 - mean_absolute_percentage_error: 74242.0625 - val_loss: 1.4981e-04 - val_mean_absolute_percentage_error: 2.7936\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 1864.1882\n",
            "Epoch 7: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 0.0033 - mean_absolute_percentage_error: 1864.1882 - val_loss: 7.9321e-04 - val_mean_absolute_percentage_error: 7.7141\n",
            "Epoch 8/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 28182.8594\n",
            "Epoch 8: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 0.0028 - mean_absolute_percentage_error: 27500.8262 - val_loss: 1.5757e-04 - val_mean_absolute_percentage_error: 2.9979\n",
            "Epoch 9/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 56935.2383\n",
            "Epoch 9: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 0.0025 - mean_absolute_percentage_error: 55557.1211 - val_loss: 3.8311e-04 - val_mean_absolute_percentage_error: 5.0858\n",
            "Epoch 10/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 77003.5234\n",
            "Epoch 10: val_loss improved from 0.00015 to 0.00015, saving model to best_model.h5\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0027 - mean_absolute_percentage_error: 70720.3594 - val_loss: 1.4692e-04 - val_mean_absolute_percentage_error: 2.7602\n",
            "Epoch 11/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 87480.3125\n",
            "Epoch 11: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0029 - mean_absolute_percentage_error: 82852.2969 - val_loss: 1.7460e-04 - val_mean_absolute_percentage_error: 3.2297\n",
            "Epoch 12/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 88598.7344\n",
            "Epoch 12: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0029 - mean_absolute_percentage_error: 76285.5781 - val_loss: 1.6869e-04 - val_mean_absolute_percentage_error: 3.1636\n",
            "Epoch 13/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 93967.3125 \n",
            "Epoch 13: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0029 - mean_absolute_percentage_error: 91692.4297 - val_loss: 4.8674e-04 - val_mean_absolute_percentage_error: 5.6629\n",
            "Epoch 14/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 1208.5555\n",
            "Epoch 14: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 1145.8341 - val_loss: 5.2541e-04 - val_mean_absolute_percentage_error: 6.0030\n",
            "Epoch 15/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 79637.7656\n",
            "Epoch 15: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 75425.8594 - val_loss: 2.1445e-04 - val_mean_absolute_percentage_error: 3.4120\n",
            "Epoch 16/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 34781.0078\n",
            "Epoch 16: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0028 - mean_absolute_percentage_error: 32941.2227 - val_loss: 1.5366e-04 - val_mean_absolute_percentage_error: 2.7941\n",
            "Epoch 17/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 115435.9062\n",
            "Epoch 17: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0027 - mean_absolute_percentage_error: 109328.8203 - val_loss: 3.9230e-04 - val_mean_absolute_percentage_error: 4.8054\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 46119.4141\n",
            "Epoch 18: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0031 - mean_absolute_percentage_error: 46119.4141 - val_loss: 1.5783e-04 - val_mean_absolute_percentage_error: 3.0362\n",
            "Epoch 19/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 64412.9375\n",
            "Epoch 19: val_loss did not improve from 0.00015\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0027 - mean_absolute_percentage_error: 61005.6406 - val_loss: 1.6639e-04 - val_mean_absolute_percentage_error: 3.1240\n",
            "Epoch 20/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 21.4228\n",
            "Epoch 20: val_loss improved from 0.00015 to 0.00013, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 89471.1016 - val_loss: 1.2693e-04 - val_mean_absolute_percentage_error: 2.6903\n",
            "Epoch 21/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 101372.3984\n",
            "Epoch 21: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0027 - mean_absolute_percentage_error: 98918.7266 - val_loss: 3.3984e-04 - val_mean_absolute_percentage_error: 4.8157\n",
            "Epoch 22/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 53979.4766\n",
            "Epoch 22: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0024 - mean_absolute_percentage_error: 46477.9141 - val_loss: 5.9531e-04 - val_mean_absolute_percentage_error: 6.6453\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 37756.4180\n",
            "Epoch 23: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0026 - mean_absolute_percentage_error: 37756.4180 - val_loss: 3.6287e-04 - val_mean_absolute_percentage_error: 4.8650\n",
            "Epoch 24/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 90198.2891\n",
            "Epoch 24: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0029 - mean_absolute_percentage_error: 82838.7031 - val_loss: 2.9826e-04 - val_mean_absolute_percentage_error: 4.4038\n",
            "Epoch 25/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 86645.8750 \n",
            "Epoch 25: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0024 - mean_absolute_percentage_error: 82062.1406 - val_loss: 1.3253e-04 - val_mean_absolute_percentage_error: 2.7759\n",
            "Epoch 26/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 45765.3477\n",
            "Epoch 26: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 40719.6680 - val_loss: 1.5343e-04 - val_mean_absolute_percentage_error: 2.9989\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 31611.6992\n",
            "Epoch 27: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0028 - mean_absolute_percentage_error: 31611.6992 - val_loss: 1.4992e-04 - val_mean_absolute_percentage_error: 2.7538\n",
            "Epoch 28/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 133429.0625\n",
            "Epoch 28: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0028 - mean_absolute_percentage_error: 122540.9688 - val_loss: 8.1588e-04 - val_mean_absolute_percentage_error: 7.9051\n",
            "Epoch 29/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 113644.2422\n",
            "Epoch 29: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0028 - mean_absolute_percentage_error: 101109.5547 - val_loss: 1.3373e-04 - val_mean_absolute_percentage_error: 2.6892\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 8475.9463 \n",
            "Epoch 30: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 8475.9463 - val_loss: 5.3243e-04 - val_mean_absolute_percentage_error: 5.8728\n",
            "Epoch 31/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 40200.2695\n",
            "Epoch 31: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0025 - mean_absolute_percentage_error: 35767.8711 - val_loss: 5.0882e-04 - val_mean_absolute_percentage_error: 6.0970\n",
            "Epoch 32/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 163465.5781\n",
            "Epoch 32: val_loss did not improve from 0.00013\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0026 - mean_absolute_percentage_error: 140744.7188 - val_loss: 1.6262e-04 - val_mean_absolute_percentage_error: 2.9318\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 74393.5781\n",
            "Epoch 33: val_loss improved from 0.00013 to 0.00011, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0027 - mean_absolute_percentage_error: 74393.5781 - val_loss: 1.1210e-04 - val_mean_absolute_percentage_error: 2.4899\n",
            "Epoch 34/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 47017.7930\n",
            "Epoch 34: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0025 - mean_absolute_percentage_error: 45879.8242 - val_loss: 1.3623e-04 - val_mean_absolute_percentage_error: 2.7958\n",
            "Epoch 35/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 131278.1406\n",
            "Epoch 35: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0029 - mean_absolute_percentage_error: 128099.6562 - val_loss: 2.5936e-04 - val_mean_absolute_percentage_error: 4.0674\n",
            "Epoch 36/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 3224.1262\n",
            "Epoch 36: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0024 - mean_absolute_percentage_error: 3054.7158 - val_loss: 5.3728e-04 - val_mean_absolute_percentage_error: 6.1553\n",
            "Epoch 37/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 30115.2637\n",
            "Epoch 37: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0024 - mean_absolute_percentage_error: 29386.2676 - val_loss: 1.2386e-04 - val_mean_absolute_percentage_error: 2.4697\n",
            "Epoch 38/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 21601.7285\n",
            "Epoch 38: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0027 - mean_absolute_percentage_error: 20459.4453 - val_loss: 1.2620e-04 - val_mean_absolute_percentage_error: 2.5964\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 181739.5000\n",
            "Epoch 39: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0031 - mean_absolute_percentage_error: 181739.5000 - val_loss: 1.2557e-04 - val_mean_absolute_percentage_error: 2.6437\n",
            "Epoch 40/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 13043.4141\n",
            "Epoch 40: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0025 - mean_absolute_percentage_error: 11981.1260 - val_loss: 2.1764e-04 - val_mean_absolute_percentage_error: 3.4626\n",
            "Epoch 41/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 44024.3242\n",
            "Epoch 41: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0027 - mean_absolute_percentage_error: 42958.5859 - val_loss: 6.6334e-04 - val_mean_absolute_percentage_error: 6.9759\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 50691.6992\n",
            "Epoch 42: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 0.0029 - mean_absolute_percentage_error: 50691.6992 - val_loss: 3.7542e-04 - val_mean_absolute_percentage_error: 5.1083\n",
            "Epoch 43/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 69559.3750\n",
            "Epoch 43: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0031 - mean_absolute_percentage_error: 59892.2812 - val_loss: 1.1320e-04 - val_mean_absolute_percentage_error: 2.5214\n",
            "Epoch 44/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 17727.9219\n",
            "Epoch 44: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0024 - mean_absolute_percentage_error: 16282.4932 - val_loss: 3.5927e-04 - val_mean_absolute_percentage_error: 4.7881\n",
            "Epoch 45/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 36948.0664\n",
            "Epoch 45: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 32874.2773 - val_loss: 1.2071e-04 - val_mean_absolute_percentage_error: 2.5934\n",
            "Epoch 46/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 3969.3645\n",
            "Epoch 46: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0030 - mean_absolute_percentage_error: 3646.9089 - val_loss: 1.1662e-04 - val_mean_absolute_percentage_error: 2.4608\n",
            "Epoch 47/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 19786.4609\n",
            "Epoch 47: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0027 - mean_absolute_percentage_error: 19308.0469 - val_loss: 1.1260e-04 - val_mean_absolute_percentage_error: 2.5083\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 34949.3711\n",
            "Epoch 48: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0025 - mean_absolute_percentage_error: 34949.3711 - val_loss: 5.7150e-04 - val_mean_absolute_percentage_error: 6.5317\n",
            "Epoch 49/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 23919.6074\n",
            "Epoch 49: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 22655.0957 - val_loss: 1.2800e-04 - val_mean_absolute_percentage_error: 2.5668\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 71835.1953\n",
            "Epoch 50: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0026 - mean_absolute_percentage_error: 71835.1953 - val_loss: 7.0773e-04 - val_mean_absolute_percentage_error: 7.2071\n",
            "Epoch 51/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 7201.9946\n",
            "Epoch 51: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0026 - mean_absolute_percentage_error: 6822.2949 - val_loss: 1.2629e-04 - val_mean_absolute_percentage_error: 2.5242\n",
            "Epoch 52/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 19.7199\n",
            "Epoch 52: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0027 - mean_absolute_percentage_error: 31007.7910 - val_loss: 1.6162e-04 - val_mean_absolute_percentage_error: 3.0462\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 30419.0449\n",
            "Epoch 53: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0028 - mean_absolute_percentage_error: 30419.0449 - val_loss: 2.4197e-04 - val_mean_absolute_percentage_error: 3.8183\n",
            "Epoch 54/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 92971.8750 \n",
            "Epoch 54: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0024 - mean_absolute_percentage_error: 85385.5703 - val_loss: 3.5818e-04 - val_mean_absolute_percentage_error: 4.8863\n",
            "Epoch 55/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 5001.6333\n",
            "Epoch 55: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0030 - mean_absolute_percentage_error: 4881.3203 - val_loss: 1.3201e-04 - val_mean_absolute_percentage_error: 2.5601\n",
            "Epoch 56/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0023 - mean_absolute_percentage_error: 77940.9922\n",
            "Epoch 56: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0023 - mean_absolute_percentage_error: 76053.9219 - val_loss: 1.3863e-04 - val_mean_absolute_percentage_error: 2.8002\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 6602.1807\n",
            "Epoch 57: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0025 - mean_absolute_percentage_error: 6602.1807 - val_loss: 1.2075e-04 - val_mean_absolute_percentage_error: 2.5639\n",
            "Epoch 58/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0033 - mean_absolute_percentage_error: 41827.2461\n",
            "Epoch 58: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0032 - mean_absolute_percentage_error: 40814.7969 - val_loss: 1.5772e-04 - val_mean_absolute_percentage_error: 2.8727\n",
            "Epoch 59/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 105162.7578\n",
            "Epoch 59: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0025 - mean_absolute_percentage_error: 102617.0078 - val_loss: 1.4206e-04 - val_mean_absolute_percentage_error: 2.8305\n",
            "Epoch 60/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 70226.7812\n",
            "Epoch 60: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0025 - mean_absolute_percentage_error: 60467.0781 - val_loss: 1.9076e-04 - val_mean_absolute_percentage_error: 3.2668\n",
            "Epoch 61/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 90306.7891\n",
            "Epoch 61: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0028 - mean_absolute_percentage_error: 82937.8906 - val_loss: 1.2329e-04 - val_mean_absolute_percentage_error: 2.6397\n",
            "Epoch 62/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 75321.4609\n",
            "Epoch 62: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0027 - mean_absolute_percentage_error: 71336.8516 - val_loss: 1.7574e-04 - val_mean_absolute_percentage_error: 3.0538\n",
            "Epoch 63/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 82028.4062\n",
            "Epoch 63: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 72981.9062 - val_loss: 2.5708e-04 - val_mean_absolute_percentage_error: 4.0860\n",
            "Epoch 64/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 88731.1797 \n",
            "Epoch 64: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0026 - mean_absolute_percentage_error: 84037.3281 - val_loss: 1.5259e-04 - val_mean_absolute_percentage_error: 2.9468\n",
            "Epoch 65/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 82718.8672\n",
            "Epoch 65: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0025 - mean_absolute_percentage_error: 78342.8984 - val_loss: 1.3938e-04 - val_mean_absolute_percentage_error: 2.6718\n",
            "Epoch 66/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 53639.2578\n",
            "Epoch 66: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0027 - mean_absolute_percentage_error: 50801.7734 - val_loss: 1.2237e-04 - val_mean_absolute_percentage_error: 2.5659\n",
            "Epoch 67/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 59641.0547\n",
            "Epoch 67: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0026 - mean_absolute_percentage_error: 58197.7266 - val_loss: 7.3853e-04 - val_mean_absolute_percentage_error: 7.4700\n",
            "Epoch 68/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 8021.5444\n",
            "Epoch 68: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0030 - mean_absolute_percentage_error: 7368.4565 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 9.9117\n",
            "Epoch 69/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 67361.6953\n",
            "Epoch 69: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0030 - mean_absolute_percentage_error: 63798.0898 - val_loss: 1.5380e-04 - val_mean_absolute_percentage_error: 2.9592\n",
            "Epoch 70/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 73753.9297\n",
            "Epoch 70: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0025 - mean_absolute_percentage_error: 69853.2891 - val_loss: 2.8531e-04 - val_mean_absolute_percentage_error: 4.1835\n",
            "Epoch 71/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 5322.9878\n",
            "Epoch 71: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0025 - mean_absolute_percentage_error: 5042.5811 - val_loss: 1.1612e-04 - val_mean_absolute_percentage_error: 2.5329\n",
            "Epoch 72/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 42451.4648\n",
            "Epoch 72: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0029 - mean_absolute_percentage_error: 38988.1289 - val_loss: 1.7841e-04 - val_mean_absolute_percentage_error: 3.2209\n",
            "Epoch 73/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 21086.8066\n",
            "Epoch 73: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0026 - mean_absolute_percentage_error: 18159.3770 - val_loss: 1.5014e-04 - val_mean_absolute_percentage_error: 2.9072\n",
            "Epoch 74/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 4823.3828\n",
            "Epoch 74: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0024 - mean_absolute_percentage_error: 4569.1113 - val_loss: 1.6543e-04 - val_mean_absolute_percentage_error: 2.9777\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 69639.1328\n",
            "Epoch 75: val_loss improved from 0.00011 to 0.00011, saving model to best_model.h5\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0027 - mean_absolute_percentage_error: 69639.1328 - val_loss: 1.0997e-04 - val_mean_absolute_percentage_error: 2.4588\n",
            "Epoch 76/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 27525.0762\n",
            "Epoch 76: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0025 - mean_absolute_percentage_error: 25280.3691 - val_loss: 4.4996e-04 - val_mean_absolute_percentage_error: 5.5803\n",
            "Epoch 77/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 50715.9219\n",
            "Epoch 77: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 15ms/step - loss: 0.0029 - mean_absolute_percentage_error: 48033.8633 - val_loss: 1.1333e-04 - val_mean_absolute_percentage_error: 2.4878\n",
            "Epoch 78/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0024 - mean_absolute_percentage_error: 49770.8984\n",
            "Epoch 78: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0025 - mean_absolute_percentage_error: 45710.3984 - val_loss: 2.3017e-04 - val_mean_absolute_percentage_error: 3.6586\n",
            "Epoch 79/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 851.9172\n",
            "Epoch 79: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0028 - mean_absolute_percentage_error: 807.8228 - val_loss: 3.9071e-04 - val_mean_absolute_percentage_error: 4.8636\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 7617.8599\n",
            "Epoch 80: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0027 - mean_absolute_percentage_error: 7617.8599 - val_loss: 1.7459e-04 - val_mean_absolute_percentage_error: 3.1925\n",
            "Epoch 81/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 70513.9609\n",
            "Epoch 81: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0029 - mean_absolute_percentage_error: 68807.1562 - val_loss: 3.2704e-04 - val_mean_absolute_percentage_error: 4.7555\n",
            "Epoch 82/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 26612.9258\n",
            "Epoch 82: val_loss improved from 0.00011 to 0.00011, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 14ms/step - loss: 0.0027 - mean_absolute_percentage_error: 25968.7852 - val_loss: 1.0772e-04 - val_mean_absolute_percentage_error: 2.4117\n",
            "Epoch 83/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 28941.5332\n",
            "Epoch 83: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0024 - mean_absolute_percentage_error: 27410.7793 - val_loss: 4.8693e-04 - val_mean_absolute_percentage_error: 5.7514\n",
            "Epoch 84/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 83860.9375 \n",
            "Epoch 84: val_loss improved from 0.00011 to 0.00011, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0027 - mean_absolute_percentage_error: 77018.7266 - val_loss: 1.0709e-04 - val_mean_absolute_percentage_error: 2.3983\n",
            "Epoch 85/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 32592.4082\n",
            "Epoch 85: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0029 - mean_absolute_percentage_error: 28998.9375 - val_loss: 3.2009e-04 - val_mean_absolute_percentage_error: 4.4544\n",
            "Epoch 86/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0026 - mean_absolute_percentage_error: 80172.3672\n",
            "Epoch 86: val_loss improved from 0.00011 to 0.00011, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0025 - mean_absolute_percentage_error: 71330.8672 - val_loss: 1.0696e-04 - val_mean_absolute_percentage_error: 2.3920\n",
            "Epoch 87/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 55318.3477\n",
            "Epoch 87: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0029 - mean_absolute_percentage_error: 50805.5000 - val_loss: 3.3812e-04 - val_mean_absolute_percentage_error: 4.7893\n",
            "Epoch 88/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 22300.0156\n",
            "Epoch 88: val_loss improved from 0.00011 to 0.00011, saving model to best_model.h5\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0031 - mean_absolute_percentage_error: 21760.5000 - val_loss: 1.0560e-04 - val_mean_absolute_percentage_error: 2.3682\n",
            "Epoch 89/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 105273.2500\n",
            "Epoch 89: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0025 - mean_absolute_percentage_error: 102727.4375 - val_loss: 1.6742e-04 - val_mean_absolute_percentage_error: 3.0021\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 13828.2930\n",
            "Epoch 90: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 13ms/step - loss: 0.0025 - mean_absolute_percentage_error: 13828.2930 - val_loss: 2.8279e-04 - val_mean_absolute_percentage_error: 4.3366\n",
            "Epoch 91/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 45860.7969\n",
            "Epoch 91: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0030 - mean_absolute_percentage_error: 43434.8906 - val_loss: 1.8372e-04 - val_mean_absolute_percentage_error: 3.2778\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0027 - mean_absolute_percentage_error: 11662.5107\n",
            "Epoch 92: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0027 - mean_absolute_percentage_error: 11662.5107 - val_loss: 1.2206e-04 - val_mean_absolute_percentage_error: 2.4702\n",
            "Epoch 93/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0025 - mean_absolute_percentage_error: 22662.9199\n",
            "Epoch 93: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0025 - mean_absolute_percentage_error: 20817.1484 - val_loss: 1.1243e-04 - val_mean_absolute_percentage_error: 2.4820\n",
            "Epoch 94/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 95677.6406 \n",
            "Epoch 94: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0027 - mean_absolute_percentage_error: 90615.8359 - val_loss: 1.6717e-04 - val_mean_absolute_percentage_error: 3.0989\n",
            "Epoch 95/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 113275.1484\n",
            "Epoch 95: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0029 - mean_absolute_percentage_error: 107282.1406 - val_loss: 1.6829e-04 - val_mean_absolute_percentage_error: 2.9968\n",
            "Epoch 96/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0030 - mean_absolute_percentage_error: 64879.6680\n",
            "Epoch 96: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 16ms/step - loss: 0.0029 - mean_absolute_percentage_error: 61447.9922 - val_loss: 1.2827e-04 - val_mean_absolute_percentage_error: 2.6692\n",
            "Epoch 97/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 84802.5703\n",
            "Epoch 97: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0027 - mean_absolute_percentage_error: 80316.2031 - val_loss: 1.5582e-04 - val_mean_absolute_percentage_error: 2.8713\n",
            "Epoch 98/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_absolute_percentage_error: 104961.0703\n",
            "Epoch 98: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0028 - mean_absolute_percentage_error: 99407.9531 - val_loss: 0.0012 - val_mean_absolute_percentage_error: 9.7413\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.0031 - mean_absolute_percentage_error: 53389.8906\n",
            "Epoch 99: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 0.0031 - mean_absolute_percentage_error: 53389.8906 - val_loss: 1.1852e-04 - val_mean_absolute_percentage_error: 2.5059\n",
            "Epoch 100/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_absolute_percentage_error: 129442.5312\n",
            "Epoch 100: val_loss did not improve from 0.00011\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 0.0028 - mean_absolute_percentage_error: 118879.8828 - val_loss: 2.2514e-04 - val_mean_absolute_percentage_error: 3.6167\n",
            "Train Loss Terendah:  0.0022963068913668394\n",
            "Epoch Stop:  55\n",
            "Val Loss Terendah:  0.00010560408554738387\n",
            "Epoch Val Loss Stop:  88\n",
            "==================================================================================================================\n",
            "\n",
            "Best Model Parameters:\n",
            "{'batch_size': 32.0, 'epochs': 100.0, 'learning_rate': 0.01, 'units': 16.0, 'Training Loss': 0.0022963068913668394, 'Validation Loss': 0.00010560408554738387}\n",
            "Training Loss: 0.0022963068913668394\n",
            "Validation Loss: 0.00010560408554738387\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(123)\n",
        "random.seed(123)\n",
        "\n",
        "# Mendefinisikan hyperparameter yang akan digunakan\n",
        "param_grid = {\n",
        "    'epochs': [100],  # Jumlah iterasi\n",
        "    'batch_size': [32], # JUmlah batch dalam setiap iterasi\n",
        "    'units': [16], # Jumlah hidden unit dalam setiap hidden layer\n",
        "    'learning_rate': [0.01], # Learning rate\n",
        "    'optimizer' : ['Adam']\n",
        "}\n",
        "# Kombinasi hyperparameter\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "# Menyimpan hasil akhir dari model\n",
        "result = []\n",
        "# Menyimpan niali loss selama pelatihan model\n",
        "losses = []\n",
        "\n",
        "\n",
        "# MEMBUAT MODEL CHECKPOINT CALLBACK UNTUK MENYIMPAN MODEL TERBAIK SAAT PELATIHAN\n",
        "checkpoint_callback = ModelCheckpoint(filepath='best_model.h5', # model terbaik akan disimpan dengan nama best_model.h5\n",
        "                                      monitor='val_loss', # Menentukan metrik yang akan dipantau untuk menentukan model terbaik. Model dengan nilai val_loss terendah akan dianggap sebagai model terbaik.\n",
        "                                      save_best_only=True, # Hanya model terbaik yang akan disimpan.\n",
        "                                      mode='min', # min berarti bahwa metrik yang lebih rendah lebih baik, sehingga model dengan val_loss terendah akan disimpan.\n",
        "                                      verbose=1 # verbose=1 akan menampilkan pesan di konsol setiap kali model terbaik disimpan. Ini memberikan informasi mengenai kapan checkpoint diambil.\n",
        "                                      )\n",
        "# MELATIH MODEL DENGAN SEMUA KOMBINASI HYPERPARAMETER\n",
        "for params in param_combinations:\n",
        "    print(\"==================================================================================================================\")\n",
        "    print(f\"Training with params: {params}\")\n",
        "    print(\"==================================================================================================================\\n\")\n",
        "    model = create_model(\n",
        "        params['units'],\n",
        "        params['learning_rate'],\n",
        "        params['epochs'],\n",
        "        params['batch_size'],\n",
        "        params['optimizer'])\n",
        "\n",
        "    # Early stopping digunakan untuk menghemat waktu, ini bekerja dengan menghentikan epoch ketika nilai loss tidak mengalami peningkatan\n",
        "    # patiens=3 artinya epoch akan dihentikan ketika nilai loss tidak mengalami peningkatan setelah 3 epoch\n",
        "\n",
        "    # Fungsi ini melatih model menggunakan data pelatihan (X_train dan y_train) selama beberapa epoch yang ditentukan.\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=params['epochs'], batch_size=params['batch_size'], callbacks=[checkpoint_callback])\n",
        "    # history berisi riwayat pelatihan model, termasuk nilai loss dan metrik lainnya untuk setiap epoch.\n",
        "    # early_stopping adalah callback yang memonitor metrik tertentu (misalnya, val_loss) dan menghentikan pelatihan jika metrik tersebut tidak membaik setelah sejumlah epoch tertentu.\n",
        "    # epoch_stopped adalah atribut dari callback early_stopping yang menyimpan nomor epoch di mana pelatihan dihentikan lebih awal.\n",
        "\n",
        "    # HASIL NILAI LOSS DARI HISTORY\n",
        "    # train_loss untuk loss dari data training pada proses pembelajaran\n",
        "    train_loss = history.history['loss']\n",
        "    # val_loss untuk loss dari data testing pada proses pengujian\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    # mencatat nilai loss pada tiap epoch\n",
        "    losses.append({'train_loss': train_loss, 'val_loss': val_loss})\n",
        "    # losses = sebuah list yg menyimpan dictionary\n",
        "    # setiap dictionary berisi nilai loss pada tiap epoch\n",
        "    # append = digunakan untuk menambahkan elemen baru ke dalam list\n",
        "\n",
        "    print('Train Loss Terendah: ', min(history.history['loss']))\n",
        "    print('Epoch Stop: ', history.history['loss'].index(min(history.history['loss'])))\n",
        "    print('Val Loss Terendah: ', min(history.history['val_loss']))\n",
        "    print('Epoch Val Loss Stop: ', history.history['val_loss'].index(min(history.history['val_loss']))+1)\n",
        "    print('==================================================================================================================\\n')\n",
        "\n",
        "    # MENYIMPAN HASIL KOMBIANSI HYPERPARAMETER\n",
        "    # menyimpan hasil pemodelan berdasarkan kombinasi parameter dalam list\n",
        "    result.append({**params, \"Training Loss\": min(train_loss), \"Validation Loss\": min(history.history['val_loss'])})\n",
        "    # nilai loss yang dicatat merupakan nilai loss minimum\n",
        "\n",
        "# MENGUBAH DALAM BENTUK EXCEL\n",
        "# membuat dataframe untuk result agar mudah untuk dianalisis (dibuat tabel)\n",
        "result_df = pd.DataFrame(result)\n",
        "# menyimpan result dalam format excel\n",
        "result_df.to_excel(f'Result Grafik Loss {params[\"optimizer\"]}.xlsx', index=False)\n",
        "\n",
        "# MEMUAT MODEL TERBAIK\n",
        "# Mencari baris dalam dataframe result_df yang memiliki nilai minimum MAPE\n",
        "# Menentukan parameter terbaik berdasarkan nilai minimum MAPE\n",
        "best_result = result_df.loc[result_df['Validation Loss'].idxmin()]\n",
        "# membuat dictionary tanpa MAPE dan Epoch Stopped\n",
        "best_params = best_result.drop(['optimizer']).to_dict()\n",
        "best_params = {param: float(value) for param, value in best_params.items()}\n",
        "\n",
        "\n",
        "# MENAMPILKAN HYPERPARAMETER TERBAIK\n",
        "print(\"Best Model Parameters:\")\n",
        "print(best_params)\n",
        "print(\"Training Loss:\", best_result['Training Loss'].min())\n",
        "print(\"Validation Loss:\", best_result['Validation Loss'].min())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "collapsed": true,
        "id": "yOMxknXK5NWt",
        "outputId": "70dbb5db-8f99-49ef-fe16-39dd4a89e41f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss Adam')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qQebe4ZR4Hv7",
        "NjoJ8njZzF4Q",
        "quUiueKbzgWK",
        "d9oEyHzGz84A",
        "0Otu_8Hi9uZo",
        "r2xHEFpYOMno",
        "PqyJkMERODti",
        "Fj6T9rxM0QLq"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}